% This is the Reed College LaTeX thesis template. Most of the work
% for the document class was done by Sam Noble (SN), as well as this
% template. Later comments etc. by Ben Salzberg (BTS). Additional
% restructuring and APA support by Jess Youngberg (JY).
% Your comments and suggestions are more than welcome; please email
% them to cus@reed.edu
%
% See http://web.reed.edu/cis/help/latex.html for help. There are a
% great bunch of help pages there, with notes on
% getting started, bibtex, etc. Go there and read it if you're not
% already familiar with LaTeX.
%
% Any line that starts with a percent symbol is a comment.
% They won't show up in the document, and are useful for notes
% to yourself and explaining commands.
% Commenting also removes a line from the document;
% very handy for troubleshooting problems. -BTS

% As far as I know, this follows the requirements laid out in
% the 2002-2003 Senior Handbook. Ask a librarian to check the
% document before binding. -SN

%%
%% Preamble
%%
% \documentclass{<something>} must begin each LaTeX document
%\documentclass[12pt,twoside]{reedthesis}
\documentclass[12pt,oneside]{reedthesis} 
% Packages are extensions to the basic LaTeX functions. Whatever you
% want to typeset, there is probably a package out there for it.
% Chemistry (chemtex), screenplays, you name it.
% Check out CTAN to see: http://www.ctan.org/
%%
\usepackage{graphicx,latexsym}
\usepackage{amsmath}
\usepackage{amssymb,amsthm}
\usepackage{longtable,booktabs,setspace}
\usepackage{chemarr} %% Useful for one reaction arrow, useless if you're not a chem major
\usepackage[hyphens]{url}
\usepackage[utf8]{inputenc}
% Added by CII
\usepackage[hidelinks]{hyperref}  
% \usepackage{hyperref}
\usepackage{lmodern}
\usepackage{float}
\floatplacement{figure}{H}
% End of CII addition
\usepackage{rotating}

% Next line commented out by CII
%%% \usepackage{natbib}
% Comment out the natbib line above and uncomment the following two lines to use the new
% biblatex-chicago style, for Chicago A. Also make some changes at the end where the
% bibliography is included.
%\usepackage{biblatex-chicago}
%\bibliography{thesis}


% Added by CII (Thanks, Hadley!)
% Use ref for internal links
\renewcommand{\hyperref}[2][???]{\autoref{#1}}
\def\chapterautorefname{Chapter}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}
% End of CII addition

% Added by CII
\usepackage{caption}
\captionsetup{width=5in}
% End of CII addition

% \usepackage{times} % other fonts are available like times, bookman, charter, palatino

% Syntax highlighting #22

% To pass between YAML and LaTeX the dollar signs are added by CII
\title{Spatio-temporal analysis of extreme wind velocities for infrastructure design}
\author{Alexys Herleym Rodríguez Avellaneda}
% The month and year that you submit your FINAL draft TO THE LIBRARY (May or December)
\date{Jan 2020}
\division{Institute for Geoinformatics - IFGI}
\advisor{Dr.~Edzer Pebesma}
\institution{University of Münster}
\degree{Master of Science in Geospatial Technologies}
%If you have two advisors for some reason, you can use the following
% Uncommented out by CII
\altadvisor{Dr.~Juan C. Reyes\textbackslash Dr.~Sara Ribero}
% End of CII addition

%%% Remember to use the correct department!
\department{Faculty of Geosciences}
% if you're writing a thesis in an interdisciplinary major,
% uncomment the line below and change the text as appropriate.
% check the Senior Handbook if unsure.
%\thedivisionof{The Established Interdisciplinary Committee for}
% if you want the approval page to say "Approved for the Committee",
% uncomment the next line
%\approvedforthe{Committee}

% Added by CII
%%% Copied from knitr
%% maxwidth is the original width if it's less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\renewcommand{\contentsname}{Table of Contents}
% End of CII addition

\setlength{\parskip}{0pt}

% Added by CII
  %\setlength{\parskip}{\baselineskip}
  \usepackage[parfill]{parskip}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\Acknowledgements{
I would like to thank Prof.~Dr.~Edzer Pebesma, Prof.~Dr.~Juan C. Reyes, and Prof.~Dr.~Sara Ribero, for supervising my work and spending their valuable time for discussions and feedback. It was really a huge advantage for me to have this always available support. It was a pleasure to work beside you. I want to thank Dr Adam Pintar and Engineer Juan David Sandoval for their support and contributions. My mother Ligia made possible all my achievements, because she was always there with love, support, and valuable advice and contributions. I am grateful with all my heart. Thanks to my daughter Nicolle Chaely for its love, support, and always pleasant company. I would like to thank the European Union -`Erasmus Mundus Grant', because their funding allow me to fulfill this dream to go further with my academic and professionals dreams.

\par

I especially want to thank to Dr.~Joaquín Huerta Guijarro, because he always was available to help and he was very friendly and receptive. Likewise, I want to thank some family members as Elsa Manrique, Barbara Avellaneda, and Kevin Martinez because they were an important source of motivation and support.

\par

To all the beautiful people that shared with me different activities at the San Antonius Church of Muenster, with special mention of father Alejandro Serrano Palacios and choir friends.
}

\Dedication{
\begin{tabbing}
pdf \hspace{3em} \= Probability Distribution Function  \\
cdf \>  Cumulative Distribution Function \\
ppf \> Percent Point Function (Quantile) \\
hf \> Hazard Function \\
$P_e$ \> Annual Exceedance Probability \\
MRI \> Mean Return Interval or Return Period \\
$P_n$ \>  Compound Exceedance Probability \\
IDEAM \> Institute of Hydrology, Meteorology and Environmental Studies \\
ECMWF \>  European Center for Medium-Range Weather Forecasts \\
ERA5 \>  ECMWF climate reanalysis dataset  \\
GEVD \>  Generalized Extreme Value Distribution (EVD, GEV) \\
EVD \>  Extreme Value Distribution (GEVD, GEV)  \\
GEV \>  Generalized Extreme Value Distribution (GEVD, EVD)  \\
GPD \>  Generalized Pareto Distribution  \\
ISD \> Integrated Surface Database \\
AIS \> Seismic Engineering Association  \\
NSR \> Seismic Resistant Norm  \\
SEI \> Structural Engineering Institute \\
ASCE \> American Society of Civil Engineers \\
ASCE7-16 \> ASCE/SEI Design Loads Standard \\
NOAA \> National Oceanic and Atmospheric Administration \\
NetCDF \> Network Common Data Form \\
NCEI \> NOAA's National Centers for Environmental Information \\
EDA \>  Exploratory Data Analysis \\
POT \> Peaks Over Threshold \\
PP \> Poisson Process \\
RMSE \> Root Mean Squared Error \\
PACF \> Partial Autocorrelation Function \\
ACF \>  Autocorrelation Function \\
SQL \>  Structured Query Language \\
IDW \>  Inverse Distance Weighted \\
WGS84 \> World Geodetic System 1984 \\
RL \> Return Level
\end{tabbing}
}

\Preface{
Models of extreme values are used for designing against the effects of extreme events like earthquakes, winds, rainfall, floods of different types of physical processes, avoiding widespread destruction and loss of lives. This research presents a applied case of univariate extreme value analysis applied to wind velocities for infrastructure design, consequently, the main interest are probable future more extreme wind events that structures need to be able to resist.

This work in its theoretical and methodological component was directed by ASCE7-16 Engineers (\protect\hyperlink{ref-Asce2017}{2017}) considering that output products will be used to update the chapter B.6, wind forces, of the Colombian earthquake resistant standard - NSR-10, maintained by the Colombian Association of Seismic Engineering - AIS by its Spanish acronym. ASCE7-16, defines four risk categories, which implies the use of different wind loads (represented in wind extreme values for different mean recurrence intervals) for structures that belong to each category, 3000 years of MRI for risk IV, 1700 years for risk III, and 700 years for risk II and I.

This research has a particularly new situation regarding to the input data, and it is that not only time series of field measurements from meteorological stations are used (IDEAM data source), but also post-processed information coming from the Integrated Surface Database - ISD (USA database based on IDEAM data source), and forecast reanalysis data from ERA5. This condition demanded a comparison of the different data sources in order to verify the feasibility of using ERA5 and ISD, with a previous process of standardization of wind velocities to reach the needed requirement of 3-s wind gust speed, 10 meters anemometers high and open space condition.

At each station the used method Peaks Over Threshold - Poisson Process, required to identify all the non-thunderstorm events in the non-hurricane dataset through a process of de-clustering, choose a suitable threshold level to leave for the analysis only the most extreme values available, and then fit to the data a Gumbel extreme value distribution using maximum likelihood to find optimal parameters with the best goodness of fit. With the fitted model, it was possible to calculate return levels for required mean return intervals. Next, a process of spatial interpolation was done using Kriging, what allowed to have three continuous maps for the whole study area. Main interest writing this document, is help to readers to enter speedily with the current details around wind extreme analysis.
}

\Abstract{
For the input non-hurricane, non tornadic data in each available station of the study area (field measurement of forecast models), this research calculate extreme winds or return levels with three different mean recurrence intervals - MRI, 700, 1700, and 3000 years, with a change of being equaled or exceeded only one time in the corresponding MRI period. Then, continuous maps of wind extreme velocities are interpolated to cover the study area, which are mixed with existing wind extreme hurricane studies to be used as input loads for infrastructure design.

\par

Spatio-temporal analysis of historical wind data for infrastructure design, namely, \(-\) from wind time series represented in forecast models over rectangular areas or pixels with a virtual station at its center, or field measurements at weather stations in specific coordinates around the study area \(-\), calculate wind extreme magnitudes to be used as design loads of structures of different risk categories (bridges, houses, buildings, hospitals, etc), requires the use of statistical extreme value analysis methodologies to create maps with different mean recurrence intervals (MRI), \(-\) short ones for less risky/important structures, and long ones for highly important structures.

Method used to calculate the return levels at each station the Peaks Over Threshold - POT, using a non-homogeneous, bi-dimensional Poisson Process described, recommended by Engineers (\protect\hyperlink{ref-Asce2017}{2017}), and developed and implemented in Pintar, Simiu, Lombardo, \& Levitan (\protect\hyperlink{ref-Pintar2015}{2015}). To interpolate maps a geostatistical procedure using Kriging was implemented, considering the model with the best goodness of fit from model parameters comparison.
}

	\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
% End of CII addition
%%
%% End Preamble
%%
%
\begin{document}

% Everything below added by CII
  \maketitle

\frontmatter % this stuff will be roman-numbered
\pagestyle{empty} % this removes page numbers from the frontmatter
  \begin{acknowledgements}
    I would like to thank Prof.~Dr.~Edzer Pebesma, Prof.~Dr.~Juan C. Reyes, and Prof.~Dr.~Sara Ribero, for supervising my work and spending their valuable time for discussions and feedback. It was really a huge advantage for me to have this always available support. It was a pleasure to work beside you. I want to thank Dr Adam Pintar and Engineer Juan David Sandoval for their support and contributions. My mother Ligia made possible all my achievements, because she was always there with love, support, and valuable advice and contributions. I am grateful with all my heart. Thanks to my daughter Nicolle Chaely for its love, support, and always pleasant company. I would like to thank the European Union -`Erasmus Mundus Grant', because their funding allow me to fulfill this dream to go further with my academic and professionals dreams.
    
    \par
    
    I especially want to thank to Dr.~Joaquín Huerta Guijarro, because he always was available to help and he was very friendly and receptive. Likewise, I want to thank some family members as Elsa Manrique, Barbara Avellaneda, and Kevin Martinez because they were an important source of motivation and support.
    
    \par
    
    To all the beautiful people that shared with me different activities at the San Antonius Church of Muenster, with special mention of father Alejandro Serrano Palacios and choir friends.
  \end{acknowledgements}
  \begin{preface}
    Models of extreme values are used for designing against the effects of extreme events like earthquakes, winds, rainfall, floods of different types of physical processes, avoiding widespread destruction and loss of lives. This research presents a applied case of univariate extreme value analysis applied to wind velocities for infrastructure design, consequently, the main interest are probable future more extreme wind events that structures need to be able to resist.
    
    This work in its theoretical and methodological component was directed by ASCE7-16 Engineers (\protect\hyperlink{ref-Asce2017}{2017}) considering that output products will be used to update the chapter B.6, wind forces, of the Colombian earthquake resistant standard - NSR-10, maintained by the Colombian Association of Seismic Engineering - AIS by its Spanish acronym. ASCE7-16, defines four risk categories, which implies the use of different wind loads (represented in wind extreme values for different mean recurrence intervals) for structures that belong to each category, 3000 years of MRI for risk IV, 1700 years for risk III, and 700 years for risk II and I.
    
    This research has a particularly new situation regarding to the input data, and it is that not only time series of field measurements from meteorological stations are used (IDEAM data source), but also post-processed information coming from the Integrated Surface Database - ISD (USA database based on IDEAM data source), and forecast reanalysis data from ERA5. This condition demanded a comparison of the different data sources in order to verify the feasibility of using ERA5 and ISD, with a previous process of standardization of wind velocities to reach the needed requirement of 3-s wind gust speed, 10 meters anemometers high and open space condition.
    
    At each station the used method Peaks Over Threshold - Poisson Process, required to identify all the non-thunderstorm events in the non-hurricane dataset through a process of de-clustering, choose a suitable threshold level to leave for the analysis only the most extreme values available, and then fit to the data a Gumbel extreme value distribution using maximum likelihood to find optimal parameters with the best goodness of fit. With the fitted model, it was possible to calculate return levels for required mean return intervals. Next, a process of spatial interpolation was done using Kriging, what allowed to have three continuous maps for the whole study area. Main interest writing this document, is help to readers to enter speedily with the current details around wind extreme analysis.
  \end{preface}
  \hypersetup{linkcolor=black}
  \setcounter{tocdepth}{4}
  \tableofcontents

  \listoftables

  \listoffigures
  \begin{abstract}
    For the input non-hurricane, non tornadic data in each available station of the study area (field measurement of forecast models), this research calculate extreme winds or return levels with three different mean recurrence intervals - MRI, 700, 1700, and 3000 years, with a change of being equaled or exceeded only one time in the corresponding MRI period. Then, continuous maps of wind extreme velocities are interpolated to cover the study area, which are mixed with existing wind extreme hurricane studies to be used as input loads for infrastructure design.
    
    \par
    
    Spatio-temporal analysis of historical wind data for infrastructure design, namely, \(-\) from wind time series represented in forecast models over rectangular areas or pixels with a virtual station at its center, or field measurements at weather stations in specific coordinates around the study area \(-\), calculate wind extreme magnitudes to be used as design loads of structures of different risk categories (bridges, houses, buildings, hospitals, etc), requires the use of statistical extreme value analysis methodologies to create maps with different mean recurrence intervals (MRI), \(-\) short ones for less risky/important structures, and long ones for highly important structures.
    
    Method used to calculate the return levels at each station the Peaks Over Threshold - POT, using a non-homogeneous, bi-dimensional Poisson Process described, recommended by Engineers (\protect\hyperlink{ref-Asce2017}{2017}), and developed and implemented in Pintar, Simiu, Lombardo, \& Levitan (\protect\hyperlink{ref-Pintar2015}{2015}). To interpolate maps a geostatistical procedure using Kriging was implemented, considering the model with the best goodness of fit from model parameters comparison.
  \end{abstract}
  \begin{dedication}
    \begin{tabbing}
    pdf \hspace{3em} \= Probability Distribution Function  \\
    cdf \>  Cumulative Distribution Function \\
    ppf \> Percent Point Function (Quantile) \\
    hf \> Hazard Function \\
    $P_e$ \> Annual Exceedance Probability \\
    MRI \> Mean Return Interval or Return Period \\
    $P_n$ \>  Compound Exceedance Probability \\
    IDEAM \> Institute of Hydrology, Meteorology and Environmental Studies \\
    ECMWF \>  European Center for Medium-Range Weather Forecasts \\
    ERA5 \>  ECMWF climate reanalysis dataset  \\
    GEVD \>  Generalized Extreme Value Distribution (EVD, GEV) \\
    EVD \>  Extreme Value Distribution (GEVD, GEV)  \\
    GEV \>  Generalized Extreme Value Distribution (GEVD, EVD)  \\
    GPD \>  Generalized Pareto Distribution  \\
    ISD \> Integrated Surface Database \\
    AIS \> Seismic Engineering Association  \\
    NSR \> Seismic Resistant Norm  \\
    SEI \> Structural Engineering Institute \\
    ASCE \> American Society of Civil Engineers \\
    ASCE7-16 \> ASCE/SEI Design Loads Standard \\
    NOAA \> National Oceanic and Atmospheric Administration \\
    NetCDF \> Network Common Data Form \\
    NCEI \> NOAA's National Centers for Environmental Information \\
    EDA \>  Exploratory Data Analysis \\
    POT \> Peaks Over Threshold \\
    PP \> Poisson Process \\
    RMSE \> Root Mean Squared Error \\
    PACF \> Partial Autocorrelation Function \\
    ACF \>  Autocorrelation Function \\
    SQL \>  Structured Query Language \\
    IDW \>  Inverse Distance Weighted \\
    WGS84 \> World Geodetic System 1984 \\
    RL \> Return Level
    \end{tabbing}
  \end{dedication}
\mainmatter % here the regular arabic numbering starts
\pagestyle{fancyplain} % turns page numbering back on

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

This research aims to create non-hurricane non-tornadic maps of extreme wind speeds for \emph{three specific recurrence intervals} (700, 1700, and 3000 years) covering the Colombian territory. These maps will be combined with existing hurricane wind speed studies, to be used as input loads due to wind for infrastructure design.

For each station with wind speeds time histories in the input data, extreme wind speed corresponding to each recurrence interval are calculated using a \emph{Peaks Over Threshold} onwards \emph{POT} extreme value model, then wind velocities with the same recurrence interval are \emph{spatially interpolated} to generate continuous maps for the whole study area.

A wind speed linked to a \emph{mean recurrence interval - MRI} of \emph{N-years} (N-years return value or return period) is interpreted as the highest probable wind speed along the period of N-years. The annual probability of equal or exceed that wind speed is 1/N. The annual exceedance probability for all velocity values in 700-years output map will be 1/700, for the 1700-years map will be 1/1700, and 1/3000 for the 3000-years final map.

There are different methods to model extreme value data, among them are a) sample maxima using a \emph{Generalized Extreme Value Distribution} onwards \emph{GEVD} (traditional method), b) POT using a \emph{Generalized Pareto Distribution} onwards \emph{GPD}, c) POT using a two-dimensional Poisson Process, that can be homogeneous, non-homogeneous, stationary, and non-stationary (originally know as \emph{Point Process} approach), and d) POT Poisson-GPD. Following Pintar et al. (\protect\hyperlink{ref-Pintar2015}{2015}) in this research a \emph{POT using a non-homogeneous non-stationary two-dimensional Poisson proces} was selected, despite there is no R package available to apply this approach.

\hypertarget{background}{%
\section{Background}\label{background}}

To design one structure, the horizontal forces wind and earthquake play an starring role. For the study area, Colombia, initially the wind force was considered with the decree 1984 as a fixed velocity \(100 \frac{Km}{h}\), later a continuous map with a return period of 50 years was included in the official design standard of the time (NSR-98), then, with the update to NSR-10, an additional map with return period of 700 yeas was included.

In the context of this study, extreme wind analysis is concerned with statistical methods applied to very high values of wind as random variable in a stochastic process, to allow statistical inference from historical data, namely, assess from the ordered sample of wind velocities, the probability of wind events that are more extreme than the ones previously observed and included in the mentioned input sample. Classical reference in this matter is Coles (\protect\hyperlink{ref-Coles2001}{2001}), where a detailed study is done about classical extreme value theory and models and threshold models. There are four main approaches to deal with extreme value analysis: - sample maxima associated to a Generalized Extreme Value Distribution - GEV, - exceedances over threshold associated to a Generalized Pareto Distribution - GPD, - the Poisson-GPD, an homogeneous Poisson process for the number of exceedances and a GPD for the excess values, and the exceedances over threshold associated to a non- homogeneous bi-dimensional Poisson process, a Point process approach also known as Peaks Over Threshold - POT - Poisson process. Main details will be discussed here for each method, but as the last one is recommended in Asce2017, a more indeed explanation will be provided in for \protect\hyperlink{pot-pp}{POT-Poisson Process}.

\hypertarget{sample-maxima}{%
\subsection{Sample maxima}\label{sample-maxima}}

To work with random variables of sample maximum values, the used probability distribution function \emph{pdf} is the GEV

\[
H(y) = \exp\left\{-\left(1+\xi\frac{y-\mu}{\psi}\right)_+^{-\frac{1}{\xi}}\right\},
\]
\((y+=max(y,0))\) where \(\mu\) is the location parameter, \(\psi > 0\) is a scale parameter, and \(\xi\) is a shape parameter. GEV can be seen as the integration in the same \emph{psf} of the Gumbel distribution (limit \(\xi\rightarrow0\)), Fréchet distribution (\(\xi>0\)), and Weibull distribution (\(\xi<0\)).

\hypertarget{exceedances-over-threshold}{%
\subsection{Exceedances over threshold}\label{exceedances-over-threshold}}

If the researcher needs to work only with extreme values above an specific threshold, Pickands (\protect\hyperlink{ref-Pickands1971}{1971}) showed that the GEV has a GPD approximation where shape \(\xi\) parameter in previous equation is the same parameter for next equation for GPD,

\[
G(y,\sigma, \xi) = 1-\left(1+\xi\frac{y}{\sigma}\right)_+^{-\frac{1}{\xi}},
\]
\#\#\# Poisson-GPD
If a rescale of the variable indexes above the threshold is performed, then the exceedances over threshold approach can be seen as a point process, namely, an homogeneous Poisson Process where:
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The number of exceedances above the threshold has a Poisson distribution with mean \(\lambda\)
\item
  The excess values follow a GPD with \(N\leq1\)
\end{enumerate}
Its cumulative distribution function \emph{cdf} is

\[
F(y) = \exp\left\{-\lambda\left(1+\xi\frac{y-\mu}{\sigma}\right)_+^{-\frac{1}{\xi}}\right\},
\]

\hypertarget{research-aim-and-objectives}{%
\section{Research Aim and Objectives}\label{research-aim-and-objectives}}

Main aim of this research is the estimation of wind extreme velocities to be used as input loads for the design of different types of structures, considering its risk categories, and covering any place in the whole study area.

Specific objectives are:
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Analyze and compare three different sources of historical wind time series, to select and use the best data source (or combination or sources) for research, based on objective criteria, for instance similitude, completeness, coverage, etcetera, to achieve this way a formal support for the decision made in this regard.
\item
  Select and apply an suitable extreme value analysis method that allows to fulfill wind load requirements defined for the respective authority in the study area
\item
  Estimate extreme wind values for the stations in the selected input data source, for three MRI (700, 1700, 3000 years), considering non-hurricane studies.
\item
  Generate continuous maps for MRIs 700, 1700, and 3000 years, using the most suitable spatial interpolation technique, considering the specific characteristics of the input data and advantages and disadvantages of the selected methods
\item
  Combine output maps from non-hurricane analysis, with existing hurricane studies to allow the inclusion of the research study in the NSR-10 norm.
\end{enumerate}
\hypertarget{research-question}{%
\section{Research Question}\label{research-question}}

Main question of this research is directed to calculate future extreme velocities (return levels) for infrastructure design, then the research question could be

\textbf{What extreme velocities (return levels) need to be used as load design forces for structures of different use category, in the study area?}

If we remember that, for the case study area (Colombia), there are predefined requirements or mean return intervals - MRI to design structures depending of it use category, and that this MRI values are 700, 1700, and 3000 years, the research question could be more specific.

\textbf{What extreme velocities (return levels) will be equaled or exceeded with a probability equal to \(\frac{1}{MRI}\) in a given year?}

\textbf{What extreme velocities (return levels) will be equaled or exceeded only one time in the period defined for this specific MRIs: 700, 1700, and 3000 years?}

If we consider not only the annual exceedance probability \(\frac{1}{MRI}\), but also the exposure time (compound probability), understood as the time the structure will be in use, then the question will be

\textbf{What extreme velocities (return levels) will have a occurrence compound probability of 67\%, when the exposure time of the structure will be equal to the main return intervals 700, 1700, and 3000 years?}

\hypertarget{thesis-document-structure}{%
\section{Thesis Document Structure}\label{thesis-document-structure}}

\hypertarget{rmd-data}{%
\chapter{Data}\label{rmd-data}}

Input data is made up of three different sources a) IDEAM - Institute of Hydrology, Meteorology and Environmental Studies of Colombia \url{http://www.ideam.gov.co}, b) ISD - Integrated Surface Database \url{https://www.ncdc.noaa.gov/isd}, and c) ERA5 climate reanalysis \url{https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5}.

\begingroup\fontsize{10}{12}\selectfont
\begin{longtable}[t]{l>{\raggedright\arraybackslash}p{0.8in}>{\raggedright\arraybackslash}p{4in}}
\caption[Datasets]{\label{tab:tabledatasources1}Datasets description}\\
\toprule
\multicolumn{1}{l}{Institution} & \multicolumn{1}{l}{Dataset} & \multicolumn{1}{l}{Details}\\
\midrule
IDEAM & Historical records at weather stations & IDEAM is responsible for the instalation, maintenance and management of all kind of weather stations located everywhere along the country\\
NOAA & ISD & ISD (Integrated Surface Database. NOAA's National Centers for Environmental Information - NCEI) Lite: A subset from the full ISD dataset containing eight common surface parameters in a fixed-width format free of duplicate values, sub-hourly data, and complicated flags.\\
ECMWF & ERA5 & ERA5 is a reanalysis dataset with hourly estimates of atmospheric variables with horizontal resolution of 0.25º (33 kilómeters), this is equally spaced cells every 0.25 degrees\\
\bottomrule
\end{longtable}
\endgroup{}

\begingroup\fontsize{10}{12}\selectfont
\begin{longtable}[t]{l>{\raggedright\arraybackslash}p{1.2in}>{\raggedright\arraybackslash}p{3.5in}}
\caption[Variables]{\label{tab:tabledatasources2}Datasets variables}\\
\toprule
\multicolumn{1}{l}{Dataset} & \multicolumn{1}{l}{Variables} & \multicolumn{1}{l}{Description}\\
\midrule
IDEAM & vv\_aut\_2 & Instantaneous wind velocity each two (2) minutes\\
 & vv\_aut\_10 & Instantaneous wind velocity each ten (10) minutes\\
ISD & v5 & Maximun hourly five seconds (5-s) wind gust velocity\\
ERA5 & fg10 & 10 metre wind gust since previous post-processing\\
 & fsr & Forecast Surface Roughness\\
\bottomrule
\end{longtable}
\endgroup{}

\begingroup\fontsize{10}{12}\selectfont
\begin{longtable}[t]{l>{\raggedright\arraybackslash}p{0.8in}>{\raggedright\arraybackslash}p{3in}l}
\caption[Units and Time]{\label{tab:tabledatasources3}Variables units and time}\\
\toprule
\multicolumn{1}{l}{Variable} & \multicolumn{1}{l}{Units} & \multicolumn{1}{l}{Time} & \multicolumn{1}{l}{Stations}\\
\midrule
vvmx\_aut\_60 & meters per second & Variable from 2001 until today. Irregular time series. & 203\\
Wind speed & meters per second & Variable from 1941 until today. Note: There is too much variability in time (start, end, and time range) for each station. Irregutal time series. & 101\\
fg10 & meters per second & 1979-Today & 3381\\
fsr & meters per second & 1979-Today & 3381\\
\bottomrule
\end{longtable}
\endgroup{}

Ideal data source to create extreme wind speeds maps should be field observed data from IDEAM, but there are not enough number of stations around the study area to represent all the local wind variability in a huge country with multiple variety of climates and and changing thermal floors, but there are other important motivation to include different sources trying to improve output results:
\begin{itemize}
\tightlist
\item
  As just mentioned, low quantity of IDEAM stations
\item
  There are uncertainties related to the way IDEAM anemometers are registering data, then comparison with other data sources are needed to be able to do appropriate data standardization, needed as a prerequisite to the analysis.
\item
  There is no time continuity in the registration of IDEAM data. Historical time series are different and variable in each station.
\end{itemize}
Importance of ISD database for this study is based on the fact that post-processed ISD database has wind extreme values, and it was used to create extreme wind maps for United States. ISD allows comparison with IDEAM records to take better decisions in order to do needed data standardization.

Despite that ERA5 data are not observed data, but forecast, its main advantage is data availability to assess the local climatic variance every 33 square kilometers.

\hypertarget{ideam}{%
\section{IDEAM}\label{ideam}}

Historical observed wind speeds from 203 stations in Colombia are managed by the official environmental authority IDEAM. Table \ref{tab:tableideamstations} shows a sample of five IDEAM stations. Figure \ref{fig:plotideamstations} shows a map of IDEAM stations.
\begin{longtable}[t]{lrr}
\caption[IDEAM Stations]{\label{tab:tableideamstations}IDEAM Stations sample}\\
\toprule
Name[Code] & Latitud & Longitud\\
\midrule
EMAS - AUT [26155230] & 5.09 & -75.51\\
SAN BENITO - AUT [25025380] & 9.16 & -75.04\\
AEROPUERTO ALFONSO LOPEZ - [28025502] & 10.44 & -73.25\\
TIBAITATA - AUT [21206990] & 4.69 & -74.21\\
ELDORADO CATAM - AUT [21205791] & 4.71 & -74.15\\
\bottomrule
\end{longtable}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotideamstations-1.pdf}
\caption{\label{fig:plotideamstations}IDEAM Stations. Colombia}
\end{figure}
Following, the time series, autocorrelation function, and partial autocorrelation function, for IDEAM station ``21205791'' will be displayed.
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneideamstation-1.pdf}
\caption{\label{fig:plotoneideamstation}IDEAM Station - Time Series}
\end{figure}
\hypertarget{isd}{%
\section{ISD}\label{isd}}

ISD is a database with environmental variables among then extreme wind speeds. ISD has data for the whole planet, and is based on observed data at meteorological stations in each country, which means that for Colombia is based on IDEAM data. Main advantage is data availability at neighbor countries and specialized post-processing made by NOAA's National Centers for Environmental Information - NCEI in United States, which facilitates its use.Table \ref{tab:tableisdstations} shows a sample of five ISD stations. Figure \ref{fig:plotisdstations} shows a map of ISD stations.
\begin{longtable}[t]{llrr}
\caption[ISD Stations]{\label{tab:tableisdstations}ISD Stations sample}\\
\toprule
Code & Name & Latitud & Longitud\\
\midrule
804400 & BARINAS & 8.62 & -70.22\\
800810 & ALTO CURICHE & 7.05 & -76.35\\
801000 & BAHIA SOLANO / JOSE MUTIS & 6.18 & -77.40\\
802590 & ALFONSO BONILLA ARAGON INTL & 3.54 & -76.38\\
803150 & BENITO SALAS & 2.95 & -75.29\\
\bottomrule
\end{longtable}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotisdstations-1.pdf}
\caption{\label{fig:plotisdstations}ISD Stations. Colombia and surroundings}
\end{figure}
Following, the time series, autocorrelation function, and partial autocorrelation function, for ISD station ``802590'' will be displayed.
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneisdstation-1.pdf}
\caption{\label{fig:plotoneisdstation}ISD Station - Time Series}
\end{figure}
\hypertarget{era5}{%
\section{ERA5}\label{era5}}

ERA5 is forecast reanalysis data processed by the \emph{European Center for Medium-Range Weather Forecasts} - ECMWF with wind speeds time series in square cells \emph{matrix of pixels} of 0.25 degrees (33 km) covering the whole planet. For the study area was extracted a raster of 69 rows by 49 columns in format NetCDF. Figure \ref{fig:plotera5stations} shows a map of ERA5 stations (cells centers).
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotera5stations-1.pdf}
\caption{\label{fig:plotera5stations}ERA5 Cells and Stations (cells centers). 49 cols by 69 rows. Cell size 0.25 decimal degrees (aprox 28 km in Colombia). Station IDs from 1 (lon=-79, lat=12.5) to 3381 (lon=-67, lat=-4.5)}
\end{figure}
\hypertarget{data-download-and-organization}{%
\section{Data Download and Organization}\label{data-download-and-organization}}

\hypertarget{data-standardization}{%
\section{Data Standardization}\label{data-standardization}}

Analysis of extreme wind speeds requires data standardization as initial step. All input data must be standardized to represent three important conditions: a) anemometer height of 10 meters, b) open space roughness, and c) averaging time of 3-seconds wind gust. Data for analysis must represent 3-s peak wind speeds 10 meters height above the surface, in open terrain.
* 10 meters anemometer height
* Open space terrain roughness
* 3-s gust averaging time

\clearpage

\hypertarget{rmd-thefra}{%
\chapter{Theoretical Framework}\label{rmd-thefra}}

\hypertarget{probability-concepts}{%
\section{Probability Concepts}\label{probability-concepts}}

Poisson process is an stochastic method that relies in the concepts of probability distributions. The main functions related to probability for extreme value analysis will be described below.

\hypertarget{probability-density-function---pdf}{%
\subsection{\texorpdfstring{Probability Density Function - \emph{pdf}}{Probability Density Function - pdf}}\label{probability-density-function---pdf}}

\emph{Pdf} defines the probability that a continuous variable falls between two points, this is, in \emph{pdf} the probability is related to the area below the curve (integral) between two points, as for continuous probability distributions the probability at a single point is zero. The term density is directly related to the probability of a portion of the curve, if the density function has high values the probability will be greater in comparison with the same portion of curve for low values.

\[
\int_a^b f(x)dx = Pr[a \leq X \leq b]
\]

Equation \eqref{eq:gumbelpdf} is the Gumbel \emph{pdf}.
\begin{equation}
  \mathrm{
          f(x)=\frac{1}{\beta}
          \exp\left\{
            -\frac{x-\mu}{\beta}
          \right\}
          \exp\left\{
            -\exp\left\{
              -\left(
                \frac{x-\mu}{\beta}
              \right)
            \right\}
          \right\},
          \quad -\infty < x < \infty
         }
  \label{eq:gumbelpdf}
\end{equation}
where \(\exp\left\{.\right\} \mapsto \mathrm{e}^{\left\{.\right\}}\), \(\beta\) is the scale parameter, and \(\mu\) is the location parameter. Location (\(\mu\)) has the effect to shift the \emph{pdf} to left or right along `x' axis, thus, if location value is changed the effect is a movement of \emph{pdf} to the left (small value for location), or to the right (big value for location). Scale has the effect to stretch (\(\beta > 1\)) of compress (\(0 < \beta< 1\)) the \emph{pdf}, if scale parameter is close to zero the \emph{pdf} approaches a spike.

Figure \ref{fig:plotgumbelpdffunction} shows \emph{pdf} with location (\(\mu\)) = 100 and scale (\(\beta\)) = 40, using equation \eqref{eq:gumbelpdf}.

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelpdffunction-1.pdf}
\caption{\label{fig:plotgumbelpdffunction}Gumbel pdf}
\end{figure}
\normalsize

Figure \ref{fig:plotgumbelpdf} shows \emph{pdf} with location (\(\mu\)) = 100 and scale (\(\beta\)) = 40, using function \texttt{dgumbel} of the package \texttt{RcmdrMisc}

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelpdf-1.pdf}
\caption{\label{fig:plotgumbelpdf}Gumbel pdf - dgumbel function}
\end{figure}
\normalsize

\hypertarget{cumulative-distribution-function---cdf}{%
\subsection{\texorpdfstring{Cumulative Distribution Function - \emph{cdf}}{Cumulative Distribution Function - cdf}}\label{cumulative-distribution-function---cdf}}

\emph{Cdf} is the probability of taking a value less than or equal to x. That is

\[
F(x) = Pr[X < x] = \alpha
\]
For a continuous variable, \emph{cdf} can be expressed as the integral of its \emph{pdf}.
\[
F(x) = \int_{-\infty}^x f(x)dx
\]

Equation \eqref{eq:gumbelcdf} is the Gumbel \emph{cdf}.
\begin{equation}
\mathrm{
        F(x) = \exp\left\{-\exp\left[-\left(\frac{x-\mu}{\beta}\right)\right]\right\}, 
        \quad -\infty < x < \infty
        }
  \label{eq:gumbelcdf}
\end{equation}
Figure \ref{fig:plotgumbelcdffunction} shows Gumbel \emph{cdf} with location (\(\mu\)) = 100 and scale (\(\beta\)) = 40, using equation \eqref{eq:gumbelcdf}. As previously done with \emph{pdf}, similar result can be achieved using function \texttt{pgumbel} of package \texttt{RcmdrMisc}.

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelcdffunction-1.pdf}
\caption{\label{fig:plotgumbelcdffunction}Gumbel cdf}
\end{figure}
\normalsize

\hypertarget{percent-point-function---ppf}{%
\subsection{\texorpdfstring{Percent Point Function - \emph{ppf}}{Percent Point Function - ppf}}\label{percent-point-function---ppf}}

\emph{Ppf} is the inverse of \emph{cdf}, also called the \emph{quantile} function. This is, from a specific probability get the corresponding value x of the variable.

\[
x = G(\alpha) = G(F(x))
\]
Equation \eqref{eq:gumbelppf} is the Gumbel \emph{ppf}.
\begin{equation}
\mathrm{
        G(\alpha) = \mu-\beta ln(-ln(\alpha))
        \quad 0 < \alpha < 1
        }
  \label{eq:gumbelppf}
\end{equation}
Figure \ref{fig:plotgumbelppffunction} shows Gumbel \emph{ppf}, using equation \eqref{eq:gumbelppf}. Similar result can be achieved using function \texttt{qgumbel} of package \texttt{RcmdrMisc}.

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelppffunction-1.pdf}
\caption{\label{fig:plotgumbelppffunction}Gumbel ppf}
\end{figure}
\normalsize

\hypertarget{hazard-function---hf}{%
\subsection{\texorpdfstring{Hazard Function - \emph{hf}}{Hazard Function - hf}}\label{hazard-function---hf}}

Using \(S(x) = 1 - F(x)\) as survival function -\emph{sf}, the probability that a variable takes a value greater than x \(S(x) = Pr[X > x] = 1 - F(x)\), the \emph{hf} is the ratio between \emph{pdf} and \emph{sf}.

\[
h(x) = \frac{f(x)}{S(x)} = \frac{f(x)}{1-F(x)}
\]
Equation \eqref{eq:gumbelhf} is the Gumbel \emph{ppf}.
\begin{equation}
\mathrm{
        h(x)= \frac{1}{\beta}\frac{\exp(-(x-\mu)/\beta)}{\exp(\exp(-(x-\mu)/\beta))-1}
       }
  \label{eq:gumbelhf}
\end{equation}
Figure \ref{fig:plotgumbelhffunction} shows Gumbel \emph{hf}, using equation \eqref{eq:gumbelhf}.

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelhffunction-1.pdf}
\caption{\label{fig:plotgumbelhffunction}Gumbel hf}
\end{figure}
\normalsize

\hypertarget{statistical-concepts-for-extreme-analysis}{%
\section{Statistical Concepts For Extreme Analysis}\label{statistical-concepts-for-extreme-analysis}}

In order to approach the extreme value analysis, some statistical concepts are needed to understand the theoretical framework behind this knowledge area. In this section will be introduced the concepts annual exceedance probability, mean recurrence interval - MRI, exposure time, and compound probability for any given exposure time and MRI.

As an hypothetical example, a simulated database of extreme wind speed will be used. This database is supposed to have 10.000 years of simulated wind speeds.

\hypertarget{annual-exceedance-probability---p_e}{%
\subsection{\texorpdfstring{Annual Exceedance Probability - \(P_e\)}{Annual Exceedance Probability - P\_e}}\label{annual-exceedance-probability---p_e}}

Using the previously described database, a question arises to calculate the probability to exceed the highest probable loss due to the simulated winds. It is possible to conclude that there is only one event grater or equal (in this case equal) to the highest probable causing loss in 10.000 years, and it is the \emph{highest wind}. If we sort the database by wind magnitude in descending order (small winds last), the question is solved calculating the annual exceedance probability \emph{Pe} with next formula

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/unnamed-chunk-9-1.pdf}
\caption{\label{fig:unnamed-chunk-9}Sorted Winds by Magnitude - wind simulation database}
\end{figure}
\normalsize

\[
P_e = \frac{Event\,index\,after\,descending\,sorting}{Years\,of\,simulations } = \frac{1}{10.000}=0.001=0.01\%
\]
because the highest wind will be the first in the sorted list. Same exercise can be done with all winds to construct the annual exceedance probability curve, that in this case will represent the probability to equal or exceed different probable losses due to wind.

\hypertarget{return-period---mean-recurrence-interval---mri}{%
\subsection{Return Period - Mean Recurrence Interval - MRI}\label{return-period---mean-recurrence-interval---mri}}

Continuing with the previous section, if the inverse of the exceedance probability is taken, the return period (in years) is obtained. The return period or Mean Recurrence Interval - MRI is associated with an specific return level (wind extreme velocity). MRI is the numbers of years (N) needed to obtain 63\% of change that the corresponding return level will occur at least one time in that period. The return level is expected to be exceeded on average once every N-years. The annual exceedance probability of the return level corresponding to N-years of MRI, is \(P_e=\frac{1}{MRI}=\frac{1}{N}\).

For an specific wind extreme event A, the probability that the event will occur in a period equal to MRI years is 63\%. If we analyze for the same period a strongest wind extreme event B, its occurrence probability will be lest than 67\%. If the purpose of this research is to design infrastructure considering wind loads, the structure will be more resistant to wind if we design with stronger winds, this is high MRIs, and low annual exceedance probability. Common approach for infrastructure design, considering any type of load (earthquake, wind, etc) is to choose high MRI according to the importance/use/risk/type of the structure. For highly important structures, like hospitals or coliseums, where the risk of collapse must be diminished, the MRI used to design is higher in comparison to common structures (for instance a normal house), which implies less risks for its use and importance.

\[
  \mathrm{
    P_e = 
    \begin{cases}
      \begin{split}
            &1-\exp\left(-\frac{1}{MRI}\right),\;for\,MRI\,<\,10\,years
            \\
            &\frac{1}{MRI},\;for\,MRI\,\geq\,10\,years      
      \end{split}
    \end{cases}
  }
\]

\hypertarget{compound-exceedance-probability---pn}{%
\subsection{Compound Exceedance Probability - Pn}\label{compound-exceedance-probability---pn}}

If time of exposure is consider, understood as time the structure will be in use, it is possible to have a compound probability \(P_n\), where \(n\) is the exposure period. \(P_n\) is the probability that the extreme wind speed will be equaled or exceeded at least one time in \(n\) years, and is related with the occurrence probability, but also is possible to calculate the non-occurrence compound probability (probability that the event will not occur).

\[
  \mathrm{
    P_n = 
    \begin{cases}
      \begin{split}
            &1-\left(1-\frac{1}{MRI}\right)^n,\;occurrence\,probability
            \\
            &\left(1-\frac{1}{MRI}\right)^n,\;non-occurrence\,probability
      \end{split}
    \end{cases}
  }
\]

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/compoundprobability-1.pdf}
\caption{\label{fig:compoundprobability}Compound Probability}
\end{figure}
\normalsize

If it is consider exposure time as a multiple of return period, the resulting figure \ref{fig:compoundprobability}, shows that:
\begin{itemize}
\tightlist
\item
  When exposure time is .69\% of the return period, then probability (occurrence and non-occurrence) will be 50\%
\item
  As was stated previously, when exposure time is equal to return period, then the probability that the extreme wind speed (return level) occur is 63\%, and 37\% for the non occurrence probability.
\item
  If exposure time is 4.5 times the return period, there is a 99\% of change that the return level will occur.
\end{itemize}
The example discussed here was presented as an instrument to introduce important concepts, nonetheless,there are specialized approaches to deal with extreme value analysis which will be discussed in \protect\hyperlink{extremeoverview}{Extreme Value Analysis Overview} and more in detail in \protect\hyperlink{pot-pp}{Peaks Over Threshold - Poisson Process}. In summary, is necessary to fit the data over a specific threshold to an extreme value distribution, and \(P_e\) will be \(1-F(y)\), with F(y) as the \emph{cdf}, and MRI as \(\frac{1}{1-F(y)}\).

\hypertarget{extremeoverview}{%
\section{Extreme Value Analysis Overview}\label{extremeoverview}}

Analysis of extreme values is related with statistical inference to calculate probabilities of extreme events. Main methods to analyze extreme data are epochal, Peaks Over Threshold - POT, and extreme index. The epochal method, also known as block maxima, uses the most extreme value for a specific frame of time, typically, one year. POT is based in the selection of a single threshold value to do the analysis only with values above the threshold. But there are different POT approaches, the most common one is Generalized Pareto Distribution - POT-GPD, but also it is possible to use the Poisson process approach.

In both methods (Epochal and POT), the first step is to fit the data to an appropriate probability distribution model, among them the most used are, - Extreme Value Type I (Gumbel), Extreme Value Type II (Fréchet), Weibull, Generalized Pareto - GPD, and Generalized Extreme Value - GEV.

Distribution models are fitted based in the estimation of its parameters, commonly called location, scale and shape, nonetheless each model has its own parameters names. There are different methods to estimate parameters, among them, - method of moments (modified moments - see Kubler (\protect\hyperlink{ref-Kubler1994}{1994}), and L moments - see Hosking \& Wallis (\protect\hyperlink{ref-Hosking1997}{1997})), - method of maximum likelihood MLE, see Harris \& Stocker (\protect\hyperlink{ref-Harris1994}{1998}), which is problematic for GPD and GEV, - probability plot correlation coefficient, and - elemental percentiles (for GPD and GEV)

Once candidate parameters are available, it is necessary to assess the goodness of fit of the selected model, using one of the next methods, - Kolmogorov-Smirnov (KS) goodness of fit test, and - Anderson-Darling goodness of fit test. Here a visual assessment is also useful using a probability plot or a kernel density plot with the fitted \emph{pdf} overlaid.

The main use of the fitted model is the estimation of mean return intervals - MRI, and extreme wind speeds (return levels),

\[
MRI=\frac{1}{1-F(y)}
\]
with \(F(y)\) as the \emph{cdf}. If \(1-F(y)\) is the annual exceedance probability, MRI is its inverse, see Simiu \& Scanlan (\protect\hyperlink{ref-Simiu1996}{1996}) for more details about MRI. If \(y\) is solved from previous equation using a given MRI of N-years, its value represents the \(Y_N\) wind speed return level,

\[
Y_N = G\left(1-\frac{1}{\lambda\,N}\right)
\]
where \(G\) is the \emph{ppf} (quantile function) and \(\lambda\) is the number of wind speeds over the threshold per year.

The CRAN Task View ``Extreme Value Analysis'' \url{https://cran.r-project.org/web/views/ExtremeValue.html} shows available \textbf{R} for block maxima, POT by GPD, and external indexes estimation approaches. Most important to consider are \texttt{evd}, \texttt{extremes}, \texttt{evir}, \texttt{POT}, \texttt{extremeStat}, \texttt{ismev}, and \texttt{Renext}.

\hypertarget{pot-gpd}{%
\subsection{POT-GPD}\label{pot-gpd}}

Short description of POT-GPD (this section need to be complemented)

In POT-GPD, to calculate return levels (RL), \(Y_N\), corresponding to the N-years return period, next equation is used,

\[
Y_N =G\left(y, 1-\frac{1}{\lambda\,N}\right)
\]

Where \(G\) is the quantile function (\emph{ppf}), and the value of the probability passed to the \(G\) function, has to be modified with the \(\lambda\) parameter. \(\lambda\) is the number of wind speed events over the threshold per year.

\hypertarget{pot-pp}{%
\section{Peaks Over Threshold Poisson Process POT-PP}\label{pot-pp}}

According to Pintar et al. (\protect\hyperlink{ref-Pintar2015}{2015}) the stochastic Poisson Process - PP is mainly defined by its intensity function. As the intensity function is not uniform over the domain, the PP considered here is non-homogeneous, and due to the intensity function dependency of magnitude and time, it is also bi-dimensional. PP was described for the first time in Pickands (\protect\hyperlink{ref-Pickands1971}{1971}), then extended in Smith (\protect\hyperlink{ref-Smith1989}{1989}).
\begin{equation}
  \mathrm{
    \lambda\left(y,t\right)
    \begin{cases}
      \begin{split}
            &\lambda_t(y),\;for\,t\,in\,thunderstorm\,period
            \\
            &\lambda_nt(y),\;for\,t\,in\,non-thunderstorm\,period      
      \end{split}
    \end{cases}
  }
  \label{eq:ppgenericintensityfunction}
\end{equation}
Generic equation \eqref{eq:ppgenericintensityfunction} shows the intensity function, which is defined in the domain \(D = D_t\,{\cup}\,D_{nt}\), and allow to fit the PP at each station to the observed data \(\{t_i, y_i\}_{i=1}^I\), for all the times (\(t_i\)) of threshold crossing observations, and its corresponding wind speeds magnitudes (\(y_i\)). Thus, only data above the threshold (POT) are used.

Intensity function of the PP is defined in Smith (\protect\hyperlink{ref-Smith2004}{2004}),
\begin{equation}
  \mathrm{
    \frac{1}{\psi_t}\left(1+\zeta_t\frac{y-\omega_t}{\psi_t}\right)_+^{-\frac{1}{\zeta_t}-1}
  }
  \label{eq:ppintensityfunction}
\end{equation}
Where, at a given time \(t\), parameter \(shape = \zeta_t\) controls the tail length of the intensity function, and the other two parameters \(\omega_t\) and \(\psi_t\) define the location and scale of the intensity function.
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotdomainpp-1.pdf}
\caption{\label{fig:plotdomainpp}Domain off the Poisson Process - PP}
\end{figure}
Figure \ref{fig:plotdomainpp} represent the domain \(D\) of PP. In time, the domain represents the station service period from first sample \(t_1\) to last sample \(t_4\). \(D\) is the union of all thunderstorm periods \(D_t\) (from \(t_2\) to \(t_3\)), and all non-thunderstorm periods \(D_{nt}\) (periods \(t_1\) to \(t_2\) and \(t_3\) to \(t_4\)). In magnitude, only thunderstorm data above its threshold \(b_t\), and only non-thunderstorm data above its threshold \(b_{nt}\) are used.

Thunderstorms and non-thunderstorms are modeled independently:
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Observations in domain \(D\) follow a Poisson distribution with mean \(\int_D\lambda(t,y)\,dt\,dy\)
\item
  For each disjoint sub-domain \(D_1\) or \(D_2\) inside \(D\), the observations in \(D_1\) or \(D_2\) are independent random variables.
\end{enumerate}
Visual representation of the intensity function for PP can be seen in figure \ref{fig:plotdomain3dpp}. In vertical axis, two surfaces were drawn representing independent intensity functions for thunderstorm \(\lambda_t(y)\) and for non-thunderstorm \(\lambda_{nt}(y)\). The volume under each surface for its corresponding time periods and peak (over threshold) velocities, is the mean of PP.
\begin{figure}

{\centering \includegraphics[width=4.07in]{figure/domain3d} 

}

\caption{Volume under surfaces represents the mean of PP}\label{fig:plotdomain3dpp}
\end{figure}
To fit the intensity function to the data, the method of maximum likelihood is used to estimate its parameters, \(scale = \psi\), \(location = \omega\), and \(shape = \zeta\), the selected vector of parameters \(\eta\) are the \(\hat\eta = (\hat\psi, \hat\omega, \hat\zeta)\) values that maximizes next function
\begin{equation}
  \mathrm{
          L(\eta)=\left( 
                        \prod_{i=1}^I\lambda\left(y_i,t_i\right)  
                  \right)
                  \exp\left\{
                            -\int_{{D}}\lambda\left(y,t\right)dy\,dt
                     \right\}
         }
  \label{eq:pplikelihood}
\end{equation}
The values of \(\hat\eta\) need to be calculated using a numerical approach, because there is not analytical solution available.

Once the PP is fitted to the data, the model will provide extreme wind velocities (return levels), for different return periods (mean recurrence intervals).

A \(Y_N\) extreme wind velocity, called the return level (RL) belonging to the N-years return period, has a expected frequency to occur or to be exceeded (annual exceedance probability)\(P_e = \frac{1}{N}\), and also has a probability that the event does not occur (annual non-exceedance probability) \(P_{ne}=1-\frac{1}{N}\). \(Y_N\) will be the resulting value of the \(G\) (ppf or quantile) function using a probability equal to \(P_{ne}\). \(Y_N=quantile(y, p=P_{ne})=G(y,p=P_{ne})=ppf(y,p=P_{ne})\). \(Y_N\) can be understood as the wind extreme value expected to be exceeded on average once every N years.

For PP \(Y_N\) is the solution to the next equation, which is defined in terms of the intensity function,
\begin{equation}
  \mathrm{
          \int_{Y_N}^{\infty}\int_0^1\lambda\left( y,t\right)dydt = A_t\int_{Y_N}^{\infty}\lambda_t\left( y\right)\,dy + A_{nt}\int_{Y_N}^{\infty}\lambda_{nt}\left( y\right)\,dy = \frac{1}{N}
         }
  \label{eq:pprl}
\end{equation}
where \(A_t\), is the multiplication of the average number of thunderstorm per year and the average length of a thunderstorm, taken to be 1 hour as defined in Pintar et al. (\protect\hyperlink{ref-Pintar2015}{2015}), and \(A_{nt} = 365 - A_t\). The average length of a non-thunderstorm event is variable, and it is adjusted for each station to guarantee that \(A_{nt} + A_t = 365\). Value 365 is used only, if operations with time in the dataset are performed in days.

The same thunderstorm event in considered to occur if the time lag distance between successive thunderstorm samples is small than six hours, and for non-thunderstorm this time is 4 days. For PP, all the measurements belonging to the same event (thunderstorm or non-thunderstorm), need to be de-clustered to leave only one maximum value. In other words, the number of thunderstorm in the time series is one plus the number of time lag distances grater than 6 hours, and for non-thunderstorm grater than 4 days.

\hypertarget{thresholdselection}{%
\subsection{Threshold Selection}\label{thresholdselection}}

POT-PP needs selection of the best threshold pairs \(b_t\) and \(b_{nt}\) (see figure \ref{fig:plotdomainpp}) that produces the optimal fit. Measurement of this threshold fitting is done through \(W\) statistics. If wind variable \(Y\), in a POT-PP approach, has a \(cdf = U = F(Y)\), then \(F(Y)\) is distributed as Uniform between 0 and 1 - Uniform(0,1), meaning that the transformation \(W = -log(1-U)\) is an exponential random variable with mean one (1).
\begin{equation}
  \mathrm{
            cdf = U= F(Y) = P(Y \leq y) = \frac{\int_b^y\lambda(y,t)\,dy}{\int_b^\infty\lambda(y,t)\,dy} 
         }
  \label{eq:ppcdf}
\end{equation}
The procedure to choose the best thresholds pairs based in W transformation, is described in methodology, section \protect\hyperlink{thresholding}{thresholding}.

\hypertarget{windloadsrequirements}{%
\section{Wind Loads Requirements}\label{windloadsrequirements}}

As the output maps of this research will be used as input loads for infrastructure design, the methodology used for its creation, need to be consistent with Colombian official wind loads requirements. Colombian structure design code, from now the design standard, was created and it maintained by the Colombian Association of Seismic Engineering - AIS.

The design standard is mainly based in \emph{minimum design loads and associated criteria for buildings and other structures - ASCE7-16} norm, see Engineers (\protect\hyperlink{ref-Asce2017}{2017}). Under these circumstances, ASCE7-16 defines the minimum requirements of the research products. Especially the chapter C26 - ``wind loads - general requirements'', C26.5 ``wind hazard map'', and C26.7 ``Exposure'' - pages 733 to 747. Wind speeds requirements of ASCE7-16 are based in the combination of independent non-hurricane analysis, and hurricane wind speeds simulations models. The focus of this research will be the analysis of non-hurricane wind data, however, existing results of hurricane studies will be used to present final maps with both components. In ASCE7-16, for non-hurricane wind speed, the procedure is mainly based on Pintar et al. (\protect\hyperlink{ref-Pintar2015}{2015}).

ASCE7-16 (page 734), requires the calculation of wind extreme return levels for specific return periods according to the risk category of the structure to be designed: risk category I - 300 years, risk category II - 700 years, risk category III - 1700 years, risk category IV - 3000 years. The design standard only requires 700, 1700 and 3000 years. In addition, extreme wind speeds for those MRI need to correspond to: - 3 second gust speeds, - at 33 ft (10 meters) above the ground, and - exposure category C (open space).
\begin{itemize}
\tightlist
\item
  Risk IV - This are `indispensable buildings' that involve substantial risk. These structures that can handle toxic or explosive substances.
\item
  Risk III - There is substantial risk because these structures that can handle toxic or explosive substances, can cause a serious economical impact, or massive interruption of activities if they fail.
\item
  Risk II - Category `by default', and correspond to structures not classified in others categories.
\item
  Risk I - This structures represent low risk for life of people.
\end{itemize}
To standardize wind speeds to gust speeds ASCE7-16 proposes the curve Durst (see C. S. Durst (\protect\hyperlink{ref-Durst1960}{1960}), and figure \ref{fig:durstcurve}). Durst curve is only valid for open terrain conditions, and it shows in axis \(y\) the gust factor \(\frac{V_t}{V_{3600}}\), a ratio between any wind gust averaged at \(t\) seconds, \(V_t\), and the hourly averaged wind speed \(V_{3600}\), and in the axis \(x\) the duration \(t\) of the gust in seconds.
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/durstcurve-1.pdf}
\caption{\label{fig:durstcurve}Maximum speeds averaged over t (sec), to hourly mean speed. Note: curve values taken visually from the original (use original curve for calculations!)}
\end{figure}
\hypertarget{rmd-method}{%
\chapter{Methodology}\label{rmd-method}}

Figure \ref{fig:methodology} shows a graphic representation of the methodology. This research is focus in non-hurricane data, with three main elements: - data, - temporal analysis with a POT-PP, and - spatial analysis with probabilistic and deterministic methods to do spatial interpolation and create return levels (wind velocities) maps, for MRI of 700, 1700, and 3000 years. An additional element, is the integration with existing hurricane maps to produce final maps, that will be used as input loads for infrastructure design, and will be part of the design standard.

More representative and important steps of the methodology are identified by numbers in figure \ref{fig:methodology}, 1) standardization, 2) de-clustering, 3) thresholding, 4) fit intensity function, 5) hazard curve, 6) return levels, and 7) spatial interpolation. Steps 1 to 6, need to be done for each available station to get extreme wind velocities (return levels - RL) for MRI. With RL in each station, a continuous surface will be created, one for 700 years, next for 1700 years and finally for 3000 years. Figure \ref{fig:mainmethodology} schematize the iterative process in the methodology.
\begin{figure}

{\centering \includegraphics[width=6.26in]{figure/methodology} 

}

\caption{Methodology}\label{fig:methodology}
\end{figure}
\begin{figure}

{\centering \includegraphics[width=2.5in]{figure/main_methodology} 

}

\caption{Iterative process in methodology}\label{fig:mainmethodology}
\end{figure}
\hypertarget{rmd-standartization}{%
\section{Data Standardization}\label{rmd-standartization}}

Parallel to the standardization activity described below (3-s gust, roughness, and 10 meters anemometer height), it is also important to consider for all stations involved in the analysis:
\begin{itemize}
\item
  \emph{Separating}: As far as possible, identify each record of the time series, as thunderstorm (t) or non-thunderstorm (nt)
\item
  \emph{Filtering}: Remove wind speeds above \(200 \frac{Km}{h}\) and data pertaining to hurricane events, because the procedure with hurricane requires a different approach and need to be done independently
\item
  Downscaling approach: As it happens in this study, where it is intended to complement the local/regional wind analysis, with data from ISD (output data of a model for extreme winds), and ERA5 reanalysis dataset (large scale forecast data), it is required to probe by means of \emph{comparisons} (exploratory data analysis and statistical measures) that modeled or forecast data are suitable to complement the study.
\end{itemize}
\hypertarget{anemometer-height---10-m}{%
\subsection{Anemometer height - 10 m}\label{anemometer-height---10-m}}

According to the protocol for field data collection and location of methodological stations - IDEAM (\protect\hyperlink{ref-ideam2005}{2005}), the anemometer (wind sensor) in installed always to a fixed height of 10 meters from the surface, as is shown in figure \ref{fig:anemometer}, ergo, no height correction is needed.
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/anemometer-1} 

}

\caption{Anemometer height - 10 m}\label{fig:anemometer}
\end{figure}
\hypertarget{rmd-roughness}{%
\subsection{Surface Roughness at Open Terrain (0.03 m)}\label{rmd-roughness}}

Due to the effects that the terrain has on wind speed, a correction should be applied if the station is located in a geographical space considered ``not open terrain''. When terrain is open, the roughness corresponds to 0.03 meters. There are some alternative methodologies to calculate the roughness, Masters, Vickery, Bacon, \& Rappaport (\protect\hyperlink{ref-Masters2010}{2010}) uses the station data, but the separation of the measurements should not exceed one minute, something difficult to obtain, and Lettau (\protect\hyperlink{ref-Lettau1969}{1969}) uses an empirical equation that is recommended in Engineers (\protect\hyperlink{ref-Asce2017}{2017}) (page 743, equation C26.7-1), which was used here,

\[
Roughness = z_0= 0.5 * H_{ob}*\frac{S_{ob}}{A_{ob}}
\]
Where \(H_{ob}\) is the average height of the obstacles, \(S_{ob}\) is the average vertical area perpendicular to the wind of the obstacles, and \(A_{ob}\) is the average area of the terrain occupied by each obstruction. Then, the empirical exponent \(\alpha\), gradient height \(z_g\), and exposure coefficient \(K_z\), corresponding to equations C26.10-3, C26.10-4, and C26.10-1.si of Engineers (\protect\hyperlink{ref-Asce2017}{2017}), are used to calculate the correction factor \(F_{exposition}\), verifying that \(z_0\) units are in meters.

\[
\alpha =  5.65*z_0^{-0.133}
\]

\[
z_g=450*z_0^{0.125}
\]

\[
K_z= 2.01*\left(\frac{z}{z_g}\right)
\]

\[
F_{exposition} = \frac{0.951434}{K_z}
\]
Following NIST (\protect\hyperlink{ref-nist2012}{2012}), calculation of roughness need to be weighted according to the predominance of wind magnitude in eight directions (north, south, east, west, north-east, north-west, south-east, and south-west), see figure \ref{fig:compassrose}, using a detailed aerial photo or satellite image inside a radiuos of 800 meters around the station location, as shown in figure \ref{fig:lettaustation}, with south direction highlighted.
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/compassrose-1} 

}

\caption{Wind rose with wind percentages in eight directions, for a generic station}\label{fig:compassrose}
\end{figure}
\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/lettaustation2-1} 

}

\caption{Digital imagery for 'Vanguardia' ISD station (USAF:802340), located in Villavicencio airport. with four (south, north, east, and west) 45 degree sectors highlighted. Radious of the circular zone is 800 meters}\label{fig:lettaustation2}
\end{figure}
\normalsize

Figure \ref{fig:lettauexamples} shows extreme conditions for roughness, open space in left image (ISD Station 804070), closed space in center image (ISD Station 803000), and a typical example where Lettau procedure is needed. Lettau equation need to be applied to each direction and then the final \(z_o\) value is the weighted average, using historical wind percentage. See figure \ref{fig:lettauvalues} showing the strokes made to calculate the different areas for two Colombian stations. Information about wind percentage per direction at each station were obtained from IDEAM (\protect\hyperlink{ref-ideam1999}{1999}).
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/lettauexamples2-1} 

}

\caption{Roughness values: 0.03 for open space (left), 0.1 for closed space (center), and areas where Lettau equation is needed because roughness is different in each direction (right).}\label{fig:lettauexamples2}
\end{figure}
\begin{figure}

{\centering \includegraphics[width=3.71in]{figure/lettauvalues} 

}

\caption{Lettau calculation. In red the area occupied by the obstacles, and in blue the perpendicular area. Source Triana (2019)}\label{fig:lettauvalues}
\end{figure}
\hypertarget{rmd-gust}{%
\subsection{Averaging Time 3-s Gust}\label{rmd-gust}}

To transform hourly mean wind velocity \(V_{3600}\), to 3-s gust velocity \(V_3\), Engineers (\protect\hyperlink{ref-Asce2017}{2017}) recommends to use C. S. Durst (\protect\hyperlink{ref-Durst1960}{1960}). See \protect\hyperlink{windloadsrequirements}{Wind Loads Requirements}. As the axis \(x\) represents duration \(t\) of the gust, what is done is to look there for the value 3 seconds, and read the corresponding gust factor \(\frac{V_t}{V_{3600}}\), this is, the value in the axis \(y\), then

\[
V_t = V_{3\,seconds} = (gust factor) * V_{3600\,seconds}
\]

It is valid only for open terrain conditions. Durst curve shows in axis \(y\) the gust factor \(\frac{V_t}{V_{3600}}\), a ration between any wind gust averaged at \(t\) seconds, \(V_t\), and the hourly averaged wind speed \(V_{3600}\), and in the axis \(x\) the duration \(t\) of the gust in seconds.

\hypertarget{peaks-over-threshold---poisson-process-pot-pp}{%
\section{Peaks Over Threshold - Poisson Process (POT-PP)}\label{peaks-over-threshold---poisson-process-pot-pp}}

Similar to how the adjustment of statistical data to a normal distribution works in order to make inferences considering deviations from the mean, here only some part of the data (those that are extreme - over a high threshold - POT), need to be fitted to a PP considering extreme deviations from the mean. While in the first case (normal distribution) the inferences are for events similar to the samples, in this case, when working with extreme value theory, the inferences will be for more extreme events than any previously observed or measured. In the \protect\hyperlink{rmd-thefra}{theoretical framework} section are described the main elements of \protect\hyperlink{pot-pp}{POT-PP}.

In summary, POT means only to work with extreme values, and PP means to adjust data to a \emph{pdf}, which depends on an intensity function \(\lambda(t,y)\), where \(t\) is time, \(y\) is wind extreme velocity. As is shown in figure \ref{fig:plotdomainpp}, in a POT-PP approach with domain \(D\), all the observations follow a Poisson distribution with mean \(\int_D\lambda(t,y)\,dt\,dy\). Main advantage of POT-PP is that it is designed to consider storm and not-storm events independently (for each disjoint sub-domain \(D_1\) or \(D_2\) inside \(D\), the observations in \(D_1\) or \(D_2\) are independent random variables), but in the end use them both for the inferences,
\begin{equation}
  \mathrm{
          pdf = f(t,y|\eta) = \frac{\lambda(t,y)}{\int_D\lambda(t,y)\,dt\,dy}
        }
  \label{eq:pppdf}
\end{equation}
\hypertarget{de-clustering}{%
\subsection{De-clustering}\label{de-clustering}}

To make the assumptions of PP more justifiable, it is important to have only one sample per event, the highest one. For instance, if a hypothetical storm started at 11:30 in the morning and ended at 12:30 in the afternoon, and the time series for that event has thirty wind measurements (one each two minutes), it is necessary to leave only the stronger or maximum value, and this process is called de-clustering (see Figure \ref{fig:declustering}). POT-PP defines that all the adjacent observations separated by six hours (6) or less in the case of thunderstorm events, and four (4) days or less, in the case of non-thunderstorm events belong to the same cluster.

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/declustering-1} 

}

\caption{De-clustering in PP. Two thunderstorm clusters are shown. Separation between adjacent observations inside the clusters are always equal or less than six hours. Distance between the last event in the first cluster and the first event in the second cluster is larger than six hours. Only red samples are used to fit the PP, but in addition a POT (thresholding) process is needed}\label{fig:declustering}
\end{figure}
\normalsize

\hypertarget{thresholding}{%
\subsection{Thresholding}\label{thresholding}}

As the POT model requires to work only with the most extreme values in the time series, it is necessary to select a threshold to filter out small values. Selection of threshold value imply two effects in the model. Bias is high when a low threshold is selected (many exceedances) because the asymptotic support is weak. Opposite situation happens for high thresholds where variance is potentially high, so according to Davison \& Smith (\protect\hyperlink{ref-Davison1990}{1990}), it is needed to select a threshold value, consistent with model structure.

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/thresholding-1} 

}

\caption{POT - Thresholding}\label{fig:thresholding}
\end{figure}
\normalsize

Selection of the thresholds pairs, one for thunderstorm, and one for non-thunderstorm, is based in \(W\) transformation described in \protect\hyperlink{thresholdselection}{threshold selection section}. W-statistic is done comparing the ordered empirical result of applying \(W = -log(1-U)\) to the data, axis \(y\) in figure \ref{fig:wstatistics}, with the theoretical quantiles of an exponential variable with uniform distribution between 0 and 1, axis \(x\) in same figure. W-statistic is the highest vertical distance between the 45º line and the points in the graphic. The best thresholds pairs returns the minimum value for W-statistics after testing, in an iterative process, with many threshold pairs combinations.

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/wstatistics-1} 

}

\caption{POT - Thresholding}\label{fig:wstatistics}
\end{figure}
\normalsize

\hypertarget{exclude-no-data-periods}{%
\subsection{Exclude no-data periods}\label{exclude-no-data-periods}}

PP requires to remove long periods of time when stations were not recording or failing. Proposed time in Pintar et al. (\protect\hyperlink{ref-Pintar2015}{2015}) is 180 days, namely, to remove all the gaps from the time series larger than six months.

\hypertarget{fit-intensity-function}{%
\subsection{Fit Intensity Function}\label{fit-intensity-function}}

Probability density function \emph{pdf}, and cumulative distribution function \emph{cdf}, of the PP, depend of the intensity function, and are shown in equation \eqref{eq:pppdf}, and equation \eqref{eq:ppcdf}, respectively.

To facilitate the estimation of the parameters for the PP intensity function, parameter \(shape = \zeta_t\) is taken to be zero in equation \eqref{eq:ppintensityfunction}, then doing the limit, the resulting intensity function is the same as the the GEV type I or Gumbel distribution,
\begin{equation}
  \mathrm{
          \frac{1}{\psi_t}\exp\left\{\frac{-(y-\omega_t)}{\psi_t}\right\}
         }
  \label{eq:ppusedif}
\end{equation}
In this study, the used intensity functions are shown in next equation \eqref{eq:ppspecificintensityfunction}.
\begin{equation}
  \mathrm{
    \lambda\left(y,t\right)
    \begin{cases}
      \begin{split}
            &\frac{1}{\psi_s}\exp\left(\frac{-(y-\omega_s)}{\psi_s}\right),\;for\;t\;in\;thunderstorm\;period
            \\
            &\frac{1}{\psi_{nt}}\exp\left(\frac{-(y-\omega_{nt})}{\psi_{nt}}\right),\;for\;t\;in\;non\-thunderstorm\;period      
      \end{split}
    \end{cases}
  }
  \label{eq:ppspecificintensityfunction}
\end{equation}
As is shown in \ref{fig:fitif}, the fitting process involve finding the best group of parameters of the intensity function, in such a way that the red curve (\emph{pdf} of the PP, based in intensity function) be as tight as possible to the shape of the data histogram. As is described in \protect\hyperlink{pot-pp}{POT-PP}, optimal parameters to do the fitting process of the intensity function are calculated using \emph{maximum likelihood}.

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/fitif-1} 

}

\caption{POT - PP intensity function fitting process}\label{fig:fitif}
\end{figure}
\normalsize

\hypertarget{hazard-curve---return-levels---rl}{%
\subsection{Hazard Curve - Return Levels - RL}\label{hazard-curve---return-levels---rl}}

If equation \eqref{eq:pprl}, \(Y_N\) is solved using estimated parameters of the intensity function, and a hazard curve is constructed as shown in figure \ref{fig:hc}, where axis \(x\) represents annual exceedance probability \(P_e = \frac{1}{N}\), and axis \(y\) represents the RL \(Y_N\) for the corresponding N-years return period, then it will be possible to have the extreme return wind velocity level for any given return period going from axis \(x\) to axis \(y\) through the curve.

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/hc-1} 

}

\caption{POT - PP fitting process}\label{fig:hc}
\end{figure}
\normalsize

\hypertarget{two-alternatives-approaches-for-rl}{%
\subsubsection{Two alternatives approaches for RL}\label{two-alternatives-approaches-for-rl}}

There is an equation that allows direct calculations of return levels, and also it is possible to use the quantile function of Gumbel when shape parameter equals to zero, but it is important to emphasize that equation \eqref{eq:pprv}, and the use of Gumbel quantile function for RL calculations, is only valid when the analysis of POT-PP includes only one type of event (thunderstorm or non-thunderstorm), and the average estimated duration time of the event in a year is considered to be one (independent of the units in which time is processed), namely, the values for parameters \(A_t\) or \(A_{nt}\) of equation \eqref{eq:pprl} are equal to one.

Instead of solving equation \eqref{eq:pprl}, next equation \eqref{eq:pprv} can be used replacing directly the PP parameters and the N return periods to create the hazard curve and get RL.
\begin{equation}
  \mathrm{
Y_N=\frac{\psi}{\zeta}\left[-log\left(\frac{N-1}{N}\right)\right]^{-\zeta}-\frac{\psi}{\zeta}+\omega
        }
  \label{eq:pprv}
\end{equation}
As for this research \(\zeta = 0\), return levels \(Y_N\) can be calculated using the Gumbel quantile function, but using \((1-\frac{1}{N})\) as probability.

\hypertarget{spatial-interpolation}{%
\section{Spatial Interpolation}\label{spatial-interpolation}}

Probabilistic (Kriging) and deterministic (IDW, local polynomials) techniques are used to create maps for return levels with same return period. Interpolation with Kriging requires verification of minimum procedures to ensure proper use of the method, for instance,
\begin{itemize}
\item
  Structural analysis, which includes data normality check, for example, with Kolmogorov Smirnov or Shapiro Wilk goodness of fit tests, and if needed, data transformation to ensure data normality, e.g.~using Box-Cox, and in addition, trend analysis to verify the need for trend modeling, in subsequent steps
\item
  Semivariance Analysis: Use of available tools like cloud semivariogram, experimental semivariogram, directional semivariograms to verify isotropy or anisotropy, and different theoretical semivariograms, to ensure the best model of spatial autocorrelation, as a preliminary step to interpolation.
\item
  Kriging Predictions: Use of different types of Kriging predictors, like simple, ordinary, universal, based on the results of the structural analysis.
\item
  Cross Validation: Use of statistics like root mean square, average standard error, mean standardized, and root mean square standardized, that allow to measure the quality of the predictions and the magnitude of the errors.
\end{itemize}
Possible advantage of deterministic methods, is a better assessment of the local variability of spatial autocorrelation. It can also be considered with IDW or local polynomials a detailed assessment of structural analysis and cross validation. At the end of the spatial interpolation analysis all the predictions can be compared to select the most suitable result.

\hypertarget{integration-with-non-hurricane-data}{%
\section{Integration with Non-Hurricane data}\label{integration-with-non-hurricane-data}}

Engineers (\protect\hyperlink{ref-Asce2017}{2017}) propose the equation C26.5-2 for combination of statistically independent events, of non-hurricane and hurricane wind speed data.
\begin{equation}
  \mathrm{
          P_e(y>Y_N) = 1 - P_{NH}(y<Y_N)*P_{H}(y<Y_N)
        }
  \label{eq:combination}
\end{equation}
Where \(P_e(y>Y_N)\) is the annual exceedance probability for the combined wind hazards, \(P_{NH}(y<Y_N)\) is the annual non-exceedance probability for non-hurricane winds, and \(P_{H}(y<Y_N)\) is the annual non-exceedance probability for hurricane winds.

To understand equation \eqref{eq:combination}, it is important to remember that to calculate return level \(Y_N\), for a given N-year return period, the exceedance probability \(\frac{1}{N}\) of \(Y_N\) is calculated. Then, the non-exceedance probability for \(Y_N\) is \(\left(1-\frac{1}{N}\right)\). The procedure consist in the creation of a new hazard curve, calculating all \(P_e(y>Y_N)\) values for different \(Y_N\) return levels, combining hazard curves from non-thunderstorm and thunderstorm data.

After the combined hazard curve is created, a new process of spatial interpolation need to be accomplished. In case of absence of hazard curves for stations, but availability of return levels maps, it becomes necessary to recreate hazard curves cell by cell, to apply equation \eqref{eq:combination}. In this case are required as many maps as possible for different return periods, in order to estimate detailed enough hazard curves from return level values (cell values).

\hypertarget{rmd-results}{%
\chapter{Results}\label{rmd-results}}

In this section, will be shown first, the data source comparison to face the downscaling issue by using ERA5 and ISD database, then, the resulting process of fitting a POT-PP in the station 801120, which includes revision of intensity function parameters, goodness of fit, hazard curve, return levels, and comparison with POT-GPD results, next, non-hurricane maps outputs, which includes results for ISD and ERA5 stations, using POT-PP and POT-GPD approaches, and finally, output maps combining hurricane and non-hurricane results will be displayed.

\hypertarget{data-standardization-and-downscaling-support}{%
\section{Data Standardization and Downscaling Support}\label{data-standardization-and-downscaling-support}}

Looking for a statistical justification in the use of ISD (model) and ERA5 databases (forecast), as input data for this study, and considering the \emph{downscaling approach} described in the \protect\hyperlink{rmd-standartization}{standartization process} section of methodology, data sources ISD and IDEAM were standardized to enable comparison. Standardization consisted of transforming the data to be equivalent to 3-s gust \(V_3\), 10 meters anemometer height, and open space roughness. In the comparison process, for coincident stations by spatial location, it was checked if the velocity values (standardized) in the three sources, for equal dates, were similar in magnitude.

\hypertarget{data-standardization-1}{%
\subsection{Data Standardization}\label{data-standardization-1}}

None of the sources required anemometer height standardization. Lettau (\protect\hyperlink{ref-Lettau1969}{1969}) was used for roughness standardization of ISD and IDEAM, applying the method station by station. Gust velocities standardization was done using Durst cuve, and in order to obtain \(V_3\) from Durst curve, it is required to start from \(V_{3600}\) (average hourly speed), or from a different wind gust speed, for instance \(V_5\).

For ERA5:
\begin{itemize}
\tightlist
\item
  Variable \emph{10m wind gust - 10fg} of ERA5 data source does not need any standardization, because it comes standardized from the source
\end{itemize}
For ISD:
\begin{itemize}
\item
  Wind velocity from ISD comes from source as \(V_5\), that is, five seconds gust wind velocity. To standardize from \(V_5\) to \(V_3\), using Durst curve, the correction factor is 1.03.
\item
  Wind velocity \(V_5\) from 74 ISD stations, was standardized station by station, using procedure described in \protect\hyperlink{rmd-roughness}{Surface Roughness at Open Space} section, and \protect\hyperlink{rmd-gust}{Averaging Time 3-s Gust} section
\end{itemize}
For IDEAM:
\begin{itemize}
\item
  As the original variables obtained from IDEAM, do not represent gust speeds, it is necessary to start from \emph{average hourly speed} \(V_{3600}\), to obtain 3-s gust \(V_3\). To standardize from \(V_{3600}\) to \(V_3\), using Durst curve, the correction factor is 1.51.
\item
  It was not possible to obtain the \emph{average hourly speed} \(V_{3600}\) from IDEAM, see table \ref{tab:tabledatasources2}, but from \emph{instantaneous wind velocity each 2 minutes - VV\_AUT\_2} it is possible to obtain a \textbf{good} estimator of \(V_{3600}\), and from \emph{instantateous wind velocity each 10 minutes - VV\_AUT\_10} it is possible to obtain a \textbf{poor} estimator of \(V_{3600}\).
\end{itemize}
\hypertarget{data-comparison}{%
\subsection{Data Comparison}\label{data-comparison}}

The available IDEAM data allowed two comparison processes, with quality data for a few stations, and with low quality data, but available for all stations.

In both cases, to make the use of ISD and ERA5 viable, its time series are expected to be as similar as possible to IDEAM. To verify this, two types of graphics were constructed:
\begin{itemize}
\item
  Time series overlay for the three sources. Not very effective method due to the large amount of data that makes the graphics unreadable.
\item
  Scatter plot maps comparing two different sources. Matching values by time, were sorted in ascending order and put together on a scatter plot. The expected behavior in case of similarity in the data, is that all the points fall in a \(45^\circ\) line
\end{itemize}
\hypertarget{quality-data-available-in-some-ideam-stations}{%
\subsubsection{Quality data available in some IDEAM stations}\label{quality-data-available-in-some-ideam-stations}}

IDEAM VV\_AUT\_2 was available for twenty (20) stations, of which only twelve (12) were \emph{perfectly equivalent} to ISD stations (see table \ref{tab:table12stations}). VV\_AUT\_2 dataset was transformed to \(V_{3600}\) (average hourly speed), averaging all 20 values available per hour. For twelve matching stations, wind velocity \(V_{3600}\) (transformation of VV\_AUT\_2), was standardized station by station, using procedure described in \protect\hyperlink{rmd-roughness}{Surface Roughness at Open Space} section and \protect\hyperlink{rmd-gust}{Averaging Time 3-s Gust}, and finally, for the same twelve ISD and IDEAM standardized stations, a comparison was done against matching ERA5 stations (the corresponding cell in ERA5 that has within ISD and IDEAM locations).

\begingroup\fontsize{10}{12}\selectfont
\begin{longtable}[t]{>{\raggedright\arraybackslash}p{0.6in}>{\raggedright\arraybackslash}p{0.6in}>{\raggedright\arraybackslash}p{2.7in}}
\caption[Twelve equivalent stations from ISD, IDEAM and ERA5]{\label{tab:table12stations}Equivalent stations from ISD and IDEAM and ERA5, representing the same weather station in the field}\\
\toprule
\multicolumn{1}{l}{ISD ID} & \multicolumn{1}{l}{IDEAM ID} & \multicolumn{1}{l}{ERA5 ID}\\
\midrule
803980 & 48015050 & 3320. Col:37. Row:68. Lon:-70. Lat:-4.25\\
803700 & 52055230 & 2309. Col:6. Row:48. Lon:-77.75. Lat:0.75\\
802110 & 26125061 & 1582. Col:14. Row:33. Lon:-75.75. Lat:4.5\\
802100 & 26125710 & 1533. Col:14. Row:32. Lon:-75.75. Lat:4.75\\
801120 & 23085270 & 1240. Col:15. Row:26. Lon:-75.5. Lat:6.25\\
\addlinespace
801100 & 27015330 & 1240. Col:15. Row:26. Lon:-75.5. Lat:6.25\\
800970 & 16015501 & 909. Col:27. Row:19. Lon:-72.5. Lat:8\\
800940 & 23195502 & 1102. Col:24. Row:23. Lon:-73.25. Lat:7\\
800630 & 13035501 & 749. Col:14. Row:16. Lon:-75.75. Lat:8.75\\
800360 & 28025502 & 416. Col:24. Row:9. Lon:-73.25. Lat:10.5\\
\addlinespace
800350 & 15065180 & 221. Col:25. Row:5. Lon:-73. Lat:11.5\\
800280 & 29045190 & 312. Col:18. Row:7. Lon:-74.75. Lat:11\\
\bottomrule
\end{longtable}
\endgroup{}

Stations 28025502 from IDEAM, 800360 from ISD, and 416 (cell with center point in \(-73.25^\circ\) longitude, and \(10.5^\circ\) latitude) from ERA5, showed high correspondence. See figures \ref{fig:sideamera5}. Unfortunately, in the other eleven stations, there was no high equivalence between sources.
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/qualitycomparison2-1.pdf}
\caption{\label{fig:qualitycomparison2}Quality Data Comparison
Left: Twelve matching stations
from IDEAM and ISD. Right: Stations 28025502 from IDEAM, 800360 from ISD, and 416 from ERA5}
\end{figure}
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/sideamera5-1} 

}

\caption{Scatter plot of IDEAM vs ERA5. Stations comparison: 28025502 (IDEAM), and 416 (ERA5)}\label{fig:sideamera5}
\end{figure}
\hypertarget{poor-data-available-in-all-ideam-stations}{%
\subsubsection{Poor data available in all IDEAM stations}\label{poor-data-available-in-all-ideam-stations}}

VV\_AUT\_10 was available for 204 stations, and despide that \(V_{3600}\) calculated from this source, is not an accurate or quality estimator, the standarization process was done to allow a comparison process.
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/poorcomparison-1.pdf}
\caption{\label{fig:poorcomparison}`Poor Data' Comparison: ERA5 vs ISD vs IDEAM. Downscaling Support: `Good' in 23 ERA5 stations (2261, 1971, 2066, 2020, 2260, 1875, 2213, 2637, 1442, 1583, 1501, 1582, 1381, 1493, 1485, 1397, 1338, 1055, 511, 1644, 515, 221, 1038), and `Very Good' in 5 (265, 360, 78, 312, 416)}
\end{figure}
\hypertarget{pot-pp-in-isd-station-801120}{%
\section{POT-PP in ISD Station 801120}\label{pot-pp-in-isd-station-801120}}

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/page1-1} 

}

\caption{Time Series ISD. Station 801120}\label{fig:page1}
\end{figure}
\normalsize

\hypertarget{w-statiscis-plot}{%
\subsection{W-statiscis Plot}\label{w-statiscis-plot}}

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/page6-1} 

}

\caption{W-Statiscics Plot. Best Threshold Pair. Station 801120}\label{fig:page6}
\end{figure}
\normalsize

\hypertarget{parameters}{%
\subsection{Parameters}\label{parameters}}

\hypertarget{fitted-pdf-and-cdf}{%
\subsection{Fitted pdf and cdf}\label{fitted-pdf-and-cdf}}

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/page7-1} 

}

\caption{pdf POT-PP. Station 801120}\label{fig:page7}
\end{figure}
\normalsize

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/page9-1} 

}

\caption{cdf POT-PP. Station 801120}\label{fig:page9}
\end{figure}
\normalsize

\hypertarget{goodness-of-fit}{%
\subsection{Goodness of Fit}\label{goodness-of-fit}}

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/page8-1} 

}

\caption{Graphic Diagnosis Of Goodness of Fit. Station 801120}\label{fig:page8}
\end{figure}
\normalsize

\hypertarget{hazard-curve-and-return-levels}{%
\subsection{Hazard Curve and Return Levels}\label{hazard-curve-and-return-levels}}

\footnotesize
\begin{figure}

{\centering \includegraphics{thesis_files/figure-latex/page10-1} 

}

\caption{Hazard Curve. Station 801120}\label{fig:page10}
\end{figure}
\normalsize

\hypertarget{comparison-with-pot-gpd}{%
\subsection{Comparison with POT-GPD}\label{comparison-with-pot-gpd}}

\hypertarget{non-hurricane-maps}{%
\section{Non-Hurricane Maps}\label{non-hurricane-maps}}

\hypertarget{isd-1}{%
\subsection{ISD}\label{isd-1}}

\hypertarget{pot-pp-1}{%
\subsubsection{POT-PP}\label{pot-pp-1}}

\hypertarget{pot-gpd-1}{%
\subsubsection{POT-GPD}\label{pot-gpd-1}}

\hypertarget{era5-1}{%
\subsection{ERA5}\label{era5-1}}

\hypertarget{pot-pp-2}{%
\subsubsection{POT-PP}\label{pot-pp-2}}

\hypertarget{pot-gpd-2}{%
\subsubsection{POT-GPD}\label{pot-gpd-2}}

\hypertarget{hurricane-and-non-hurricane-maps}{%
\section{Hurricane and Non-Hurricane Maps}\label{hurricane-and-non-hurricane-maps}}

\hypertarget{isd-2}{%
\subsection{ISD}\label{isd-2}}

\hypertarget{pot-pp-3}{%
\subsubsection{POT-PP}\label{pot-pp-3}}

\hypertarget{pot-gpd-3}{%
\subsubsection{POT-GPD}\label{pot-gpd-3}}

\hypertarget{era5-2}{%
\subsection{ERA5}\label{era5-2}}

\hypertarget{pot-pp-4}{%
\subsubsection{POT-PP}\label{pot-pp-4}}

\hypertarget{pot-gpd-4}{%
\subsubsection{POT-GPD}\label{pot-gpd-4}}

\hypertarget{rmd-discussion}{%
\chapter{Discussion}\label{rmd-discussion}}

\hypertarget{conclusion}{%
\chapter*{Conclusion}\label{conclusion}}
\addcontentsline{toc}{chapter}{Conclusion}

\appendix

\hypertarget{r-code}{%
\chapter{R Code}\label{r-code}}

\backmatter

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\noindent

\setlength{\parindent}{-0.20in}
\setlength{\leftskip}{0.20in}
\setlength{\parskip}{8pt}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-Coles2001}{}%
Coles, S. (2001). \emph{An introduction to statistical modeling of extreme values}. Springer London. \url{http://doi.org/10.1007/978-1-4471-3675-0}

\leavevmode\hypertarget{ref-Durst1960}{}%
C. S. Durst, B. A., O. B.E. (1960). Wind speeds over short periods of time. \emph{The Meteorological Magazine}, \emph{89}(1056), 181--187. Retrieved from \url{https://www.depts.ttu.edu/nwi/Pubs/ReportsJournals/ReportsJournals/Windspeeds.pdf}

\leavevmode\hypertarget{ref-Davison1990}{}%
Davison, A. C., \& Smith, R. L. (1990). Models for exceedances over high thresholds. \emph{Journal of the Royal Statistical Society. Series B (Methodological)}, \emph{52}(3), 393--442. Retrieved from \url{http://www.jstor.org/stable/2345667}

\leavevmode\hypertarget{ref-Asce2017}{}%
Engineers, A. S. O. C. (2017). \emph{Minimum design loads and associated criteria for buildings and other structures (asce7-16)}. American Society of Civil Engineers. Retrieved from \url{https://www.ebook.de/de/product/35017614/american_society_of_civil_engineers_minimum_design_loads_and_associated_criteria_for_buildings_and_other_structures_7_16.html}

\leavevmode\hypertarget{ref-Harris1994}{}%
Harris, J. W., \& Stocker, H. (1998). Maximum likelihood method. In \emph{Handbook of mathematics and computational science} (p. 824). Springer-Verlag.

\leavevmode\hypertarget{ref-Hosking1997}{}%
Hosking, J. R. M., \& Wallis, J. R. (1997). \emph{Regional frequency analysis}. Cambridge University Press. \url{http://doi.org/10.1017/cbo9780511529443}

\leavevmode\hypertarget{ref-ideam1999}{}%
IDEAM. (1999, June). Aeronautical information. Annual wind regime. Web Page. Retrieved from \url{http://bart.ideam.gov.co/cliciu/rosas/viento.htm}

\leavevmode\hypertarget{ref-ideam2005}{}%
IDEAM. (2005). \emph{Protocolo toma de datos de campo y emplazamiento de estaciones meteorológicas}.

\leavevmode\hypertarget{ref-Kubler1994}{}%
Kubler, J. (1994). \emph{Computational Statistics \&Amp; Data Analysis}, \emph{18}(4), 473--474. Retrieved from \url{https://EconPapers.repec.org/RePEc:eee:csdana:v:18:y:1994:i:4:p:473-474}

\leavevmode\hypertarget{ref-Lettau1969}{}%
Lettau, H. (1969). Note on aerodynamic roughness-parameter estimation on the basis of roughness-element description. \emph{Journal of Applied Meteorology}, \emph{8}(5), 828--832. \url{http://doi.org/10.1175/1520-0450(1969)008\%3C0828:NOARPE\%3E2.0.CO;2}

\leavevmode\hypertarget{ref-Masters2010}{}%
Masters, F. J., Vickery, P. J., Bacon, P., \& Rappaport, E. N. (2010). Toward objective, standardized intensity estimates from surface wind speed observations. \emph{Bulletin of the American Meteorological Society}, \emph{91}(12), 1665--1682. \url{http://doi.org/10.1175/2010bams2942.1}

\leavevmode\hypertarget{ref-nist2012}{}%
NIST. (2012, February). Standardized extreme wind speed database for the united states. Web Page. Retrieved from \url{https://www.itl.nist.gov/div898/winds/NIST_TN/nist_tn.htm}

\leavevmode\hypertarget{ref-Pickands1971}{}%
Pickands, J. (1971). The two-dimensional poisson process and extremal processes. \emph{Journal of Applied Probability}, \emph{8}(4), 745--756. \url{http://doi.org/10.2307/3212238}

\leavevmode\hypertarget{ref-Pintar2015}{}%
Pintar, A. L., Simiu, E., Lombardo, F. T., \& Levitan, M. L. (2015). \emph{Simple guide for evaluating and expressing the uncertainty of NIST MeasuremenMaps of non-hurricane non-tornadic wind speeds with specified mean recurrence intervals for the contiguous united states using a two-dimensional poisson process extreme value model and local regressiont results}. National Institute of Standards; Technology.

\leavevmode\hypertarget{ref-Simiu1996}{}%
Simiu, E., \& Scanlan, R. H. (1996). \emph{Wind effects on structures : Fundamentals and applications to design} (3rd ed.). New York : John Wiley. Retrieved from \url{http://lib.ugent.be/catalog/rug01:001267836}

\leavevmode\hypertarget{ref-Smith1989}{}%
Smith, R. L. (1989). Extreme value analysis of environmental time series: An application to trend detection in ground-level ozone. \emph{Statistical Science}, \emph{4}(4), 367--377. \url{http://doi.org/10.1214/ss/1177012400}

\leavevmode\hypertarget{ref-Smith2004}{}%
Smith, R. L. (2004). Extreme values in finance, telecommunications, and the environment (chapman \& hall/crc monographs on statistics and applied probability). In B. F. inkenstädt \& H. Rootzén (Eds.), (pp. 1--78). Chapman; Hall/CRC. Retrieved from \url{https://www.amazon.com/Telecommunications-Environment-Monographs-Statistics-Probability/dp/1584884118?SubscriptionId=AKIAIOBINVZYXZQZ2U3A\&tag=chimbori05-20\&linkCode=xm2\&camp=2025\&creative=165953\&creativeASIN=1584884118}


% Index?

\end{document}
