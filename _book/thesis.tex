% This is the Reed College LaTeX thesis template. Most of the work
% for the document class was done by Sam Noble (SN), as well as this
% template. Later comments etc. by Ben Salzberg (BTS). Additional
% restructuring and APA support by Jess Youngberg (JY).
% Your comments and suggestions are more than welcome; please email
% them to cus@reed.edu
%
% See http://web.reed.edu/cis/help/latex.html for help. There are a
% great bunch of help pages there, with notes on
% getting started, bibtex, etc. Go there and read it if you're not
% already familiar with LaTeX.
%
% Any line that starts with a percent symbol is a comment.
% They won't show up in the document, and are useful for notes
% to yourself and explaining commands.
% Commenting also removes a line from the document;
% very handy for troubleshooting problems. -BTS

% As far as I know, this follows the requirements laid out in
% the 2002-2003 Senior Handbook. Ask a librarian to check the
% document before binding. -SN

%%
%% Preamble
%%
% \documentclass{<something>} must begin each LaTeX document
\documentclass[12pt,twoside]{reedthesis}
% Packages are extensions to the basic LaTeX functions. Whatever you
% want to typeset, there is probably a package out there for it.
% Chemistry (chemtex), screenplays, you name it.
% Check out CTAN to see: http://www.ctan.org/
%%
\usepackage{graphicx,latexsym}
\usepackage{amsmath}
\usepackage{amssymb,amsthm}
\usepackage{longtable,booktabs,setspace}
\usepackage{chemarr} %% Useful for one reaction arrow, useless if you're not a chem major
\usepackage[hyphens]{url}
\usepackage[utf8]{inputenc}
% Added by CII
\usepackage{hyperref}
\usepackage{lmodern}
\usepackage{float}
\floatplacement{figure}{H}
% End of CII addition
\usepackage{rotating}

% Next line commented out by CII
%%% \usepackage{natbib}
% Comment out the natbib line above and uncomment the following two lines to use the new
% biblatex-chicago style, for Chicago A. Also make some changes at the end where the
% bibliography is included.
%\usepackage{biblatex-chicago}
%\bibliography{thesis}


% Added by CII (Thanks, Hadley!)
% Use ref for internal links
\renewcommand{\hyperref}[2][???]{\autoref{#1}}
\def\chapterautorefname{Chapter}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}
% End of CII addition

% Added by CII
\usepackage{caption}
\captionsetup{width=5in}
% End of CII addition

% \usepackage{times} % other fonts are available like times, bookman, charter, palatino

% Syntax highlighting #22
  \usepackage{color}
  \usepackage{fancyvrb}
  \newcommand{\VerbBar}{|}
  \newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
  % Add ',fontsize=\small' for more characters per line
  \usepackage{framed}
  \definecolor{shadecolor}{RGB}{248,248,248}
  \newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
  \newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
  \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
  \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\BuiltInTok}[1]{#1}
  \newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
  \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
  \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
  \newcommand{\ExtensionTok}[1]{#1}
  \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\ImportTok}[1]{#1}
  \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\NormalTok}[1]{#1}
  \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
  \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
  \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
  \newcommand{\RegionMarkerTok}[1]{#1}
  \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

% To pass between YAML and LaTeX the dollar signs are added by CII
\title{Spatio temporal analysis of extreme wind velocities for infrastructure desing. Case study Colombia}
\author{Alexys Herleym Rodríguez Avellaneda}
% The month and year that you submit your FINAL draft TO THE LIBRARY (May or December)
\date{Jan 2020}
\division{Instituto for Geoinformatics - IFGI}
\advisor{Dr.~Edzer Pebesma}
\institution{University of Münster}
\degree{Master of Science in Geospatial Technologies}
%If you have two advisors for some reason, you can use the following
% Uncommented out by CII
\altadvisor{Dr.~Juan C. Reyes\textbackslash Dr.~Sara Ribero}
% End of CII addition

%%% Remember to use the correct department!
\department{Faculty of Geosciences}
% if you're writing a thesis in an interdisciplinary major,
% uncomment the line below and change the text as appropriate.
% check the Senior Handbook if unsure.
%\thedivisionof{The Established Interdisciplinary Committee for}
% if you want the approval page to say "Approved for the Committee",
% uncomment the next line
%\approvedforthe{Committee}

% Added by CII
%%% Copied from knitr
%% maxwidth is the original width if it's less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\renewcommand{\contentsname}{Table of Contents}
% End of CII addition

\setlength{\parskip}{0pt}

% Added by CII

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\Acknowledgements{
I want to thank a few people.
}

\Dedication{
You can have a dedication here if you wish.
}

\Preface{
This is an example of a thesis setup to use the reed thesis document class
(for LaTeX) and the R bookdown package, in general.
}

\Abstract{
The preface pretty much says it all.

\par

Second paragraph of abstract starts here.
}

	\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
% End of CII addition
%%
%% End Preamble
%%
%
\begin{document}

% Everything below added by CII
  \maketitle

\frontmatter % this stuff will be roman-numbered
\pagestyle{empty} % this removes page numbers from the frontmatter
  \begin{acknowledgements}
    I want to thank a few people.
  \end{acknowledgements}
  \begin{preface}
    This is an example of a thesis setup to use the reed thesis document class
    (for LaTeX) and the R bookdown package, in general.
  \end{preface}
  \hypersetup{linkcolor=black}
  \setcounter{tocdepth}{2}
  \tableofcontents

  \listoftables

  \listoffigures
  \begin{abstract}
    The preface pretty much says it all.
    
    \par
    
    Second paragraph of abstract starts here.
  \end{abstract}
  \begin{dedication}
    You can have a dedication here if you wish.
  \end{dedication}
\mainmatter % here the regular arabic numbering starts
\pagestyle{fancyplain} % turns page numbering back on

\hypertarget{introduction}{%
\chapter*{Introduction}\label{introduction}}
\addcontentsline{toc}{chapter}{Introduction}

This research aims to create non-hurricane non-tornadic maps of extreme wind speeds for \emph{three specific recurrence intervals} (700, 1700, and 3000 years) covering the Colombian territory. These maps will be combined with existing hurricane wind speed studies, to be used as input loads due to wind for infrastructure desing.

For each station with wind speeds time histories in the input data, extreme wind speed corresponding to each recurrence interval are calculated using a \emph{Peaks Over Threshold} onwards \emph{POT} extreme value model, then wind velocities with the same recurrence interval are \emph{spatially interpolated} to generate continuous maps for the whole study area.

A wind speed linked to a \emph{mean recurrence interval - MRI} of \emph{N-years} (N-years return value or return period) is interpreted as the highest probable wind speed along the period of N-years. The annual probability of equal or exceed that wind speed is 1/N. The annual excedance probability for all velocity values in 700-years output map will be 1/700, for the 1700-years map will be 1/1700, and 1/3000 for the 3000-years final map.

There are different methods to model extreme value data, among them are a) sample maxima using a \emph{Generalized Extreme Value Distribution} onwards \emph{GEVD} (traditional method), b) POT using a \emph{Generalized Pareto Distribution} onwards \emph{GPD}, c) POT using a two-dimensional Poisson Process, that can be homomegenos, non-homogeneous, stationary, and non-stationary (originally know as \emph{Point Process} approach), and d) POT Poisson-GPD. Following Pintar, Simiu, Lombardo, \& Levitan (2015) in this research a \emph{POT using a non-homogeneous non-stationary two-dimensional poisson proces} was selected, despide there is no R package available to apply this approach.

\hypertarget{rmd-data}{%
\chapter{Data}\label{rmd-data}}

Input data is made up of three different sources a) IDEAM - Institute of Hydrology, Meteorology and Environmental Studies of Colombia \url{http://www.ideam.gov.co}, b) ISD - Integrated Surface Database \url{https://www.ncdc.noaa.gov/isd}, and c) ERA5 climate reanalysis \url{https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5}.

\begingroup\fontsize{10}{12}\selectfont
\begin{longtable}[t]{l>{\raggedright\arraybackslash}p{0.8in}>{\raggedright\arraybackslash}p{4in}}
\caption[Datasets]{\label{tab:tabledatasources1}Datasets description}\\
\toprule
\multicolumn{1}{l}{Institution} & \multicolumn{1}{l}{Dataset} & \multicolumn{1}{l}{Details}\\
\midrule
IDEAM & Historical records at weather stations & IDEAM is responsible for the instalation, maintenance and management of all kind of weather stations located everywhere along the country\\
NOAA & ISD & ISD (Integrated Surface Database. NOAA's National Centers for Environmental Information - NCEI) Lite: A subset from the full ISD dataset containing eight common surface parameters in a fixed-width format free of duplicate values, sub-hourly data, and complicated flags.\\
ECMWF & ERA5 & ERA5 is a reanalysis dataset with hourly estimates of atmospheric variables with horizontal resolution of 0.25º (33 kilómeters), this is equally spaced cells every 0.25 degrees\\
\bottomrule
\end{longtable}
\endgroup{}

\begingroup\fontsize{10}{12}\selectfont
\begin{longtable}[t]{l>{\raggedright\arraybackslash}p{1.2in}>{\raggedright\arraybackslash}p{3.5in}}
\caption[Variables]{\label{tab:tabledatasources2}Datasets variables}\\
\toprule
\multicolumn{1}{l}{Dataset} & \multicolumn{1}{l}{Variables} & \multicolumn{1}{l}{Description}\\
\midrule
IDEAM & vvmx\_aut\_60 & Hourly wind maximun velocity\\
ISD & wind speed rate & Maximun hourly wind velocity. The rate of horizontal travel of air past a fixed point.\\
ERA5 & fg10 & 10 metre wind gust since previous post-processing\\
 & fsr & Forecast Surface Roughness\\
\bottomrule
\end{longtable}
\endgroup{}

\begingroup\fontsize{10}{12}\selectfont
\begin{longtable}[t]{l>{\raggedright\arraybackslash}p{0.8in}>{\raggedright\arraybackslash}p{3in}l}
\caption[Units and Time]{\label{tab:tabledatasources3}Variables units and time}\\
\toprule
\multicolumn{1}{l}{Variable} & \multicolumn{1}{l}{Units} & \multicolumn{1}{l}{Time} & \multicolumn{1}{l}{Stations}\\
\midrule
vvmx\_aut\_60 & meters per second & Variable from 2001 until today. Irregular time series. & 203\\
Wind speed & meters per second & Variable from 1941 until today. Note: There is too much variability in time (start, end, and time range) for each station. Irregutal time series. & 101\\
fg10 & meters per second & 1979-Today & 3381\\
fsr & meters per second & 1979-Today & 3381\\
\bottomrule
\end{longtable}
\endgroup{}

Ideal data source to create extreme wind speeds maps should be field observed data from IDEAM, but there are not enough number of stations around the study area to represent all the local wind variability in a huge country with multiple variety of climates and and changing thermal floors, but there are other important motivatios to include different sources trying to improve output results:
\begin{itemize}
\tightlist
\item
  As just mentioned, low quantity of IDEAM stations
\item
  There are uncertanties related to the way IDEAM anemometers are registering data, then comparison with other datasources are needed to be able to do appropriate data standardization, needed as a prerequisite to the analysis.
\item
  There is no time continuity in the registration of IDEAM data. Historical time series are different and variable in each station.
\end{itemize}
Importance of ISD database for this study is based on the fact that post-procesed ISD database has wind extreme values, and it was used to create extreme wind maps for United States. ISD allows comparison with IDEAM records to take better decitions in order to do needed data standarization.

Despite that ERA5 data are not observed data, but forecast, its main advantage is data availability to assess the local climatic variance every 33 square kilometers.

\hypertarget{ideam}{%
\section{IDEAM}\label{ideam}}

Historical observed wind speeds from 203 in Colombia are managed by the official environmental authority IDEAM. Table \ref{tab:tableideamstations} shows a sample of five IDEAM stations. Figure \ref{fig:plotideamstations} shows a map of IDEAM stations.
\begin{longtable}[t]{lrr}
\caption[IDEAM Stations]{\label{tab:tableideamstations}IDEAM Stations sample}\\
\toprule
Name[Code] & Latitud & Longitud\\
\midrule
EMAS - AUT [26155230] & 5.09 & -75.51\\
SAN BENITO - AUT [25025380] & 9.16 & -75.04\\
AEROPUERTO ALFONSO LOPEZ - [28025502] & 10.44 & -73.25\\
TIBAITATA - AUT [21206990] & 4.69 & -74.21\\
ELDORADO CATAM - AUT [21205791] & 4.71 & -74.15\\
\bottomrule
\end{longtable}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotideamstations-1.pdf}
\caption{\label{fig:plotideamstations}IDEAM Stations}
\end{figure}
Following, the time serie, autocorrelation function, and partial autocorrelation function, for IDEAM station ``21205791'' will be displayed.
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneideamstation-1.pdf}
\caption{\label{fig:plotoneideamstation}IDEAM Station - Time Serie}
\end{figure}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneideamstationacf-1.pdf}
\caption{\label{fig:plotoneideamstationacf}IDEAM Station ACF}
\end{figure}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneideamstationpacf-1.pdf}
\caption{\label{fig:plotoneideamstationpacf}IDEAM Station PACF}
\end{figure}
\hypertarget{isd}{%
\section{ISD}\label{isd}}

ISD is a database with environmental variables among then extreme wind speeds. ISD has data for the whole planet, and is based on observed data at metereological stations in each country, which means that for Colombia is based on IDEAM data. Main advantage is data availability at neighbor countries and specialized postprocesing made by NOAA's National Centers for Environmental Information - NCEI in United States, which facilitates its use.Table \ref{tab:tableisdstations} shows a sample of five ISD stations. Figure \ref{fig:plotisdstations} shows a map of ISD stations.
\begin{longtable}[t]{llrr}
\caption[ISD Stations]{\label{tab:tableisdstations}ISD Stations sample}\\
\toprule
Code & Name & Latitud & Longitud\\
\midrule
804400 & BARINAS & 8.62 & -70.22\\
800810 & ALTO CURICHE & 7.05 & -76.35\\
801000 & BAHIA SOLANO / JOSE MUTIS & 6.18 & -77.40\\
802590 & ALFONSO BONILLA ARAGON INTL & 3.54 & -76.38\\
803150 & BENITO SALAS & 2.95 & -75.29\\
\bottomrule
\end{longtable}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotisdstations-1.pdf}
\caption{\label{fig:plotisdstations}ISD Stations}
\end{figure}
Following, the time serie, autocorrelation function, and partial autocorrelation function, for ISD station ``802590'' will be displayed.
\begin{verbatim}
select "mydatetime", "802590" as "X802590" from isd_lite_unstack where "802590" IS NOT NULL
\end{verbatim}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneisdstation-1.pdf}
\caption{\label{fig:plotoneisdstation}ISD Station - Time Serie}
\end{figure}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneisdstationacf-1.pdf}
\caption{\label{fig:plotoneisdstationacf}ISD Station ACF}
\end{figure}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneisdstationpacf-1.pdf}
\caption{\label{fig:plotoneisdstationpacf}IDEAM Station PACF}
\end{figure}
\hypertarget{era5}{%
\section{ERA5}\label{era5}}

ERA5 is forecast reanalysis data procesed by the \emph{European Centre for Medium-Range Weather Forecasts} - ECMWF with wind speeds time series in square cells \emph{matrix of pixels} of 0.25 degrees (33 km) covering the whole plannet. For the study area was extracted a raster of 69 rows by 49 XXX columns in format NetCDF. Figure \ref{fig:plotera5stations} shows a map of ERA5 stations (cells centers).
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotera5stations-1.pdf}
\caption{\label{fig:plotera5stations}ERA5 Stations (cells centers)}
\end{figure}
\hypertarget{data-download-and-organization}{%
\section{Data Download and Organization}\label{data-download-and-organization}}

\hypertarget{data-standarzation}{%
\section{Data Standarzation}\label{data-standarzation}}

Analysis of extreme wind speeds requieres data standarizaton as initial step. All input data must be standarized to represent three important conditions: a) anemometer height of 10 meters, b) open space roughness, and c) averaging time of 3-seconds wind gust. Data for analysis must represent 3-s peak wind speeds 10 meters heigh above the surface, in open terrain.
* 10 mts anemometer height
* Open space terrain roughness
* 3-s gust averaging time

\clearpage

\hypertarget{rmd-thefra}{%
\chapter{Theoretical Framework}\label{rmd-thefra}}

\hypertarget{probability-concepts}{%
\section{Probability Concepts}\label{probability-concepts}}

Poisson process is an stochastic method that relies in the concepts of probability distributions. The main functions related to probability for extreme value analysis will be described below.

\hypertarget{probability-density-function---pdf}{%
\subsection{\texorpdfstring{Probability Density Function - \emph{pdf}}{Probability Density Function - pdf}}\label{probability-density-function---pdf}}

Pdf defines the probability that a continuos variable falls between two points, this is, in \emph{pdf} the proability is related to the area below the curve (integral) between two points, as for continuos probability distributions the probability at a single point is zero. The term density is directly related to the probability of a portion of the curve, if the density function has high values the probability will be greater in comparison with the same portion of curve for low values.

\[
\int_a^b f(x)dx = Pr[a \leq X \leq b]
\]

Equation \eqref{eq:gumbelpdf} is the Gumbel \emph{pdf}.
\begin{equation}
  \mathrm{
          f(x)=\frac{1}{\beta}
          \exp\left\{
            -\frac{x-\mu}{\beta}
          \right\}
          \exp\left\{
            -\exp\left\{
              -\left(
                \frac{x-\mu}{\beta}
              \right)
            \right\}
          \right\},
          \quad -\infty < x < \infty
         }
  \label{eq:gumbelpdf}
\end{equation}
where \(\exp\left\{.\right\} \mapsto \mathrm{e}^{\left\{.\right\}}\), \(\beta\) is the scale parameter, and \(\mu\) is the location parameter. Location (\(\mu\)) has the effect to shift the \emph{pdf} to left or right along `x' axis, thus, if location value is changed the effect is a movement of \emph{pdf} to the left (small value for location), or to the right (big value for location). Scale has the effect to stretch (\(\beta > 1\)) of compress (\(0 < \beta< 1\)) the \emph{pdf}, if scale parameter is close to zero the pdf approaches a spike.

Figure \ref{fig:plotgumbelpdffunction} shows \emph{pdf} with location (\(\mu\)) = 100 and scale (\(\beta\)) = 40, using equation \eqref{eq:gumbelpdf}.

\footnotesize
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location =}\StringTok{ }\DecValTok{100}
\NormalTok{scale =}\StringTok{ }\DecValTok{40}
\NormalTok{.x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DataTypeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{pdfG <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
  \DecValTok{1}\OperatorTok{/}\NormalTok{location }\OperatorTok{*}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{-}\NormalTok{location)}\OperatorTok{/}\NormalTok{scale)}\OperatorTok{*}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{-}\NormalTok{location)}\OperatorTok{/}\NormalTok{scale))}
\NormalTok{  \}}
\NormalTok{.y =}\StringTok{ }\KeywordTok{pdfG}\NormalTok{(.x)}
\KeywordTok{plot}\NormalTok{(.x, .y, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{4}\NormalTok{, }
     \DataTypeTok{xlab=}\StringTok{"Velocities Km/h"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Density Function - Gumbel Distribution"}\NormalTok{, }
     \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Gumbel - Density Function Gumbel Distribution}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\StringTok{"Location="}\NormalTok{, }
     \KeywordTok{round}\NormalTok{(location,}\DecValTok{2}\NormalTok{), }\StringTok{" Scale="}\NormalTok{, }\KeywordTok{round}\NormalTok{(scale,}\DecValTok{2}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }
     \DataTypeTok{cex.axis =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{cex.lab=} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{cex.main=}\FloatTok{0.7}\NormalTok{, }\DataTypeTok{cex.sub=}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelpdffunction-1.pdf}
\caption{\label{fig:plotgumbelpdffunction}Gumbel pdf}
\end{figure}
\normalsize

Figure \ref{fig:plotgumbelpdf} shows \emph{pdf} with location (\(\mu\)) = 100 and scale (\(\beta\)) = 40, using function \texttt{dgumbel} of the package \texttt{RcmdrMisc}

\footnotesize
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location =}\StringTok{ }\DecValTok{100}
\NormalTok{scale =}\StringTok{ }\DecValTok{40}
\NormalTok{.x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DataTypeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{dfG =}\StringTok{ }\KeywordTok{dgumbel}\NormalTok{(.x, }\DataTypeTok{location=}\NormalTok{location, }\DataTypeTok{scale=}\NormalTok{scale)}
\KeywordTok{plot}\NormalTok{(.x, dfG, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{4}\NormalTok{, }
     \DataTypeTok{xlab=}\StringTok{"Velocities Km/h"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Density Function - Gumbel Distribution"}\NormalTok{, }
     \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Gumbel - Density Function Gumbel Distribution}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\StringTok{"Location="}\NormalTok{, }
     \KeywordTok{round}\NormalTok{(location,}\DecValTok{2}\NormalTok{), }\StringTok{" Scale="}\NormalTok{, }\KeywordTok{round}\NormalTok{(scale,}\DecValTok{2}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }
     \DataTypeTok{cex.axis =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{cex.lab=} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{cex.main=}\FloatTok{0.7}\NormalTok{, }\DataTypeTok{cex.sub=}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelpdf-1.pdf}
\caption{\label{fig:plotgumbelpdf}Gumbel pdf - dgumbel function}
\end{figure}
\normalsize

\hypertarget{cumulative-distribution-funtcion---cdf}{%
\subsection{\texorpdfstring{Cumulative Distribution Funtcion - \emph{cdf}}{Cumulative Distribution Funtcion - cdf}}\label{cumulative-distribution-funtcion---cdf}}

\emph{Cdf} is the probability of taking a value less than or equal to x. That is

\[
F(x) = Pr[X < x] = \alpha
\]
For a continuous variable, \emph{cdf} can be expressed as the integral of its \emph{pdf}.
\[
F(x) = \int_{-\infty}^x f(x)dx
\]

Equation \eqref{eq:gumbelcdf} is the Gumbel \emph{cdf}.
\begin{equation}
\mathrm{
        F(x) = \exp\left\{-\exp\left[-\left(\frac{x-\mu}{\beta}\right)\right]\right\}, 
        \quad -\infty < x < \infty
        }
  \label{eq:gumbelcdf}
\end{equation}
Figure \ref{fig:plotgumbelcdffunction} shows Gumbel \emph{cdf} with location (\(\mu\)) = 100 and scale (\(\beta\)) = 40, using equation \eqref{eq:gumbelcdf}. As previously done with \emph{pdf}, similar result can be achieved using function \texttt{pgumbel} of package \texttt{RcmdrMisc}.

\footnotesize
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location =}\StringTok{ }\DecValTok{100}
\NormalTok{scale =}\StringTok{ }\DecValTok{40}
\NormalTok{.x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DataTypeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{cdfG <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
  \KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{-}\NormalTok{location)}\OperatorTok{/}\NormalTok{scale))}
\NormalTok{  \}}
\NormalTok{.y =}\StringTok{ }\KeywordTok{cdfG}\NormalTok{(.x)}
\KeywordTok{plot}\NormalTok{(.x, .y, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{4}\NormalTok{, }
     \DataTypeTok{xlab=}\StringTok{"Velocities Km/h"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Probability"}\NormalTok{, }
     \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Gumbel - Cumulative Distribution Function}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\StringTok{"Location="}\NormalTok{, }
     \KeywordTok{round}\NormalTok{(location,}\DecValTok{2}\NormalTok{), }\StringTok{" Scale="}\NormalTok{, }\KeywordTok{round}\NormalTok{(scale,}\DecValTok{2}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }
     \DataTypeTok{cex.axis =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{cex.lab=} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{cex.main=}\FloatTok{0.7}\NormalTok{, }\DataTypeTok{cex.sub=}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelcdffunction-1.pdf}
\caption{\label{fig:plotgumbelcdffunction}Gumbel cdf}
\end{figure}
\normalsize

\hypertarget{percent-point-function---ppf}{%
\subsection{\texorpdfstring{Percent Point Function - \emph{ppf}}{Percent Point Function - ppf}}\label{percent-point-function---ppf}}

\emph{Ppf} is the inverse of \emph{cdf}, also called the \emph{quantile} function. This is, from a specific probability get the corresponding value x of the variable.

\[
x = G(\alpha) = G(F(x))
\]
Equation \eqref{eq:gumbelppf} is the Gumbel \emph{ppf}.
\begin{equation}
\mathrm{
        G(\alpha) = \mu-\beta ln(-ln(\alpha))
        \quad 0 < \alpha < 1
        }
  \label{eq:gumbelppf}
\end{equation}
Figure \ref{fig:plotgumbelppffunction} shows Gumbel \emph{ppf}, using equation \eqref{eq:gumbelppf}. Similar result can be achieved using function \texttt{qgumbel} of package \texttt{RcmdrMisc}.

\footnotesize
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location =}\StringTok{ }\DecValTok{100}
\NormalTok{scale =}\StringTok{ }\DecValTok{40}
\NormalTok{.x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DataTypeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{ppfG <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  location }\OperatorTok{-}\StringTok{ }\NormalTok{(scale}\OperatorTok{*}\KeywordTok{log}\NormalTok{(}\OperatorTok{-}\KeywordTok{log}\NormalTok{(x)))}
\NormalTok{  \}}
\NormalTok{.y =}\StringTok{ }\KeywordTok{ppfG}\NormalTok{(.x)}
\KeywordTok{plot}\NormalTok{(.x, .y, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{4}\NormalTok{, }
     \DataTypeTok{ylab=}\StringTok{"Velocities Km/h"}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"Probability"}\NormalTok{, }
     \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Gumbel - Percent Point Function}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\StringTok{"Location="}\NormalTok{, }
     \KeywordTok{round}\NormalTok{(location,}\DecValTok{2}\NormalTok{), }\StringTok{" Scale="}\NormalTok{, }\KeywordTok{round}\NormalTok{(scale,}\DecValTok{2}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }
     \DataTypeTok{cex.axis =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{cex.lab=} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{cex.main=}\FloatTok{0.7}\NormalTok{, }\DataTypeTok{cex.sub=}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelppffunction-1.pdf}
\caption{\label{fig:plotgumbelppffunction}Gumbel cdf}
\end{figure}
\normalsize

\hypertarget{hazard-function---hf}{%
\subsection{\texorpdfstring{Hazard Function - \emph{hf}}{Hazard Function - hf}}\label{hazard-function---hf}}

Using \(S(x) = 1 - F(x)\) as survival function -\emph{sf}, the probability that a variable takes a value greather than x \(S(x) = Pr[X > x] = 1 - F(x)\), the \emph{hf} is the ratio between \emph{pdf} and \emph{sf}.

\[
h(x) = \frac{f(x)}{S(x)} = \frac{f(x)}{1-F(x)}
\]
Equation \eqref{eq:gumbelhf} is the Gumbel \emph{ppf}.
\begin{equation}
\mathrm{
        h(x)= \frac{1}{\beta}\frac{\exp(-(x-\mu)/\beta)}{\exp(\exp(-(x-\mu)/\beta))-1}
       }
  \label{eq:gumbelhf}
\end{equation}
Figure \ref{fig:plotgumbelhffunction} shows Gumbel \emph{hf}, using equation \eqref{eq:gumbelhf}.

\footnotesize
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location =}\StringTok{ }\DecValTok{100}
\NormalTok{scale =}\StringTok{ }\DecValTok{40}
\NormalTok{.x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{3000}\NormalTok{, }\DataTypeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{hfG <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  (}\DecValTok{1}\OperatorTok{/}\NormalTok{scale)}\OperatorTok{*}\NormalTok{(}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{-}\NormalTok{location)}\OperatorTok{/}\NormalTok{scale))}\OperatorTok{/}\NormalTok{(}\KeywordTok{exp}\NormalTok{(}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{-}\NormalTok{location)}\OperatorTok{/}\NormalTok{scale))}\OperatorTok{-}\DecValTok{1}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{.y =}\StringTok{ }\KeywordTok{hfG}\NormalTok{(.x)}
\KeywordTok{plot}\NormalTok{(.x, .y, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{4}\NormalTok{, }
     \DataTypeTok{xlab=}\StringTok{"Velocities Km/h"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Hazard"}\NormalTok{, }
     \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Gumbel - Hazard Function}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\StringTok{"Location="}\NormalTok{, }
     \KeywordTok{round}\NormalTok{(location,}\DecValTok{2}\NormalTok{), }\StringTok{" Scale="}\NormalTok{, }\KeywordTok{round}\NormalTok{(scale,}\DecValTok{2}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }
     \DataTypeTok{cex.axis =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{cex.lab=} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{cex.main=}\FloatTok{0.7}\NormalTok{, }\DataTypeTok{cex.sub=}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelhffunction-1.pdf}
\caption{\label{fig:plotgumbelhffunction}Gumbel cdf}
\end{figure}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#library(reliaR)}
\CommentTok{#plot(.x, hgumbel(.x, mu=location, sigma=scale))}
\CommentTok{#plot(.x, hra.gumbel(.x, mu=location, sigma=scale))}
\end{Highlighting}
\end{Shaded}
\normalsize

\hypertarget{statistical-concepts-for-extreme-analysis}{%
\section{Statistical Concepts For Extreme Analysis}\label{statistical-concepts-for-extreme-analysis}}

In order to approach the extreme value analysis, some statistical concepts are needed to understand the theoretical framework behind this knowledge area. In this section will be introduced the concepts annual excedance probability, mean recurrence interval - MRI, exposure time, and compound probability for any given exposure time and MRI.

As an hypotetical example, a simulated database of extreme wind speed will be used. This database is supposed to have 10.000 years of simulated wind speeds.

\hypertarget{annual-excedance-probability---pe}{%
\subsection{Annual Excedance Probability - Pe}\label{annual-excedance-probability---pe}}

Using the previously described database, a question arises to calculate the probability to exceed the highest probable loss due to the simulated winds. It is possible to conclude that there is only one event grather or equal (in this case equal) to the higest probable causing loss in 10.000 years, and it is the \emph{highest wind}. If we sort the database by wind magnitude in descending order (small winds last), the question is solved calculating the annual excedance probability \emph{Pe} with next formula

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/unnamed-chunk-9-1.pdf}
\caption{\label{fig:unnamed-chunk-9}Sorted Winds by Magnitud - wind simulation database}
\end{figure}
\normalsize

\[
P_e = \frac{Event\,index\,after\,descending\,sorting}{Years\,of\,simulations } = \frac{1}{10.000}=0.001=0.01\%
\]
because the highest wind will be the first in the sorted list. Same exercise can be done with all winds to construct the annual exedance probability curve, that in this case will represent the probability to equal or exceed different probable losses due to wind.

\hypertarget{return-period---mean-recurrence-interval}{%
\subsection{Return Period - Mean Recurrence Interval}\label{return-period---mean-recurrence-interval}}

Continuing with the previous section, if the inverse of the excedance probability is taken, the return period (in years) is obtained. The return period or Mean Recurrence Interval - MRI is associated with an specific return level (wind extreme velocity). MRI is the numbers of years (N) needed to obtain 63\% of change that the corresponding return level will occur at least one time in that period. The return level is expected to be exceeded on average once every N-years. The annual excedance probability of the return level corresponding to N-years of MRI, is \(P_e=\frac{1}{MRI}=\frac{1}{N}\).

For an specific wind extreme event A, the probability that the event will occur in a period equal to MRI years is 63\%. If we analyse for the same period a strongest wind extreme event B, its orrurence probability will be lest than 67\%. If the purpose of this researh is to design infrastructure considering wind loads, the structure will be more resistant to wind if we desing with stronger winds, this is high MRIs, and low annual excedance probability. Common approach for infrastructure design, considering any type of load (earthquake, wind, etc) is to choose high MRI according to the importance/use/risk/type of the structure. For highly important structures lik hospitals or coliseums, where the risk of collapse must be diminished, the MRI used to design is higher in comparison to common structures (for instance a normal house), which implies less risks for its use and importance.

\[
  \mathrm{
    P_e = 
    \begin{cases}
      \begin{split}
            &1-\exp\left(-\frac{1}{MRI}\right),\;for\,MRI\,<\,10\,years
            \\
            &\frac{1}{MRI},\;for\,MRI\,\geq\,10\,years      
      \end{split}
    \end{cases}
  }
\]

\hypertarget{compound-excedance-probability---pn}{%
\subsection{Compound Excedance Probability - Pn}\label{compound-excedance-probability---pn}}

If time of exposure is consider, understood as time the structure will be in use, it is possible to have a compound probability \(P_n\), where \(n\) is the exposure period. \(P_n\) is the probability that the extreme wind speed will be equaled or exceeded at least one time in \(n\) years, and is related with the occurrence probability, but also is posible to calculate the non-ocurrence compound probability (probability that the event will not occur).

\[
  \mathrm{
    P_n = 
    \begin{cases}
      \begin{split}
            &1-\left(1-\frac{1}{MRI}\right)^n,\;occurrence\,probability
            \\
            &\left(1-\frac{1}{MRI}\right)^n,\;non-occurrence\,probability
      \end{split}
    \end{cases}
  }
\]

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/compoundprobability-1.pdf}
\caption{\label{fig:compoundprobability}Compound Probability}
\end{figure}
\normalsize

If it is consider exposure time as a multiple of return period, the resulting figure \ref{fig:compoundprobability}, shows that:
\begin{itemize}
\tightlist
\item
  When exposure time is .69\% of the return period, then probability (ocurrence and non-occurrence) will be 50\%
\item
  As was stated previously, whe exposure time is equal to return period, then the probability that the extreme wind speed (return level) occur is 63\%, and 37\% for the non occurrence probability.
\item
  If exposure time is 4.5 times the return period, there is a 99\% of change that the return level will occur.
\end{itemize}
The example discused here was presented as an instrument to introduce important concepts, nonetheless,there are specialized approaches to deal with extreme value analysis which will be discussed in \protect\hyperlink{extremeoverview}{Extreme Valua Analysis Overview} and more in detail in \protect\hyperlink{pot-pp}{Peaks Over Threshold - Poisson Process}. In summary, is neccesary to fit the data over a specific threshold to an extreme value distribution, and \(P_e\) wil be \(1-F(y)\), with F(y) as the \emph{cdf}, and MRI as \(\frac{1}{1-F(y)}\).

\hypertarget{extremeoverview}{%
\section{Extreme Value Analysis Overview}\label{extremeoverview}}

Analysis of extreme values is related with statistical inference to calculate probabilities of extreme events. Main methods to analize extreme data are ephochal, Peaks Over Threshold - POT, and extreme index. The epochal method, also known as block maxima, uses the most extreme value for a specific frame of time, tipically, one year. POT is based in the selection of a single threshold value to do the analysis only with values above the threshold. But there are different POT aproaches, the most commond one is Generalized Paretto Distribution - POT-GPD, but also it is possible to use the Poisson process approach.

In both methods (Epochal and POT), the first step is to fit the data to an appropiate probability distribution model, among them the most used are, - Extreme Value Type I (Gumbel), Extreme Value Type II (Frechet), Weibull, Generalized Pareto - GPD, and Generalized Extreme Value - GEV.

Distribution models are fitted based in the estimation of its parameters, mommonly called location, scale and shape, nonetheless each model has its own parameters names. There are different methods to estimate parameters, among them, - method of moments (modified moments - see Kubler (1994), and L moments - see Hosking \& Wallis (1997)), - method of maximum likelihood MLE, see Harris \& Stocker (1998), which is problematic for GPD and GEV, - probability plot correlation coeficient, and - elemental percentiles (for GPD and GEV)

Once cadidate parameters are available, it is neccesary to assess the goodness of fit of the selected model, using one of the next methods, - Kolmogorov-Smirnov (KS) goodnes of fit test, and - Anderson-Darling goodness of fit test. Here a visual assesment is also useful using a probability plot or a kernel density plot with the fitted \emph{pdf} overlaid.

The main use of the fitted model is the estimation of mean return intervals - MRI, and extreme wind speeds (return levels),

\[
MRI=\frac{1}{1-F(y)}
\]
with \(F(y)\) as the \emph{cdf}. If \(1-F(y)\) is the annual excedance probability, MRI is its inverse, see Simiu \& Scanlan (1996) for more details about MRI. If \(y\) is solved from previos equation using a given MRI of N-years, its value represents the \(Y_N\) wind speed return level,

\[
Y_N = G\left(1-\frac{1}{\lambda\,N}\right)
\]
where \(G\) is the \emph{ppf} (quantile function) and \(\lambda\) is the number of wind spees over the threshold per year.

The CRAN Task View ``Extreme Value Analysis'' \url{https://cran.r-project.org/web/views/ExtremeValue.html} shows available \textbf{R} for block maxima, POT by GPD, and external indexes estimation aproaches. Most important to consider are \texttt{evd}, \texttt{extremes}, \texttt{evir}, \texttt{POT}, \texttt{extremeStat}, \texttt{ismev}, and \texttt{Renext}.

\hypertarget{pot-pp}{%
\section{Peaks Over Threshold - Poisson Process}\label{pot-pp}}

According to Pintar et al. (2015) the stochastic poisson process is mainly defined by its intensity function. As the intensity function is nos uniform over the domain, the poisson process considered here is non-homogeneous, and due to the intensity function dependance of magnitud and time, it is also bi-dimmensional. Poisson Process was described for the first time in Pickands (1971), then extended in Smith (1989).
\begin{equation}
  \mathrm{
    \lambda\left(y,t\right)
    \begin{cases}
      \begin{split}
            &\lambda_t(y),\;for\,t\,in\,thunderstorm\,period
            \\
            &\lambda_nt(y),\;for\,t\,in\,non-thunderstorm\,period      
      \end{split}
    \end{cases}
  }
  \label{eq:ppgenericintensityfunction}
\end{equation}
Generic equation \eqref{eq:ppgenericintensityfunction} shows the intensity function, which is defined in the domain \(D = D_t\,{\cup}\,D_{nt}\), and allow to fit the poisson process at each station to the observed data \(\{t_i, y_i\}_{i=1}^I\) for al the times (\(t_i\)) of threshold crossing observations and its corresponding wind speeds magnitudes (\(y_i\)). Thus, only data above the threshold is used.

Intensity function of the Poisson Process is defined in Smith (2004),

\[
\frac{1}{\psi_t}\left(1+\zeta_t\frac{y-\omega_t}{\psi_t}\right)_+^{-\frac{1}{\zeta_t}-1}
\]
Where \(\zeta_t\) controls the tail lengh of the intensity function at a given time \(t\), but to facilitate the estimation of the parameters then \(\zeta_t\) is taken to be zero, then doing the limit, the resulting intensity function is the same as the the GEV type I or Gumbel distribution,

\[
\frac{1}{\psi_t}\exp\left\{\frac{-(y-\omega_t)}{\psi_t}\right\}
\]

In this study, the used intensity functions are shown in ecuation \eqref{eq:ppspecificintensityfunction}.
\begin{equation}
  \mathrm{
    \lambda\left(y,t\right)
    \begin{cases}
      \begin{split}
            &\frac{1}{\psi_s}\exp\left\{\frac{-(y-\omega_s)}{\psi_s}\right\},\;for\,t\,in\,thunderstorm\,period
            \\
            &\frac{1}{\psi_{nt}}\exp\left\{\frac{-(y-\omega_{nt})}{\psi_{nt}}\right\},\;for\,t\,in\,non-thunderstorm\,period      
      \end{split}
    \end{cases}
  }
  \label{eq:ppspecificintensityfunction}
\end{equation}
\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotdomainpp-1.pdf}
\caption{\label{fig:plotdomainpp}Domanin off the Poisson Process}
\end{figure}
\normalsize

Figure \ref{fig:plotdomainpp} represent the domain \(D\) of the Poisson process. In time, the domain represents the station service period from first sample \(t_1\) to last sample \(t_4\). \(D\) is the union of all thunderstorm periods \(D_t\) (from \(t_2\) to \(t_3\)), and all non-thunderstorm periods \(D_{nt}\) (periods \(t_1\) to \(t_2\) and \(t_3\) to \(t_4\)). In magnitud, only thunderstorm data above its threshold \(b_t\), and only non-tunderstorm data above its threshold \(b_{nt}\) are used.

Thunderstoms and non-thunderstorms are modeled independently:
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Observations in domain \(D\) follow a Poisson distribution with mean \(\int_D\lambda(t,y)\,dt\,dy\)
\item
  For each disjoint subdomain \(D_1\) or \(D_2\) inside \(D\), the observations in \(D_1\) or \(D_2\) are independent random variables.
\end{enumerate}
Visual representation of the intensity function for the Poisson Process can be seen in figure \ref{fig:plotdomain3dpp}. In vertical axis, two surfaces were drawn representing independent intensity functions for thunderstorm \(\lambda_t(y)\) and for non-thunderstorm \(\lambda_{nt}(y)\). The volume under each surface for its corresponding time periods and peak (over threshold) velocities, is the mean of the Poisson Process.

\footnotesize
\begin{figure}
\includegraphics[width=6.35in]{figure/domain3d} \caption{Volume under surfaces represents the mean of the Poisson process}\label{fig:plotdomain3dpp}
\end{figure}
\normalsize

The method of maximun likelihood es used to estimate the parameters of the Poisson process, the selected vector of parameters \(\eta\) are the \(\hat\eta\) values that maximizes the function
\begin{equation}
  \mathrm{
          L(\eta)=\left( 
                        \prod_{i=1}^I\lambda\left(y_i,t_i\right)  
                  \right)
                  \exp\left\{
                            -\int_{{D}}\lambda\left(y,t\right)dy\,dt
                     \right\}
         }
  \label{eq:pplikelihood}
\end{equation}
\(\hat\eta\) values need to be calculated using a numericall approach because there is not analytical solution available.

Once the Poisson process is fittet to the data, the model will provide extreme wind velocities (return levels), for different return periods (mean recurrence intervals).

A \(Y_N\) extreme wind velocity, called the return level (RL) belonging to the N-years return period, has a expected frequency to occur or to be exceeded (annual excedance probability)\(P_e = \frac{1}{N}\), and also has a probability that the event does not occur (annual non-excedance probability) \(P_{ne}=1-\frac{1}{N}\). \(Y_N\) will be the resulting value of the \(G\) (ppf or quantile) function using a probability equal to \(P_{ne}\). \(Y_N=quantile(y, p=P_{ne})=G(x,p=P_{ne})=ppf(x,p=P_{ne})\). As for this study \(\zeta = 0\), the \(G\) function to use is the Gumbel quantile function. \(Y_N\) can be undestood as the wind extreme value expected to be exceeded on average once every N years.

For different POT approaches, as POT-GPD described --, the value of the probability passed to the \(G\) function, has to be modified with the \(\lambda\) parameter, as is described in next equation. \(\lambda\) is the number of wind speed over the threshold per year.

\[
Y_N =G\left(y, 1-\frac{1}{\lambda\,N}\right)
\]

For the Poisson process \(Y_N\) is also the solution to the next equation, which is defined in terms of the intensity function,
\begin{equation}
  \mathrm{
          \int_{Y_N}^{\infty}\int_0^1\lambda\left( y,t\right)dydt = A_t\int_{Y_N}^{\infty}\lambda_t\left( y\right)\,dy + A_{nt}\int_{Y_N}^{\infty}\lambda_{nt}\left( y\right)\,dy = \frac{1}{N}
         }
  \label{eq:ppmri}
\end{equation}
where \(A_t\), is the multiplication of the average number of thunderstorm per year and the average lengh of a thunderstorm (taken to be 1 hour as defined in Pintar et al. (2015)), and \(A_{nt} = 1 - A_t\). The average length of a non-thunderstorm event is variable, and it is adjusted in each station to guarantee that \(A_{nt} + A_t = 1\)

The same thunderstorm event in considered to occur if the time lag distance between sucesive thunderstorm samples is small than six hours, and for non-thunderstorm this time is 4 days. For the Poisson process, all the measurements belonging to the same event (thunderstorm or non tunderstorm), need to be declustered to leave only one maximun value. In other words, the number of thunderstorm in the time serie is the number of time lag distances grather than 6 hours, and for non-thunderstorm grather than 4 days.

\#\#\#Threshold Selection

\[U=F(Y)\]
\[W = -log(1-U)\]

\hypertarget{wind-loads-requirements}{%
\section{Wind Loads Requirements}\label{wind-loads-requirements}}

Colombian norm that defines wind loads today is the Earth

As the output maps of this research will be used as input loads for infrastructure design, the methodology used for its creation, need to be consistent with Colombian official wind loads requirements. Today (2020), the Colombian norm that defines wind loads is the Seismic Resistant Standard 2010 - NSR-10 by its acronym of Spanish, see XXX. Chapter related to wind loads is B.6. NSR-10 was created and is maintained by the Colombian Association of Seismic Engineering - AIS.

NSR-10 is mainly based in the USA norm American Society of Civil Engineers 7-16, minimum design loads and associated criteria for buildings and other structures - ASCE7-16, see Engineers (2017). Under these circumstances, ASCE7-16 defines the minimum requirements of the research products. Especially the chapter C26 - ``wind loads - general requirements'', C26.5 ``wind hazard map'', and C26.7 ``Exposure'' - pages 733 to 747. Wind speeds requirements of ASCE7-16 are based in the combination of independent non-hurricane analysis, and hurricane wind speeds simulations models. The focus of this research will be the analysis of non-hurricane wind data, however, existing results of hurricane studies will be used to present final maps with both components. In ASCE7-16, for non-hurricane wind speed, the procedure is mainly based on Pintar et al. (2015).

ASCE7-16 (page 734), requires the calculation of wind extreme return levels for specific return periods according to the risk category of the structure to be designed: risk category I - 300 years, risk category II - 700 years, risk category III - 1700 years, risk category IV - 3000 years (NSR-10 only requires 700, 1700 and 3000 years). In addition, extreme wind speeds for those MRI need to correspond to: - 3 second gust speeds, - at 33 ft (10 meters) above the ground, and - exposure category C (open space).

To standarize wind speeds to gust speeds ASCE7-16 proposes the curve Durst (see C. S. Durst (1960), and figure \ref{fig:durstcurve}). It is valid only for open terran conditions. Durst curve shows in axis \(y\) the gust factor \(\frac{V_t}{V_{3600}}\), a ration between any wind gust averaged at \(t\) seconds, \(V_t\), and the hourly averaged wind speed \(V_{3600}\), and in the axis \(x\) the duration \(t\) of the gust.

\footnotesize
\begin{figure}
\includegraphics[width=6.14in]{figure/durst} \caption{Maximun speeds averaged over t (sec), to hourly mean speed}\label{fig:durstcurve}
\end{figure}
\normalsize

\hypertarget{rmd-method}{%
\chapter{Methodology}\label{rmd-method}}

\hypertarget{input-data-selection-and-standarization}{%
\section{Input Data Selection and Standarization}\label{input-data-selection-and-standarization}}

\clearpage

\hypertarget{data-selection}{%
\subsection{Data Selection}\label{data-selection}}

\hypertarget{data-standarization}{%
\subsection{Data Standarization}\label{data-standarization}}

\hypertarget{anemometer-height---10-m}{%
\subsubsection{Anemometer height - 10 m}\label{anemometer-height---10-m}}

\hypertarget{surface-roughness---0.03-m}{%
\subsubsection{Surface Roughness - 0.03 m}\label{surface-roughness---0.03-m}}

\hypertarget{averaging-time---3-s-gust}{%
\subsubsection{Averaging Time - 3-s gust}\label{averaging-time---3-s-gust}}

\hypertarget{data-filterng}{%
\subsection{Data Filterng}\label{data-filterng}}

\hypertarget{fit-data-to-a-pot---poisson-process}{%
\section{Fit data to a POT - Poisson Process}\label{fit-data-to-a-pot---poisson-process}}

\hypertarget{data-requirements}{%
\subsection{Data Requirements}\label{data-requirements}}

\hypertarget{exploratory-data-analysis-and-data-preparation}{%
\subsection{Exploratory Data Analysis and Data Preparation}\label{exploratory-data-analysis-and-data-preparation}}

\hypertarget{declustering-of-observations}{%
\subsubsection{Declustering of observations}\label{declustering-of-observations}}

\hypertarget{exclude-no-data-periods}{%
\subsubsection{Exclude no-data periods}\label{exclude-no-data-periods}}

\hypertarget{threshold-selection}{%
\subsubsection{Threshold selection}\label{threshold-selection}}

\hypertarget{parameters-estimation}{%
\subsection{Parameters Estimation}\label{parameters-estimation}}

\hypertarget{intensity-function}{%
\subsubsection{Intensity function}\label{intensity-function}}

\hypertarget{density-function}{%
\subsubsection{Density function}\label{density-function}}

\hypertarget{distribution-function}{%
\subsubsection{Distribution function}\label{distribution-function}}

\hypertarget{maximun-likelihood-estimation}{%
\subsubsection{Maximun likelihood estimation}\label{maximun-likelihood-estimation}}

\hypertarget{velocities-at-return-periods}{%
\subsection{Velocities at Return Periods}\label{velocities-at-return-periods}}

\hypertarget{spatial-interpolation}{%
\section{spatial Interpolation}\label{spatial-interpolation}}

\hypertarget{conclusion}{%
\chapter*{Conclusion}\label{conclusion}}
\addcontentsline{toc}{chapter}{Conclusion}

If we don't want Conclusion to have a chapter number next to it, we can add the \texttt{\{-\}} attribute.

\textbf{More info}

And here's some other random info: the first paragraph after a chapter title or section head \emph{shouldn't be} indented, because indents are to tell the reader that you're starting a new paragraph. Since that's obvious after a chapter or section title, proper typesetting doesn't add an indent there.

\appendix

\hypertarget{the-first-appendix}{%
\chapter{The First Appendix}\label{the-first-appendix}}

This first appendix includes all of the R chunks of code that were hidden throughout the document (using the \texttt{include\ =\ FALSE} chunk tag) to help with readibility and/or setup.

\textbf{In the main Rmd file}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This chunk ensures that the thesisdown package is}
\CommentTok{# installed and loaded. This thesisdown package includes}
\CommentTok{# the template files for the thesis.}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(devtools))}
  \KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(thesisdown))}
\NormalTok{  devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"ismayc/thesisdown"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(thesisdown)}
\end{Highlighting}
\end{Shaded}
\textbf{In Chapter \ref{rmd-method}:}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This chunk ensures that the thesisdown package is}
\CommentTok{# installed and loaded. This thesisdown package includes}
\CommentTok{# the template files for the thesis and also two functions}
\CommentTok{# used for labeling and referencing}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(devtools))}
  \KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(dplyr))}
    \KeywordTok{install.packages}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(ggplot2))}
    \KeywordTok{install.packages}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(ggplot2))}
    \KeywordTok{install.packages}\NormalTok{(}\StringTok{"bookdown"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(thesisdown))\{}
  \KeywordTok{library}\NormalTok{(devtools)}
\NormalTok{  devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"ismayc/thesisdown"}\NormalTok{)}
\NormalTok{  \}}
\KeywordTok{library}\NormalTok{(thesisdown)}
\NormalTok{flights <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/flights.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\hypertarget{the-second-appendix-for-fun}{%
\chapter{The Second Appendix, for Fun}\label{the-second-appendix-for-fun}}

\backmatter

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\noindent

\setlength{\parindent}{-0.20in}
\setlength{\leftskip}{0.20in}
\setlength{\parskip}{8pt}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-Durst1960}{}%
C. S. Durst, B. A., O. B.E. (1960). Wind speeds over short periods of time. \emph{The Meteorological Magazine}, \emph{89}(1056), 181--187. Retrieved from \url{https://www.depts.ttu.edu/nwi/Pubs/ReportsJournals/ReportsJournals/Windspeeds.pdf}

\leavevmode\hypertarget{ref-Asce2017}{}%
Engineers, A. S. O. C. (2017). \emph{Minimum design loads and associated criteria for buildings and other structures (asce7-16)}. American Society of Civil Engineers. Retrieved from \url{https://www.ebook.de/de/product/35017614/american_society_of_civil_engineers_minimum_design_loads_and_associated_criteria_for_buildings_and_other_structures_7_16.html}

\leavevmode\hypertarget{ref-Harris1994}{}%
Harris, J. W., \& Stocker, H. (1998). Maximum likelihood method. In \emph{Handbook of mathematics and computational science} (p. 824). Springer-Verlag.

\leavevmode\hypertarget{ref-Hosking1997}{}%
Hosking, J. R. M., \& Wallis, J. R. (1997). \emph{Regional frequency analysis}. Cambridge University Press. \url{http://doi.org/10.1017/cbo9780511529443}

\leavevmode\hypertarget{ref-Kubler1994}{}%
Kubler, J. (1994). \emph{Computational Statistics \&Amp; Data Analysis}, \emph{18}(4), 473--474. Retrieved from \url{https://EconPapers.repec.org/RePEc:eee:csdana:v:18:y:1994:i:4:p:473-474}

\leavevmode\hypertarget{ref-Pickands1971}{}%
Pickands, J. (1971). The two-dimensional poisson process and extremal processes. \emph{Journal of Applied Probability}, \emph{8}(4), 745--756. \url{http://doi.org/10.2307/3212238}

\leavevmode\hypertarget{ref-Pintar2015}{}%
Pintar, A. L., Simiu, E., Lombardo, F. T., \& Levitan, M. L. (2015). \emph{Simple guide for evaluating and expressing the uncertainty of NIST MeasuremenMaps of non-hurricane non-tornadic wind speeds with specified mean recurrence intervals for the contiguous united states using a two-dimensional poisson process extreme value model and local regressiont results}. National Institute of Standards; Technology.

\leavevmode\hypertarget{ref-Simiu1996}{}%
Simiu, E., \& Scanlan, R. H. (1996). \emph{Wind effects on structures : Fundamentals and applications to design} (3rd ed.). New York : John Wiley. Retrieved from \url{http://lib.ugent.be/catalog/rug01:001267836}

\leavevmode\hypertarget{ref-Smith1989}{}%
Smith, R. L. (1989). Extreme value analysis of environmental time series: An application to trend detection in ground-level ozone. \emph{Statistical Science}, \emph{4}(4), 367--377. \url{http://doi.org/10.1214/ss/1177012400}

\leavevmode\hypertarget{ref-Smith2004}{}%
Smith, R. L. (2004). Extreme values in finance, telecommunications, and the environment (chapman \& hall/crc monographs on statistics and applied probability). In B. F. inkenstädt \& H. Rootzén (Eds.), (pp. 1--78). Chapman; Hall/CRC. Retrieved from \url{https://www.amazon.com/Telecommunications-Environment-Monographs-Statistics-Probability/dp/1584884118?SubscriptionId=AKIAIOBINVZYXZQZ2U3A\&tag=chimbori05-20\&linkCode=xm2\&camp=2025\&creative=165953\&creativeASIN=1584884118}


% Index?

\end{document}
