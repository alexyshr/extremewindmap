% This is the Reed College LaTeX thesis template. Most of the work
% for the document class was done by Sam Noble (SN), as well as this
% template. Later comments etc. by Ben Salzberg (BTS). Additional
% restructuring and APA support by Jess Youngberg (JY).
% Your comments and suggestions are more than welcome; please email
% them to cus@reed.edu
%
% See http://web.reed.edu/cis/help/latex.html for help. There are a
% great bunch of help pages there, with notes on
% getting started, bibtex, etc. Go there and read it if you're not
% already familiar with LaTeX.
%
% Any line that starts with a percent symbol is a comment.
% They won't show up in the document, and are useful for notes
% to yourself and explaining commands.
% Commenting also removes a line from the document;
% very handy for troubleshooting problems. -BTS

% As far as I know, this follows the requirements laid out in
% the 2002-2003 Senior Handbook. Ask a librarian to check the
% document before binding. -SN

%%
%% Preamble
%%
% \documentclass{<something>} must begin each LaTeX document
%\documentclass[12pt,twoside]{reedthesis}
\documentclass[12pt,oneside]{reedthesis} 
% Packages are extensions to the basic LaTeX functions. Whatever you
% want to typeset, there is probably a package out there for it.
% Chemistry (chemtex), screenplays, you name it.
% Check out CTAN to see: http://www.ctan.org/
%%
\usepackage{graphicx,latexsym}
\usepackage{amsmath}
\usepackage{amssymb,amsthm}
\usepackage{longtable,booktabs,setspace}
\usepackage{chemarr} %% Useful for one reaction arrow, useless if you're not a chem major
\usepackage[hyphens]{url}
\usepackage[utf8]{inputenc}
% Added by CII
\usepackage[hidelinks]{hyperref}  
% \usepackage{hyperref}
\usepackage{lmodern}
\usepackage{float}
\floatplacement{figure}{H}
% End of CII addition
\usepackage{rotating}

% Next line commented out by CII
%%% \usepackage{natbib}
% Comment out the natbib line above and uncomment the following two lines to use the new
% biblatex-chicago style, for Chicago A. Also make some changes at the end where the
% bibliography is included.
%\usepackage{biblatex-chicago}
%\bibliography{thesis}


% Added by CII (Thanks, Hadley!)
% Use ref for internal links
\renewcommand{\hyperref}[2][???]{\autoref{#1}}
\def\chapterautorefname{Chapter}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}
% End of CII addition

% Added by CII
\usepackage{caption}
\captionsetup{width=5in}
% End of CII addition

% \usepackage{times} % other fonts are available like times, bookman, charter, palatino

% Syntax highlighting #22
  \usepackage{color}
  \usepackage{fancyvrb}
  \newcommand{\VerbBar}{|}
  \newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
  % Add ',fontsize=\small' for more characters per line
  \usepackage{framed}
  \definecolor{shadecolor}{RGB}{248,248,248}
  \newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
  \newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
  \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
  \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\BuiltInTok}[1]{#1}
  \newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
  \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
  \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
  \newcommand{\ExtensionTok}[1]{#1}
  \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
  \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\ImportTok}[1]{#1}
  \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
  \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
  \newcommand{\NormalTok}[1]{#1}
  \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
  \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
  \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
  \newcommand{\RegionMarkerTok}[1]{#1}
  \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
  \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
  \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

% To pass between YAML and LaTeX the dollar signs are added by CII
\title{Spatio-temporal analysis of extreme wind velocities for infrastructure design}
\author{Alexys Herleym Rodríguez Avellaneda}
% The month and year that you submit your FINAL draft TO THE LIBRARY (May or December)
\date{Jan 2020}
\division{Institute for Geoinformatics - IFGI}
\advisor{Dr.~Edzer Pebesma}
\institution{University of Münster}
\degree{Master of Science in Geospatial Technologies}
%If you have two advisors for some reason, you can use the following
% Uncommented out by CII
\altadvisor{Dr.~Juan C. Reyes\textbackslash Dr.~Sara Ribero}
% End of CII addition

%%% Remember to use the correct department!
\department{Faculty of Geosciences}
% if you're writing a thesis in an interdisciplinary major,
% uncomment the line below and change the text as appropriate.
% check the Senior Handbook if unsure.
%\thedivisionof{The Established Interdisciplinary Committee for}
% if you want the approval page to say "Approved for the Committee",
% uncomment the next line
%\approvedforthe{Committee}

% Added by CII
%%% Copied from knitr
%% maxwidth is the original width if it's less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\renewcommand{\contentsname}{Table of Contents}
% End of CII addition

\setlength{\parskip}{0pt}

% Added by CII
  %\setlength{\parskip}{\baselineskip}
  \usepackage[parfill]{parskip}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\Acknowledgements{
I would like to thank Prof.~Dr.~Edzer Pebesma, Prof.~Dr.~Juan C. Reyes, and Prof.~Dr.~Sara Ribero, for supervising my work and spending their valuable time for discussions and feedback. It was really a huge advantage for me to have this always available support. It was a pleasure to work beside you. I want to thank Dr Adam Pintar and Engineer Juan David Sandoval for their support and contributions. My mother Ligia made possible all my achievements because she was always there with love, support and valuable advice and contributions. I am grateful with all my heart. Thanks to my daughter Nicolle Chaely for its love, support, and always pleasant company. I would like to thank the European Union -`Erasmus Mundus Grant', because their funding allow me to fulfill this dream to go further with my academic and professionals dreams.

\par

I especially want to thank to Dr.~Joaquín Huerta Guijarro, because he always was available to help and he was very friendly and receptive. Likewise, I want to thank some family members as Elsa Manrique, Barbara Avellaneda, and Kevin Martinez because they were always interested in my activities and also they were an important source of motivation and support.

\par

To all the beautiful people that shared with me different activities at the San Antonius Church of Muenster, with special mention of father Alejandro Serrano Palacios and choir friends.
}

\Dedication{
\begin{tabbing}
pdf \hspace{3em} \= Probability Distribution Function  \\
cdf \>  Cumulative Distribution Function \\
ppf \> Percent Point Function (Quantile) \\
hf \> Hazard Function \\
$P_e$ \> Annual Exceedance Probability \\
MRI \> Mean Return Interval or Return Period \\
$P_n$ \>  Compound Exceedance Probability \\
IDEAM \> Institute of Hydrology, Meteorology and Environmental Studies \\
ECMWF \>  European Center for Medium-Range Weather Forecasts \\
ERA5 \>  ECMWF climate reanalysis dataset  \\
GEVD \>  Generalized Extreme Value Distribution (EVD, GEV) \\
EVD \>  Extreme Value Distribution (GEVD, GEV)  \\
GEV \>  Generalized Extreme Value Distribution (GEVD, EVD)  \\
GPD \>  Generalized Pareto Distribution  \\
ISD \> Integrated Surface Database \\
AIS \> Seismic Engineering Association  \\
NSR \> Seismic Resistant Norm  \\
SEI \> Structural Engineering Institute \\
ASCE \> American Society of Civil Engineers \\
ASCE7-16 \> ASCE/SEI Design Loads Standard \\
NOAA \> National Oceanic and Atmospheric Administration \\
NetCDF \> Network Common Data Form \\
NCEI \> NOAA's National Centers for Environmental Information \\
EDA \>  Exploratory Data Analysis \\
POT \> Peaks Over Threshold \\
PP \> Poisson Process \\
RMSE \> Root Mean Squared Error \\
PACF \> Partial Autocorrelation Function \\
ACF \>  Autocorrelation Function \\
SQL \>  Structured Query Language \\
IDW \>  Inverse Distance Weighted \\
WGS84 \> World Geodetic System 1984 \\
RL \> Return Level
\end{tabbing}
}

\Preface{
Models of extreme values are used for designing against the effects of extreme events like earthquakes, winds, rainfall, floods of different types of physical processes, avoiding widespread destruction and loss of lives. This research presents a applied case of univariate extreme value analysis applied to wind velocities for infrastructure design, consequently, the main interest are probable future more extreme wind events that structures need to be able to resist.

This work in its theoretical and methodological component was directed by ASCE7-16 Engineers (\protect\hyperlink{ref-Asce2017}{2017}) considering that output products will be used to update the chapter B.6, wind forces, of the Colombian earthquake resistant standard - NSR-10, maintained by the Colombian Association of Seismic Engineering - AIS by its Spanish acronym. ASCE7-16, defines four risk categories, which implies the use of different wind loads (represented in wind extreme values for different mean recurrence intervals) for structures that belong to each category, 3000 years of MRI for risk IV, 1700 years for risk III, and 700 years for risk II and I.

This research has a particularly new situation regarding to the input data, and it is that not only time series of field measurements from meteorological stations are used (IDEAM data source), but also post-processed information coming from the Integrated Surface Database - ISD (USA database based on IDEAM data source), and forecast reanalysis data from ERA5. This condition demanded a comparison of the different data sources in order to verify the feasibility of using ERA5 and ISD, with a previous process of standardization of wind velocities to reach the needed requirement of 3-s wind gust speed, 10 meters anemometers high and open space condition.

At each station the used method Peaks Over Threshold - Poisson Process, required to identify all the non-thunderstorm events in the non-hurricane dataset through a process of de-clustering, choose a suitable threshold level to leave for the analysis only the most extreme values available, and then fit to the data a Gumbel extreme value distribution using maximum likelihood to find optimal parameters with the best goodness of fit. With the fitted model, it was possible to calculate return levels for required mean return intervals. Next, a process of spatial interpolation was done using Kriging, what allowed to have three continuous maps for the whole study area. Main interest writing this document, is help to readers to enter speedily with the current details around wind extreme analysis.
}

\Abstract{
For the input non-hurricane, non tornadic data in each available station of the study area (field measurement of forecast models), this research calculate extreme winds or return levels with three different mean recurrence intervals - MRI, 700, 1700, and 3000 years, with a change of being equaled or exceeded only one time in the corresponding MRI period. Then, continuous maps of wind extreme velocities are interpolated to cover the study area, which are mixed with existing wind extreme hurricane studies to be used as input loads for infrastructure design.

\par

Spatio-temporal analysis of historical wind data for infrastructure design, namely, \(-\) from wind time series represented in forecast models over rectangular areas or pixels with a virtual station at its center, or field measurements at weather stations in specific coordinates around the study area \(-\), calculate wind extreme magnitudes to be used as design loads of structures of different risk categories (bridges, houses, buildings, hospitals, etc), requires the use of statistical extreme value analysis methodologies to create maps with different mean recurrence intervals (MRI), \(-\) short ones for less risky/important structures, and long ones for highly important structures.

Method used to calculate the return levels at each station the Peaks Over Threshold - POT, using a non-homogeneous, bi-dimensional Poisson Process described, recommended by Engineers (\protect\hyperlink{ref-Asce2017}{2017}), and developed and implemented in Pintar, Simiu, Lombardo, \& Levitan (\protect\hyperlink{ref-Pintar2015}{2015}). To interpolate maps a geostatistical procedure using Kriging was implemented, considering the model with the best goodness of fit from model parameters comparison.
}

	\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
% End of CII addition
%%
%% End Preamble
%%
%
\begin{document}

% Everything below added by CII
  \maketitle

\frontmatter % this stuff will be roman-numbered
\pagestyle{empty} % this removes page numbers from the frontmatter
  \begin{acknowledgements}
    I would like to thank Prof.~Dr.~Edzer Pebesma, Prof.~Dr.~Juan C. Reyes, and Prof.~Dr.~Sara Ribero, for supervising my work and spending their valuable time for discussions and feedback. It was really a huge advantage for me to have this always available support. It was a pleasure to work beside you. I want to thank Dr Adam Pintar and Engineer Juan David Sandoval for their support and contributions. My mother Ligia made possible all my achievements because she was always there with love, support and valuable advice and contributions. I am grateful with all my heart. Thanks to my daughter Nicolle Chaely for its love, support, and always pleasant company. I would like to thank the European Union -`Erasmus Mundus Grant', because their funding allow me to fulfill this dream to go further with my academic and professionals dreams.
    
    \par
    
    I especially want to thank to Dr.~Joaquín Huerta Guijarro, because he always was available to help and he was very friendly and receptive. Likewise, I want to thank some family members as Elsa Manrique, Barbara Avellaneda, and Kevin Martinez because they were always interested in my activities and also they were an important source of motivation and support.
    
    \par
    
    To all the beautiful people that shared with me different activities at the San Antonius Church of Muenster, with special mention of father Alejandro Serrano Palacios and choir friends.
  \end{acknowledgements}
  \begin{preface}
    Models of extreme values are used for designing against the effects of extreme events like earthquakes, winds, rainfall, floods of different types of physical processes, avoiding widespread destruction and loss of lives. This research presents a applied case of univariate extreme value analysis applied to wind velocities for infrastructure design, consequently, the main interest are probable future more extreme wind events that structures need to be able to resist.
    
    This work in its theoretical and methodological component was directed by ASCE7-16 Engineers (\protect\hyperlink{ref-Asce2017}{2017}) considering that output products will be used to update the chapter B.6, wind forces, of the Colombian earthquake resistant standard - NSR-10, maintained by the Colombian Association of Seismic Engineering - AIS by its Spanish acronym. ASCE7-16, defines four risk categories, which implies the use of different wind loads (represented in wind extreme values for different mean recurrence intervals) for structures that belong to each category, 3000 years of MRI for risk IV, 1700 years for risk III, and 700 years for risk II and I.
    
    This research has a particularly new situation regarding to the input data, and it is that not only time series of field measurements from meteorological stations are used (IDEAM data source), but also post-processed information coming from the Integrated Surface Database - ISD (USA database based on IDEAM data source), and forecast reanalysis data from ERA5. This condition demanded a comparison of the different data sources in order to verify the feasibility of using ERA5 and ISD, with a previous process of standardization of wind velocities to reach the needed requirement of 3-s wind gust speed, 10 meters anemometers high and open space condition.
    
    At each station the used method Peaks Over Threshold - Poisson Process, required to identify all the non-thunderstorm events in the non-hurricane dataset through a process of de-clustering, choose a suitable threshold level to leave for the analysis only the most extreme values available, and then fit to the data a Gumbel extreme value distribution using maximum likelihood to find optimal parameters with the best goodness of fit. With the fitted model, it was possible to calculate return levels for required mean return intervals. Next, a process of spatial interpolation was done using Kriging, what allowed to have three continuous maps for the whole study area. Main interest writing this document, is help to readers to enter speedily with the current details around wind extreme analysis.
  \end{preface}
  \hypersetup{linkcolor=black}
  \setcounter{tocdepth}{4}
  \tableofcontents

  \listoftables

  \listoffigures
  \begin{abstract}
    For the input non-hurricane, non tornadic data in each available station of the study area (field measurement of forecast models), this research calculate extreme winds or return levels with three different mean recurrence intervals - MRI, 700, 1700, and 3000 years, with a change of being equaled or exceeded only one time in the corresponding MRI period. Then, continuous maps of wind extreme velocities are interpolated to cover the study area, which are mixed with existing wind extreme hurricane studies to be used as input loads for infrastructure design.
    
    \par
    
    Spatio-temporal analysis of historical wind data for infrastructure design, namely, \(-\) from wind time series represented in forecast models over rectangular areas or pixels with a virtual station at its center, or field measurements at weather stations in specific coordinates around the study area \(-\), calculate wind extreme magnitudes to be used as design loads of structures of different risk categories (bridges, houses, buildings, hospitals, etc), requires the use of statistical extreme value analysis methodologies to create maps with different mean recurrence intervals (MRI), \(-\) short ones for less risky/important structures, and long ones for highly important structures.
    
    Method used to calculate the return levels at each station the Peaks Over Threshold - POT, using a non-homogeneous, bi-dimensional Poisson Process described, recommended by Engineers (\protect\hyperlink{ref-Asce2017}{2017}), and developed and implemented in Pintar, Simiu, Lombardo, \& Levitan (\protect\hyperlink{ref-Pintar2015}{2015}). To interpolate maps a geostatistical procedure using Kriging was implemented, considering the model with the best goodness of fit from model parameters comparison.
  \end{abstract}
  \begin{dedication}
    \begin{tabbing}
    pdf \hspace{3em} \= Probability Distribution Function  \\
    cdf \>  Cumulative Distribution Function \\
    ppf \> Percent Point Function (Quantile) \\
    hf \> Hazard Function \\
    $P_e$ \> Annual Exceedance Probability \\
    MRI \> Mean Return Interval or Return Period \\
    $P_n$ \>  Compound Exceedance Probability \\
    IDEAM \> Institute of Hydrology, Meteorology and Environmental Studies \\
    ECMWF \>  European Center for Medium-Range Weather Forecasts \\
    ERA5 \>  ECMWF climate reanalysis dataset  \\
    GEVD \>  Generalized Extreme Value Distribution (EVD, GEV) \\
    EVD \>  Extreme Value Distribution (GEVD, GEV)  \\
    GEV \>  Generalized Extreme Value Distribution (GEVD, EVD)  \\
    GPD \>  Generalized Pareto Distribution  \\
    ISD \> Integrated Surface Database \\
    AIS \> Seismic Engineering Association  \\
    NSR \> Seismic Resistant Norm  \\
    SEI \> Structural Engineering Institute \\
    ASCE \> American Society of Civil Engineers \\
    ASCE7-16 \> ASCE/SEI Design Loads Standard \\
    NOAA \> National Oceanic and Atmospheric Administration \\
    NetCDF \> Network Common Data Form \\
    NCEI \> NOAA's National Centers for Environmental Information \\
    EDA \>  Exploratory Data Analysis \\
    POT \> Peaks Over Threshold \\
    PP \> Poisson Process \\
    RMSE \> Root Mean Squared Error \\
    PACF \> Partial Autocorrelation Function \\
    ACF \>  Autocorrelation Function \\
    SQL \>  Structured Query Language \\
    IDW \>  Inverse Distance Weighted \\
    WGS84 \> World Geodetic System 1984 \\
    RL \> Return Level
    \end{tabbing}
  \end{dedication}
\mainmatter % here the regular arabic numbering starts
\pagestyle{fancyplain} % turns page numbering back on

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

This research aims to create non-hurricane non-tornadic maps of extreme wind speeds for \emph{three specific recurrence intervals} (700, 1700, and 3000 years) covering the Colombian territory. These maps will be combined with existing hurricane wind speed studies, to be used as input loads due to wind for infrastructure design.

For each station with wind speeds time histories in the input data, extreme wind speed corresponding to each recurrence interval are calculated using a \emph{Peaks Over Threshold} onwards \emph{POT} extreme value model, then wind velocities with the same recurrence interval are \emph{spatially interpolated} to generate continuous maps for the whole study area.

A wind speed linked to a \emph{mean recurrence interval - MRI} of \emph{N-years} (N-years return value or return period) is interpreted as the highest probable wind speed along the period of N-years. The annual probability of equal or exceed that wind speed is 1/N. The annual exceedance probability for all velocity values in 700-years output map will be 1/700, for the 1700-years map will be 1/1700, and 1/3000 for the 3000-years final map.

There are different methods to model extreme value data, among them are a) sample maxima using a \emph{Generalized Extreme Value Distribution} onwards \emph{GEVD} (traditional method), b) POT using a \emph{Generalized Pareto Distribution} onwards \emph{GPD}, c) POT using a two-dimensional Poisson Process, that can be homogeneous, non-homogeneous, stationary, and non-stationary (originally know as \emph{Point Process} approach), and d) POT Poisson-GPD. Following Pintar et al. (\protect\hyperlink{ref-Pintar2015}{2015}) in this research a \emph{POT using a non-homogeneous non-stationary two-dimensional Poisson proces} was selected, despite there is no R package available to apply this approach.

\hypertarget{background}{%
\section{Background}\label{background}}

To design one structure, the horizontal forces wind and earthquake play an starring role. For the study area, Colombia, initially the wind force was considered with the decree 1984 as a fixed velocity \(100 \frac{Km}{h}\), later a continuous map with a return period of 50 years was included in the official design standard of the time (NSR-98), then, with the update to NSR-10, an additional map with return period of 700 yeas was included.

In the context of this study, extreme wind analysis is concerned with statistical methods applied to very high values of wind as random variable in a stochastic process, to allow statistical inference from historical data, namely, assess from the ordered sample of wind velocities, the probability of wind events that are more extreme than the ones previously observed and included in the mentioned input sample. Classical reference in this matter is Coles (\protect\hyperlink{ref-Coles2001}{2001}), where a detailed study is done about classical extreme value theory and models and threshold models. There are four main approaches to deal with extreme value analysis: - sample maxima associated to a Generalized Extreme Value Distribution - GEV, - exceedances over threshold associated to a Generalized Pareto Distribution - GPD, - the Poisson-GPD, an homogeneous Poisson process for the number of exceedances and a GPD for the excess values, and the exceedances over threshold associated to a non- homogeneous bi-dimensional Poisson process, a Point process approach also known as Peaks Over Threshold - POT - Poisson process. Main details will be discussed here for each method, but as the last one is recommended in Asce2017, a more indeed explanation will be provided in for \protect\hyperlink{pot-pp}{POT-Poisson Process}.

\hypertarget{sample-maxima}{%
\subsection{Sample maxima}\label{sample-maxima}}

To work with random variables of sample maximum values, the used probability distribution function \emph{pdf} is the GEV

\[
H(y) = \exp\left\{-\left(1+\xi\frac{y-\mu}{\psi}\right)_+^{-\frac{1}{\xi}}\right\},
\]
\((y+=max(y,0))\) where \(\mu\) is the location parameter, \(\psi > 0\) is a scale parameter, and \(\xi\) is a shape parameter. GEV can be seen as the integration in the same \emph{psf} of the Gumbel distribution (limit \(\xi\rightarrow0\)), Fréchet distribution (\(\xi>0\)), and Weibull distribution (\(\xi<0\)).

\hypertarget{exceedances-over-threshold}{%
\subsection{Exceedances over threshold}\label{exceedances-over-threshold}}

If the researcher needs to work only with extreme values above an specific threshold, Pickands (\protect\hyperlink{ref-Pickands1971}{1971}) showed that the GEV has a GPD approximation where shape \(\xi\) parameter in previous equation is the same parameter for next equation for GPD,

\[
G(y,\sigma, \xi) = 1-\left(1+\xi\frac{y}{\sigma}\right)_+^{-\frac{1}{\xi}},
\]
\#\#\# Poisson-GPD
If a rescale of the variable indexes above the threshold is performed, then the exceedances over threshold approach can be seen as a point process, namely, an homogeneous Poisson Process where:
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The number of exceedances above the threshold has a Poisson distribution with mean \(\lambda\)
\item
  The excess values follow a GPD with \(N\leq1\)
\end{enumerate}
Its cumulative distribution function \emph{cdf} is

\[
F(y) = \exp\left\{-\lambda\left(1+\xi\frac{y-\mu}{\sigma}\right)_+^{-\frac{1}{\xi}}\right\},
\]

\hypertarget{research-aim-and-objectives}{%
\section{Research Aim and Objectives}\label{research-aim-and-objectives}}

Main aim of this research is the estimation of wind extreme velocities to be used as input loads for the design of different types of structures, considering its risk categories, and covering any place in the whole study area.

Specific objectives are:
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Analyze and compare three different sources of historical wind time series, to select and use the best data source (or combination or sources) for research, based on objective criteria, for instance similitude, completeness, coverage, etcetera, to achieve this way a formal support for the decision made in this regard.
\item
  Select and apply an suitable extreme value analysis method that allows to fulfill wind load requirements defined for the respective authority in the study area
\item
  Estimate extreme wind values for the stations in the selected input data source, for three MRI (700, 1700, 3000 years), considering non-hurricane studies.
\item
  Generate continuous maps for MRIs 700, 1700, and 3000 years, using the most suitable spatial interpolation technique, considering the specific characteristics of the input data and advantages and disadvantages of the selected methods
\item
  Combine output maps from non-hurricane analysis, with existing hurricane studies to allow the inclusion of the research study in the NSR-10 norm.
\end{enumerate}
\hypertarget{research-question}{%
\section{Research Question}\label{research-question}}

Main question of this research is directed to calculate future extreme velocities (return levels) for infrastructure design, then the research question could be

\textbf{What extreme velocities (return levels) need to be used as load design forces for structures of different use category, in the study area?}

If we remember that, for the case study area (Colombia), there are predefined requirements or mean return intervals - MRI to design structures depending of it use category, and that this MRI values are 700, 1700, and 3000 years, the research question could be more specific.

\textbf{What extreme velocities (return levels) will be equaled or exceeded with a probability equal to \(\frac{1}{MRI}\) in a given year?}

\textbf{What extreme velocities (return levels) will be equaled or exceeded only one time in the period defined for this specific MRIs: 700, 1700, and 3000 years?}

If we consider not only the annual exceedance probability \(\frac{1}{MRI}\), but also the exposure time (compound probability), understood as the time the structure will be in use, then the question will be

\textbf{What extreme velocities (return levels) will have a occurrence compound probability of 67\%, when the exposure time of the structure will be equal to the main return intervals 700, 1700, and 3000 years?}

\hypertarget{thesis-document-structure}{%
\section{Thesis Document Structure}\label{thesis-document-structure}}

\hypertarget{rmd-data}{%
\chapter{Data}\label{rmd-data}}

Input data is made up of three different sources a) IDEAM - Institute of Hydrology, Meteorology and Environmental Studies of Colombia \url{http://www.ideam.gov.co}, b) ISD - Integrated Surface Database \url{https://www.ncdc.noaa.gov/isd}, and c) ERA5 climate reanalysis \url{https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5}.

\begingroup\fontsize{10}{12}\selectfont
\begin{longtable}[t]{l>{\raggedright\arraybackslash}p{0.8in}>{\raggedright\arraybackslash}p{4in}}
\caption[Datasets]{\label{tab:tabledatasources1}Datasets description}\\
\toprule
\multicolumn{1}{l}{Institution} & \multicolumn{1}{l}{Dataset} & \multicolumn{1}{l}{Details}\\
\midrule
IDEAM & Historical records at weather stations & IDEAM is responsible for the instalation, maintenance and management of all kind of weather stations located everywhere along the country\\
NOAA & ISD & ISD (Integrated Surface Database. NOAA's National Centers for Environmental Information - NCEI) Lite: A subset from the full ISD dataset containing eight common surface parameters in a fixed-width format free of duplicate values, sub-hourly data, and complicated flags.\\
ECMWF & ERA5 & ERA5 is a reanalysis dataset with hourly estimates of atmospheric variables with horizontal resolution of 0.25º (33 kilómeters), this is equally spaced cells every 0.25 degrees\\
\bottomrule
\end{longtable}
\endgroup{}

\begingroup\fontsize{10}{12}\selectfont
\begin{longtable}[t]{l>{\raggedright\arraybackslash}p{1.2in}>{\raggedright\arraybackslash}p{3.5in}}
\caption[Variables]{\label{tab:tabledatasources2}Datasets variables}\\
\toprule
\multicolumn{1}{l}{Dataset} & \multicolumn{1}{l}{Variables} & \multicolumn{1}{l}{Description}\\
\midrule
IDEAM & vvmx\_aut\_60 & Hourly wind maximun velocity\\
ISD & wind speed rate & Maximun hourly wind velocity. The rate of horizontal travel of air past a fixed point.\\
ERA5 & fg10 & 10 metre wind gust since previous post-processing\\
 & fsr & Forecast Surface Roughness\\
\bottomrule
\end{longtable}
\endgroup{}

\begingroup\fontsize{10}{12}\selectfont
\begin{longtable}[t]{l>{\raggedright\arraybackslash}p{0.8in}>{\raggedright\arraybackslash}p{3in}l}
\caption[Units and Time]{\label{tab:tabledatasources3}Variables units and time}\\
\toprule
\multicolumn{1}{l}{Variable} & \multicolumn{1}{l}{Units} & \multicolumn{1}{l}{Time} & \multicolumn{1}{l}{Stations}\\
\midrule
vvmx\_aut\_60 & meters per second & Variable from 2001 until today. Irregular time series. & 203\\
Wind speed & meters per second & Variable from 1941 until today. Note: There is too much variability in time (start, end, and time range) for each station. Irregutal time series. & 101\\
fg10 & meters per second & 1979-Today & 3381\\
fsr & meters per second & 1979-Today & 3381\\
\bottomrule
\end{longtable}
\endgroup{}

Ideal data source to create extreme wind speeds maps should be field observed data from IDEAM, but there are not enough number of stations around the study area to represent all the local wind variability in a huge country with multiple variety of climates and and changing thermal floors, but there are other important motivation to include different sources trying to improve output results:
\begin{itemize}
\tightlist
\item
  As just mentioned, low quantity of IDEAM stations
\item
  There are uncertainties related to the way IDEAM anemometers are registering data, then comparison with other data sources are needed to be able to do appropriate data standardization, needed as a prerequisite to the analysis.
\item
  There is no time continuity in the registration of IDEAM data. Historical time series are different and variable in each station.
\end{itemize}
Importance of ISD database for this study is based on the fact that post-processed ISD database has wind extreme values, and it was used to create extreme wind maps for United States. ISD allows comparison with IDEAM records to take better decisions in order to do needed data standardization.

Despite that ERA5 data are not observed data, but forecast, its main advantage is data availability to assess the local climatic variance every 33 square kilometers.

\hypertarget{ideam}{%
\section{IDEAM}\label{ideam}}

Historical observed wind speeds from 203 in Colombia are managed by the official environmental authority IDEAM. Table \ref{tab:tableideamstations} shows a sample of five IDEAM stations. Figure \ref{fig:plotideamstations} shows a map of IDEAM stations.
\begin{longtable}[t]{lrr}
\caption[IDEAM Stations]{\label{tab:tableideamstations}IDEAM Stations sample}\\
\toprule
Name[Code] & Latitud & Longitud\\
\midrule
EMAS - AUT [26155230] & 5.09 & -75.51\\
SAN BENITO - AUT [25025380] & 9.16 & -75.04\\
AEROPUERTO ALFONSO LOPEZ - [28025502] & 10.44 & -73.25\\
TIBAITATA - AUT [21206990] & 4.69 & -74.21\\
ELDORADO CATAM - AUT [21205791] & 4.71 & -74.15\\
\bottomrule
\end{longtable}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotideamstations-1.pdf}
\caption{\label{fig:plotideamstations}IDEAM Stations}
\end{figure}
Following, the time serie, autocorrelation function, and partial autocorrelation function, for IDEAM station ``21205791'' will be displayed.
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneideamstation-1.pdf}
\caption{\label{fig:plotoneideamstation}IDEAM Station - Time Serie}
\end{figure}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneideamstationacf-1.pdf}
\caption{\label{fig:plotoneideamstationacf}IDEAM Station ACF}
\end{figure}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneideamstationpacf-1.pdf}
\caption{\label{fig:plotoneideamstationpacf}IDEAM Station PACF}
\end{figure}
\hypertarget{isd}{%
\section{ISD}\label{isd}}

ISD is a database with environmental variables among then extreme wind speeds. ISD has data for the whole planet, and is based on observed data at meteorological stations in each country, which means that for Colombia is based on IDEAM data. Main advantage is data availability at neighbor countries and specialized post-processing made by NOAA's National Centers for Environmental Information - NCEI in United States, which facilitates its use.Table \ref{tab:tableisdstations} shows a sample of five ISD stations. Figure \ref{fig:plotisdstations} shows a map of ISD stations.
\begin{longtable}[t]{llrr}
\caption[ISD Stations]{\label{tab:tableisdstations}ISD Stations sample}\\
\toprule
Code & Name & Latitud & Longitud\\
\midrule
804400 & BARINAS & 8.62 & -70.22\\
800810 & ALTO CURICHE & 7.05 & -76.35\\
801000 & BAHIA SOLANO / JOSE MUTIS & 6.18 & -77.40\\
802590 & ALFONSO BONILLA ARAGON INTL & 3.54 & -76.38\\
803150 & BENITO SALAS & 2.95 & -75.29\\
\bottomrule
\end{longtable}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotisdstations-1.pdf}
\caption{\label{fig:plotisdstations}ISD Stations}
\end{figure}
Following, the time series, autocorrelation function, and partial autocorrelation function, for ISD station ``802590'' will be displayed.
\begin{verbatim}
select "mydatetime", "802590" as "X802590" from isd_lite_unstack where "802590" IS NOT NULL
\end{verbatim}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneisdstation-1.pdf}
\caption{\label{fig:plotoneisdstation}ISD Station - Time Series}
\end{figure}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneisdstationacf-1.pdf}
\caption{\label{fig:plotoneisdstationacf}ISD Station ACF}
\end{figure}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotoneisdstationpacf-1.pdf}
\caption{\label{fig:plotoneisdstationpacf}IDEAM Station PACF}
\end{figure}
\hypertarget{era5}{%
\section{ERA5}\label{era5}}

ERA5 is forecast reanalysis data processed by the \emph{European Center for Medium-Range Weather Forecasts} - ECMWF with wind speeds time series in square cells \emph{matrix of pixels} of 0.25 degrees (33 km) covering the whole planet. For the study area was extracted a raster of 69 rows by 49 XXX columns in format NetCDF. Figure \ref{fig:plotera5stations} shows a map of ERA5 stations (cells centers).
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotera5stations-1.pdf}
\caption{\label{fig:plotera5stations}ERA5 Stations (cells centers)}
\end{figure}
\hypertarget{data-download-and-organization}{%
\section{Data Download and Organization}\label{data-download-and-organization}}

\hypertarget{data-standardization}{%
\section{Data Standardization}\label{data-standardization}}

Analysis of extreme wind speeds requires data standardization as initial step. All input data must be standardized to represent three important conditions: a) anemometer height of 10 meters, b) open space roughness, and c) averaging time of 3-seconds wind gust. Data for analysis must represent 3-s peak wind speeds 10 meters height above the surface, in open terrain.
* 10 meters anemometer height
* Open space terrain roughness
* 3-s gust averaging time

\clearpage

\hypertarget{rmd-thefra}{%
\chapter{Theoretical Framework}\label{rmd-thefra}}

\hypertarget{probability-concepts}{%
\section{Probability Concepts}\label{probability-concepts}}

Poisson process is an stochastic method that relies in the concepts of probability distributions. The main functions related to probability for extreme value analysis will be described below.

\hypertarget{probability-density-function---pdf}{%
\subsection{\texorpdfstring{Probability Density Function - \emph{pdf}}{Probability Density Function - pdf}}\label{probability-density-function---pdf}}

\emph{Pdf} defines the probability that a continuous variable falls between two points, this is, in \emph{pdf} the probability is related to the area below the curve (integral) between two points, as for continuous probability distributions the probability at a single point is zero. The term density is directly related to the probability of a portion of the curve, if the density function has high values the probability will be greater in comparison with the same portion of curve for low values.

\[
\int_a^b f(x)dx = Pr[a \leq X \leq b]
\]

Equation \eqref{eq:gumbelpdf} is the Gumbel \emph{pdf}.
\begin{equation}
  \mathrm{
          f(x)=\frac{1}{\beta}
          \exp\left\{
            -\frac{x-\mu}{\beta}
          \right\}
          \exp\left\{
            -\exp\left\{
              -\left(
                \frac{x-\mu}{\beta}
              \right)
            \right\}
          \right\},
          \quad -\infty < x < \infty
         }
  \label{eq:gumbelpdf}
\end{equation}
where \(\exp\left\{.\right\} \mapsto \mathrm{e}^{\left\{.\right\}}\), \(\beta\) is the scale parameter, and \(\mu\) is the location parameter. Location (\(\mu\)) has the effect to shift the \emph{pdf} to left or right along `x' axis, thus, if location value is changed the effect is a movement of \emph{pdf} to the left (small value for location), or to the right (big value for location). Scale has the effect to stretch (\(\beta > 1\)) of compress (\(0 < \beta< 1\)) the \emph{pdf}, if scale parameter is close to zero the \emph{pdf} approaches a spike.

Figure \ref{fig:plotgumbelpdffunction} shows \emph{pdf} with location (\(\mu\)) = 100 and scale (\(\beta\)) = 40, using equation \eqref{eq:gumbelpdf}.

\footnotesize
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location =}\StringTok{ }\DecValTok{100}
\NormalTok{scale =}\StringTok{ }\DecValTok{40}
\NormalTok{.x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DataTypeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{pdfG <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
  \DecValTok{1}\OperatorTok{/}\NormalTok{location }\OperatorTok{*}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{-}\NormalTok{location)}\OperatorTok{/}\NormalTok{scale)}\OperatorTok{*}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{-}\NormalTok{location)}\OperatorTok{/}\NormalTok{scale))}
\NormalTok{  \}}
\NormalTok{.y =}\StringTok{ }\KeywordTok{pdfG}\NormalTok{(.x)}
\KeywordTok{plot}\NormalTok{(.x, .y, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{4}\NormalTok{, }
     \DataTypeTok{xlab=}\StringTok{"Velocities Km/h"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Density Function - Gumbel Distribution"}\NormalTok{, }
     \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Gumbel - Density Function Gumbel Distribution}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\StringTok{"Location="}\NormalTok{, }
     \KeywordTok{round}\NormalTok{(location,}\DecValTok{2}\NormalTok{), }\StringTok{" Scale="}\NormalTok{, }\KeywordTok{round}\NormalTok{(scale,}\DecValTok{2}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }
     \DataTypeTok{cex.axis =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{cex.lab=} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{cex.main=}\FloatTok{0.7}\NormalTok{, }\DataTypeTok{cex.sub=}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelpdffunction-1.pdf}
\caption{\label{fig:plotgumbelpdffunction}Gumbel pdf}
\end{figure}
\normalsize

Figure \ref{fig:plotgumbelpdf} shows \emph{pdf} with location (\(\mu\)) = 100 and scale (\(\beta\)) = 40, using function \texttt{dgumbel} of the package \texttt{RcmdrMisc}

\footnotesize
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location =}\StringTok{ }\DecValTok{100}
\NormalTok{scale =}\StringTok{ }\DecValTok{40}
\NormalTok{.x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DataTypeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{dfG =}\StringTok{ }\KeywordTok{dgumbel}\NormalTok{(.x, }\DataTypeTok{location=}\NormalTok{location, }\DataTypeTok{scale=}\NormalTok{scale)}
\KeywordTok{plot}\NormalTok{(.x, dfG, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{4}\NormalTok{, }
     \DataTypeTok{xlab=}\StringTok{"Velocities Km/h"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Density Function - Gumbel Distribution"}\NormalTok{, }
     \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Gumbel - Density Function Gumbel Distribution}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\StringTok{"Location="}\NormalTok{, }
     \KeywordTok{round}\NormalTok{(location,}\DecValTok{2}\NormalTok{), }\StringTok{" Scale="}\NormalTok{, }\KeywordTok{round}\NormalTok{(scale,}\DecValTok{2}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }
     \DataTypeTok{cex.axis =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{cex.lab=} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{cex.main=}\FloatTok{0.7}\NormalTok{, }\DataTypeTok{cex.sub=}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelpdf-1.pdf}
\caption{\label{fig:plotgumbelpdf}Gumbel pdf - dgumbel function}
\end{figure}
\normalsize

\hypertarget{cumulative-distribution-function---cdf}{%
\subsection{\texorpdfstring{Cumulative Distribution Function - \emph{cdf}}{Cumulative Distribution Function - cdf}}\label{cumulative-distribution-function---cdf}}

\emph{Cdf} is the probability of taking a value less than or equal to x. That is

\[
F(x) = Pr[X < x] = \alpha
\]
For a continuous variable, \emph{cdf} can be expressed as the integral of its \emph{pdf}.
\[
F(x) = \int_{-\infty}^x f(x)dx
\]

Equation \eqref{eq:gumbelcdf} is the Gumbel \emph{cdf}.
\begin{equation}
\mathrm{
        F(x) = \exp\left\{-\exp\left[-\left(\frac{x-\mu}{\beta}\right)\right]\right\}, 
        \quad -\infty < x < \infty
        }
  \label{eq:gumbelcdf}
\end{equation}
Figure \ref{fig:plotgumbelcdffunction} shows Gumbel \emph{cdf} with location (\(\mu\)) = 100 and scale (\(\beta\)) = 40, using equation \eqref{eq:gumbelcdf}. As previously done with \emph{pdf}, similar result can be achieved using function \texttt{pgumbel} of package \texttt{RcmdrMisc}.

\footnotesize
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location =}\StringTok{ }\DecValTok{100}
\NormalTok{scale =}\StringTok{ }\DecValTok{40}
\NormalTok{.x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DataTypeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{cdfG <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
  \KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{-}\NormalTok{location)}\OperatorTok{/}\NormalTok{scale))}
\NormalTok{  \}}
\NormalTok{.y =}\StringTok{ }\KeywordTok{cdfG}\NormalTok{(.x)}
\KeywordTok{plot}\NormalTok{(.x, .y, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{4}\NormalTok{, }
     \DataTypeTok{xlab=}\StringTok{"Velocities Km/h"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Probability"}\NormalTok{, }
     \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Gumbel - Cumulative Distribution Function}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\StringTok{"Location="}\NormalTok{, }
     \KeywordTok{round}\NormalTok{(location,}\DecValTok{2}\NormalTok{), }\StringTok{" Scale="}\NormalTok{, }\KeywordTok{round}\NormalTok{(scale,}\DecValTok{2}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }
     \DataTypeTok{cex.axis =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{cex.lab=} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{cex.main=}\FloatTok{0.7}\NormalTok{, }\DataTypeTok{cex.sub=}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelcdffunction-1.pdf}
\caption{\label{fig:plotgumbelcdffunction}Gumbel cdf}
\end{figure}
\normalsize

\hypertarget{percent-point-function---ppf}{%
\subsection{\texorpdfstring{Percent Point Function - \emph{ppf}}{Percent Point Function - ppf}}\label{percent-point-function---ppf}}

\emph{Ppf} is the inverse of \emph{cdf}, also called the \emph{quantile} function. This is, from a specific probability get the corresponding value x of the variable.

\[
x = G(\alpha) = G(F(x))
\]
Equation \eqref{eq:gumbelppf} is the Gumbel \emph{ppf}.
\begin{equation}
\mathrm{
        G(\alpha) = \mu-\beta ln(-ln(\alpha))
        \quad 0 < \alpha < 1
        }
  \label{eq:gumbelppf}
\end{equation}
Figure \ref{fig:plotgumbelppffunction} shows Gumbel \emph{ppf}, using equation \eqref{eq:gumbelppf}. Similar result can be achieved using function \texttt{qgumbel} of package \texttt{RcmdrMisc}.

\footnotesize
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location =}\StringTok{ }\DecValTok{100}
\NormalTok{scale =}\StringTok{ }\DecValTok{40}
\NormalTok{.x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DataTypeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{ppfG <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  location }\OperatorTok{-}\StringTok{ }\NormalTok{(scale}\OperatorTok{*}\KeywordTok{log}\NormalTok{(}\OperatorTok{-}\KeywordTok{log}\NormalTok{(x)))}
\NormalTok{  \}}
\NormalTok{.y =}\StringTok{ }\KeywordTok{ppfG}\NormalTok{(.x)}
\KeywordTok{plot}\NormalTok{(.x, .y, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{4}\NormalTok{, }
     \DataTypeTok{ylab=}\StringTok{"Velocities Km/h"}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"Probability"}\NormalTok{, }
     \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Gumbel - Percent Point Function}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\StringTok{"Location="}\NormalTok{, }
     \KeywordTok{round}\NormalTok{(location,}\DecValTok{2}\NormalTok{), }\StringTok{" Scale="}\NormalTok{, }\KeywordTok{round}\NormalTok{(scale,}\DecValTok{2}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }
     \DataTypeTok{cex.axis =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{cex.lab=} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{cex.main=}\FloatTok{0.7}\NormalTok{, }\DataTypeTok{cex.sub=}\FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelppffunction-1.pdf}
\caption{\label{fig:plotgumbelppffunction}Gumbel cdf}
\end{figure}
\normalsize

\hypertarget{hazard-function---hf}{%
\subsection{\texorpdfstring{Hazard Function - \emph{hf}}{Hazard Function - hf}}\label{hazard-function---hf}}

Using \(S(x) = 1 - F(x)\) as survival function -\emph{sf}, the probability that a variable takes a value greater than x \(S(x) = Pr[X > x] = 1 - F(x)\), the \emph{hf} is the ratio between \emph{pdf} and \emph{sf}.

\[
h(x) = \frac{f(x)}{S(x)} = \frac{f(x)}{1-F(x)}
\]
Equation \eqref{eq:gumbelhf} is the Gumbel \emph{ppf}.
\begin{equation}
\mathrm{
        h(x)= \frac{1}{\beta}\frac{\exp(-(x-\mu)/\beta)}{\exp(\exp(-(x-\mu)/\beta))-1}
       }
  \label{eq:gumbelhf}
\end{equation}
Figure \ref{fig:plotgumbelhffunction} shows Gumbel \emph{hf}, using equation \eqref{eq:gumbelhf}.

\footnotesize
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{location =}\StringTok{ }\DecValTok{100}
\NormalTok{scale =}\StringTok{ }\DecValTok{40}
\NormalTok{.x <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1500}\NormalTok{, }\DataTypeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{hfG <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  (}\DecValTok{1}\OperatorTok{/}\NormalTok{scale)}\OperatorTok{*}\NormalTok{(}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{-}\NormalTok{location)}\OperatorTok{/}\NormalTok{scale))}\OperatorTok{/}\NormalTok{(}\KeywordTok{exp}\NormalTok{(}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{-}\NormalTok{location)}\OperatorTok{/}\NormalTok{scale))}\OperatorTok{-}\DecValTok{1}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{.y =}\StringTok{ }\KeywordTok{hfG}\NormalTok{(.x)}
\KeywordTok{plot}\NormalTok{(.x, .y, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{4}\NormalTok{, }
     \DataTypeTok{xlab=}\StringTok{"Velocities Km/h"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Hazard"}\NormalTok{, }
     \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Gumbel - Hazard Function}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, }\StringTok{"Location="}\NormalTok{, }
     \KeywordTok{round}\NormalTok{(location,}\DecValTok{2}\NormalTok{), }\StringTok{" Scale="}\NormalTok{, }\KeywordTok{round}\NormalTok{(scale,}\DecValTok{2}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }
     \DataTypeTok{cex.axis =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{cex.lab=} \FloatTok{0.6}\NormalTok{, }\DataTypeTok{cex.main=}\FloatTok{0.7}\NormalTok{, }\DataTypeTok{cex.sub=}\FloatTok{0.6}\NormalTok{, }
     \DataTypeTok{xilm=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1500}\NormalTok{))}
\end{Highlighting}
\end{Shaded}
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotgumbelhffunction-1.pdf}
\caption{\label{fig:plotgumbelhffunction}Gumbel cdf}
\end{figure}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#library(reliaR)}
\CommentTok{#plot(.x, hgumbel(.x, mu=location, sigma=scale))}
\CommentTok{#plot(.x, hra.gumbel(.x, mu=location, sigma=scale))}
\end{Highlighting}
\end{Shaded}
\normalsize

\hypertarget{statistical-concepts-for-extreme-analysis}{%
\section{Statistical Concepts For Extreme Analysis}\label{statistical-concepts-for-extreme-analysis}}

In order to approach the extreme value analysis, some statistical concepts are needed to understand the theoretical framework behind this knowledge area. In this section will be introduced the concepts annual exceedance probability, mean recurrence interval - MRI, exposure time, and compound probability for any given exposure time and MRI.

As an hypothetical example, a simulated database of extreme wind speed will be used. This database is supposed to have 10.000 years of simulated wind speeds.

\hypertarget{annual-exceedance-probability---p_e}{%
\subsection{\texorpdfstring{Annual Exceedance Probability - \(P_e\)}{Annual Exceedance Probability - P\_e}}\label{annual-exceedance-probability---p_e}}

Using the previously described database, a question arises to calculate the probability to exceed the highest probable loss due to the simulated winds. It is possible to conclude that there is only one event grater or equal (in this case equal) to the highest probable causing loss in 10.000 years, and it is the \emph{highest wind}. If we sort the database by wind magnitude in descending order (small winds last), the question is solved calculating the annual exceedance probability \emph{Pe} with next formula

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/unnamed-chunk-9-1.pdf}
\caption{\label{fig:unnamed-chunk-9}Sorted Winds by Magnitude - wind simulation database}
\end{figure}
\normalsize

\[
P_e = \frac{Event\,index\,after\,descending\,sorting}{Years\,of\,simulations } = \frac{1}{10.000}=0.001=0.01\%
\]
because the highest wind will be the first in the sorted list. Same exercise can be done with all winds to construct the annual exceedance probability curve, that in this case will represent the probability to equal or exceed different probable losses due to wind.

\hypertarget{return-period---mean-recurrence-interval---mri}{%
\subsection{Return Period - Mean Recurrence Interval - MRI}\label{return-period---mean-recurrence-interval---mri}}

Continuing with the previous section, if the inverse of the exceedance probability is taken, the return period (in years) is obtained. The return period or Mean Recurrence Interval - MRI is associated with an specific return level (wind extreme velocity). MRI is the numbers of years (N) needed to obtain 63\% of change that the corresponding return level will occur at least one time in that period. The return level is expected to be exceeded on average once every N-years. The annual exceedance probability of the return level corresponding to N-years of MRI, is \(P_e=\frac{1}{MRI}=\frac{1}{N}\).

For an specific wind extreme event A, the probability that the event will occur in a period equal to MRI years is 63\%. If we analyze for the same period a strongest wind extreme event B, its occurrence probability will be lest than 67\%. If the purpose of this research is to design infrastructure considering wind loads, the structure will be more resistant to wind if we design with stronger winds, this is high MRIs, and low annual exceedance probability. Common approach for infrastructure design, considering any type of load (earthquake, wind, etc) is to choose high MRI according to the importance/use/risk/type of the structure. For highly important structures, like hospitals or coliseums, where the risk of collapse must be diminished, the MRI used to design is higher in comparison to common structures (for instance a normal house), which implies less risks for its use and importance.

\[
  \mathrm{
    P_e = 
    \begin{cases}
      \begin{split}
            &1-\exp\left(-\frac{1}{MRI}\right),\;for\,MRI\,<\,10\,years
            \\
            &\frac{1}{MRI},\;for\,MRI\,\geq\,10\,years      
      \end{split}
    \end{cases}
  }
\]

\hypertarget{compound-exceedance-probability---pn}{%
\subsection{Compound Exceedance Probability - Pn}\label{compound-exceedance-probability---pn}}

If time of exposure is consider, understood as time the structure will be in use, it is possible to have a compound probability \(P_n\), where \(n\) is the exposure period. \(P_n\) is the probability that the extreme wind speed will be equaled or exceeded at least one time in \(n\) years, and is related with the occurrence probability, but also is possible to calculate the non-occurrence compound probability (probability that the event will not occur).

\[
  \mathrm{
    P_n = 
    \begin{cases}
      \begin{split}
            &1-\left(1-\frac{1}{MRI}\right)^n,\;occurrence\,probability
            \\
            &\left(1-\frac{1}{MRI}\right)^n,\;non-occurrence\,probability
      \end{split}
    \end{cases}
  }
\]

\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/compoundprobability-1.pdf}
\caption{\label{fig:compoundprobability}Compound Probability}
\end{figure}
\normalsize

If it is consider exposure time as a multiple of return period, the resulting figure \ref{fig:compoundprobability}, shows that:
\begin{itemize}
\tightlist
\item
  When exposure time is .69\% of the return period, then probability (occurrence and non-occurrence) will be 50\%
\item
  As was stated previously, when exposure time is equal to return period, then the probability that the extreme wind speed (return level) occur is 63\%, and 37\% for the non occurrence probability.
\item
  If exposure time is 4.5 times the return period, there is a 99\% of change that the return level will occur.
\end{itemize}
The example discussed here was presented as an instrument to introduce important concepts, nonetheless,there are specialized approaches to deal with extreme value analysis which will be discussed in \protect\hyperlink{extremeoverview}{Extreme Value Analysis Overview} and more in detail in \protect\hyperlink{pot-pp}{Peaks Over Threshold - Poisson Process}. In summary, is necessary to fit the data over a specific threshold to an extreme value distribution, and \(P_e\) will be \(1-F(y)\), with F(y) as the \emph{cdf}, and MRI as \(\frac{1}{1-F(y)}\).

\hypertarget{extremeoverview}{%
\section{Extreme Value Analysis Overview}\label{extremeoverview}}

Analysis of extreme values is related with statistical inference to calculate probabilities of extreme events. Main methods to analyze extreme data are epochal, Peaks Over Threshold - POT, and extreme index. The epochal method, also known as block maxima, uses the most extreme value for a specific frame of time, typically, one year. POT is based in the selection of a single threshold value to do the analysis only with values above the threshold. But there are different POT approaches, the most common one is Generalized Pareto Distribution - POT-GPD, but also it is possible to use the Poisson process approach.

In both methods (Epochal and POT), the first step is to fit the data to an appropriate probability distribution model, among them the most used are, - Extreme Value Type I (Gumbel), Extreme Value Type II (Fréchet), Weibull, Generalized Pareto - GPD, and Generalized Extreme Value - GEV.

Distribution models are fitted based in the estimation of its parameters, commonly called location, scale and shape, nonetheless each model has its own parameters names. There are different methods to estimate parameters, among them, - method of moments (modified moments - see Kubler (\protect\hyperlink{ref-Kubler1994}{1994}), and L moments - see Hosking \& Wallis (\protect\hyperlink{ref-Hosking1997}{1997})), - method of maximum likelihood MLE, see Harris \& Stocker (\protect\hyperlink{ref-Harris1994}{1998}), which is problematic for GPD and GEV, - probability plot correlation coefficient, and - elemental percentiles (for GPD and GEV)

Once candidate parameters are available, it is necessary to assess the goodness of fit of the selected model, using one of the next methods, - Kolmogorov-Smirnov (KS) goodness of fit test, and - Anderson-Darling goodness of fit test. Here a visual assessment is also useful using a probability plot or a kernel density plot with the fitted \emph{pdf} overlaid.

The main use of the fitted model is the estimation of mean return intervals - MRI, and extreme wind speeds (return levels),

\[
MRI=\frac{1}{1-F(y)}
\]
with \(F(y)\) as the \emph{cdf}. If \(1-F(y)\) is the annual exceedance probability, MRI is its inverse, see Simiu \& Scanlan (\protect\hyperlink{ref-Simiu1996}{1996}) for more details about MRI. If \(y\) is solved from previous equation using a given MRI of N-years, its value represents the \(Y_N\) wind speed return level,

\[
Y_N = G\left(1-\frac{1}{\lambda\,N}\right)
\]
where \(G\) is the \emph{ppf} (quantile function) and \(\lambda\) is the number of wind speeds over the threshold per year.

The CRAN Task View ``Extreme Value Analysis'' \url{https://cran.r-project.org/web/views/ExtremeValue.html} shows available \textbf{R} for block maxima, POT by GPD, and external indexes estimation approaches. Most important to consider are \texttt{evd}, \texttt{extremes}, \texttt{evir}, \texttt{POT}, \texttt{extremeStat}, \texttt{ismev}, and \texttt{Renext}.

\hypertarget{pot-pp}{%
\section{Peaks Over Threshold - Poisson Process}\label{pot-pp}}

According to Pintar et al. (\protect\hyperlink{ref-Pintar2015}{2015}) the stochastic Poisson process is mainly defined by its intensity function. As the intensity function is nos uniform over the domain, the Poisson process considered here is non-homogeneous, and due to the intensity function dependency of magnitude and time, it is also bi-dimensional. Poisson Process was described for the first time in Pickands (\protect\hyperlink{ref-Pickands1971}{1971}), then extended in Smith (\protect\hyperlink{ref-Smith1989}{1989}).
\begin{equation}
  \mathrm{
    \lambda\left(y,t\right)
    \begin{cases}
      \begin{split}
            &\lambda_t(y),\;for\,t\,in\,thunderstorm\,period
            \\
            &\lambda_nt(y),\;for\,t\,in\,non-thunderstorm\,period      
      \end{split}
    \end{cases}
  }
  \label{eq:ppgenericintensityfunction}
\end{equation}
Generic equation \eqref{eq:ppgenericintensityfunction} shows the intensity function, which is defined in the domain \(D = D_t\,{\cup}\,D_{nt}\), and allow to fit the Poisson process at each station to the observed data \(\{t_i, y_i\}_{i=1}^I\) for all the times (\(t_i\)) of threshold crossing observations and its corresponding wind speeds magnitudes (\(y_i\)). Thus, only data above the threshold is used.

Intensity function of the Poisson Process is defined in Smith (\protect\hyperlink{ref-Smith2004}{2004}),

\[
\frac{1}{\psi_t}\left(1+\zeta_t\frac{y-\omega_t}{\psi_t}\right)_+^{-\frac{1}{\zeta_t}-1}
\]
Where \(\zeta_t\) controls the tail length of the intensity function at a given time \(t\), but to facilitate the estimation of the parameters then \(\zeta_t\) is taken to be zero, then doing the limit, the resulting intensity function is the same as the the GEV type I or Gumbel distribution,

\[
\frac{1}{\psi_t}\exp\left\{\frac{-(y-\omega_t)}{\psi_t}\right\}
\]

In this study, the used intensity functions are shown in equation \eqref{eq:ppspecificintensityfunction}.
\begin{equation}
  \mathrm{
    \lambda\left(y,t\right)
    \begin{cases}
      \begin{split}
            &\frac{1}{\psi_s}\exp\left\{\frac{-(y-\omega_s)}{\psi_s}\right\},\;for\,t\,in\,thunderstorm\,period
            \\
            &\frac{1}{\psi_{nt}}\exp\left\{\frac{-(y-\omega_{nt})}{\psi_{nt}}\right\},\;for\,t\,in\,non-thunderstorm\,period      
      \end{split}
    \end{cases}
  }
  \label{eq:ppspecificintensityfunction}
\end{equation}
\footnotesize
\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/plotdomainpp-1.pdf}
\caption{\label{fig:plotdomainpp}Domain off the Poisson Process}
\end{figure}
\normalsize

Figure \ref{fig:plotdomainpp} represent the domain \(D\) of the Poisson process. In time, the domain represents the station service period from first sample \(t_1\) to last sample \(t_4\). \(D\) is the union of all thunderstorm periods \(D_t\) (from \(t_2\) to \(t_3\)), and all non-thunderstorm periods \(D_{nt}\) (periods \(t_1\) to \(t_2\) and \(t_3\) to \(t_4\)). In magnitude, only thunderstorm data above its threshold \(b_t\), and only non-thunderstorm data above its threshold \(b_{nt}\) are used.

Thunderstorms and non-thunderstorms are modeled independently:
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Observations in domain \(D\) follow a Poisson distribution with mean \(\int_D\lambda(t,y)\,dt\,dy\)
\item
  For each disjoint sub-domain \(D_1\) or \(D_2\) inside \(D\), the observations in \(D_1\) or \(D_2\) are independent random variables.
\end{enumerate}
Visual representation of the intensity function for the Poisson Process can be seen in figure \ref{fig:plotdomain3dpp}. In vertical axis, two surfaces were drawn representing independent intensity functions for thunderstorm \(\lambda_t(y)\) and for non-thunderstorm \(\lambda_{nt}(y)\). The volume under each surface for its corresponding time periods and peak (over threshold) velocities, is the mean of the Poisson Process.

\footnotesize
\begin{figure}
\includegraphics[width=6.35in]{figure/domain3d} \caption{Volume under surfaces represents the mean of the Poisson process}\label{fig:plotdomain3dpp}
\end{figure}
\normalsize

The method of maximum likelihood es used to estimate the parameters of the Poisson process, the selected vector of parameters \(\eta\) are the \(\hat\eta\) values that maximizes the function
\begin{equation}
  \mathrm{
          L(\eta)=\left( 
                        \prod_{i=1}^I\lambda\left(y_i,t_i\right)  
                  \right)
                  \exp\left\{
                            -\int_{{D}}\lambda\left(y,t\right)dy\,dt
                     \right\}
         }
  \label{eq:pplikelihood}
\end{equation}
\(\hat\eta\) values need to be calculated using a numerical approach because there is not analytical solution available.

Once the Poisson process is fitted to the data, the model will provide extreme wind velocities (return levels), for different return periods (mean recurrence intervals).

A \(Y_N\) extreme wind velocity, called the return level (RL) belonging to the N-years return period, has a expected frequency to occur or to be exceeded (annual exceedance probability)\(P_e = \frac{1}{N}\), and also has a probability that the event does not occur (annual non-exceedance probability) \(P_{ne}=1-\frac{1}{N}\). \(Y_N\) will be the resulting value of the \(G\) (ppf or quantile) function using a probability equal to \(P_{ne}\). \(Y_N=quantile(y, p=P_{ne})=G(x,p=P_{ne})=ppf(x,p=P_{ne})\). As for this study \(\zeta = 0\), the \(G\) function to use is the Gumbel quantile function. \(Y_N\) can be understood as the wind extreme value expected to be exceeded on average once every N years.

For different POT approaches, as POT-GPD described --, the value of the probability passed to the \(G\) function, has to be modified with the \(\lambda\) parameter, as is described in next equation. \(\lambda\) is the number of wind speed over the threshold per year.

\[
Y_N =G\left(y, 1-\frac{1}{\lambda\,N}\right)
\]

For the Poisson process \(Y_N\) is also the solution to the next equation, which is defined in terms of the intensity function,
\begin{equation}
  \mathrm{
          \int_{Y_N}^{\infty}\int_0^1\lambda\left( y,t\right)dydt = A_t\int_{Y_N}^{\infty}\lambda_t\left( y\right)\,dy + A_{nt}\int_{Y_N}^{\infty}\lambda_{nt}\left( y\right)\,dy = \frac{1}{N}
         }
  \label{eq:ppmri}
\end{equation}
where \(A_t\), is the multiplication of the average number of thunderstorm per year and the average length of a thunderstorm (taken to be 1 hour as defined in Pintar et al. (\protect\hyperlink{ref-Pintar2015}{2015})), and \(A_{nt} = 1 - A_t\). The average length of a non-thunderstorm event is variable, and it is adjusted in each station to guarantee that \(A_{nt} + A_t = 1\)

The same thunderstorm event in considered to occur if the time lag distance between successive thunderstorm samples is small than six hours, and for non-thunderstorm this time is 4 days. For the Poisson process, all the measurements belonging to the same event (thunderstorm or non-thunderstorm), need to be de-clustered to leave only one maximum value. In other words, the number of thunderstorm in the time series is the number of time lag distances grater than 6 hours, and for non-thunderstorm grater than 4 days.

\hypertarget{threshold-selection}{%
\subsection{Threshold Selection}\label{threshold-selection}}

\[U=F(Y)\]
\[W = -log(1-U)\]

\hypertarget{wind-loads-requirements}{%
\section{Wind Loads Requirements}\label{wind-loads-requirements}}

As the output maps of this research will be used as input loads for infrastructure design, the methodology used for its creation, need to be consistent with Colombian official wind loads requirements. Today (2020), the Colombian norm that defines wind loads is the Seismic Resistant Standard 2010 - NSR-10 by its acronym of Spanish, see XXX. Chapter related to wind loads is B.6. NSR-10 was created and is maintained by the Colombian Association of Seismic Engineering - AIS.

NSR-10 is mainly based in the USA norm American Society of Civil Engineers 7-16, minimum design loads and associated criteria for buildings and other structures - ASCE7-16, see Engineers (\protect\hyperlink{ref-Asce2017}{2017}). Under these circumstances, ASCE7-16 defines the minimum requirements of the research products. Especially the chapter C26 - ``wind loads - general requirements'', C26.5 ``wind hazard map'', and C26.7 ``Exposure'' - pages 733 to 747. Wind speeds requirements of ASCE7-16 are based in the combination of independent non-hurricane analysis, and hurricane wind speeds simulations models. The focus of this research will be the analysis of non-hurricane wind data, however, existing results of hurricane studies will be used to present final maps with both components. In ASCE7-16, for non-hurricane wind speed, the procedure is mainly based on Pintar et al. (\protect\hyperlink{ref-Pintar2015}{2015}).

ASCE7-16 (page 734), requires the calculation of wind extreme return levels for specific return periods according to the risk category of the structure to be designed: risk category I - 300 years, risk category II - 700 years, risk category III - 1700 years, risk category IV - 3000 years. NSR-10 only requires 700, 1700 and 3000 years. In addition, extreme wind speeds for those MRI need to correspond to: - 3 second gust speeds, - at 33 ft (10 meters) above the ground, and - exposure category C (open space).
\begin{itemize}
\tightlist
\item
  Risk IV - This are `indispensable buildings' that involve substantial risk. This structures that can handle toxic or explosive substances.
\item
  Risk III - There is substantial risk because this structures that can handle toxic or explosive substances, can cause a serious economical impact, or massive interruption of activities if they fail
\item
  Risk II - Category `by default', and correspond to structures not classified in others categories.
\item
  Risk I - This structures represent low risk for people lives
\end{itemize}
To standardize wind speeds to gust speeds ASCE7-16 proposes the curve Durst (see C. S. Durst (\protect\hyperlink{ref-Durst1960}{1960}), and figure \ref{fig:durstcurve}). It is valid only for open terrain conditions. Durst curve shows in axis \(y\) the gust factor \(\frac{V_t}{V_{3600}}\), a ration between any wind gust averaged at \(t\) seconds, \(V_t\), and the hourly averaged wind speed \(V_{3600}\), and in the axis \(x\) the duration \(t\) of the gust.

\footnotesize
\begin{figure}
\includegraphics[width=6.14in]{figure/durst} \caption{Maximum speeds averaged over t (sec), to hourly mean speed}\label{fig:durstcurve}
\end{figure}
\normalsize

\hypertarget{rmd-method}{%
\chapter{Methodology}\label{rmd-method}}

Figure \ref{fig:methodology} shows a graphic representation of the methodology. This thesis research is focus in non-hurricane data, with three main elements: - data, - temporal analysis with a POT- Poisson process, and - spatial analysis with probabilistic and deterministic methods to do spatial interpolation and create return levels (wind velocities) maps, for MRI of 700, 1700, and 3000 years. An additional element, is the integration with existing hurricane maps to produce final maps, that will be used as input loads for infrastructure design, and will be part of the NSR-10.

More representative and important steps of the methodology are identified by numbers, 1) standardization, 2) de-clustering, 3) thresholding, 4) fit intensity function, 5) hazard curve, 6) return levels, and 7) spatial interpolation. Steps 1 to 6, need to be done for each available station to get MRI wind velocities. With MRI wind velocities in each station, a continuous surface will be created, one for 700 years, next for 1700 years and finally 3000 years. Figure \ref{fig:mainmethodology} schematize that iterative process.

\footnotesize
\begin{figure}
\includegraphics[width=6.47in]{figure/methodology} \caption{Methodology}\label{fig:methodology}
\end{figure}
\normalsize

\footnotesize
\begin{figure}
\includegraphics[width=3.51in]{figure/main_methodology} \caption{Iterative process in methodology}\label{fig:mainmethodology}
\end{figure}
\normalsize

\hypertarget{data}{%
\section{Data}\label{data}}

\hypertarget{getting-the-data}{%
\subsection{Getting the data}\label{getting-the-data}}

\hypertarget{exploratory-data-analysis---eda}{%
\subsection{Exploratory Data Analysis - EDA}\label{exploratory-data-analysis---eda}}

\hypertarget{standardization}{%
\subsection{Standardization}\label{standardization}}

\hypertarget{anemometer-height---10-m}{%
\subsubsection{Anemometer height - 10 m}\label{anemometer-height---10-m}}

According to the protocol for field data collection and location of methodological stations - IDEAM, 2005 (XXX), the anemometer (wind sensor) in installed always to a fixed high of 10 meters from the surface, as is shown in figure XXX

\hypertarget{surface-roughness---0.03-m}{%
\subsubsection{Surface Roughness - 0.03 m}\label{surface-roughness---0.03-m}}

\hypertarget{averaging-time---3-s-gust}{%
\subsubsection{Averaging Time - 3-s gust}\label{averaging-time---3-s-gust}}

To transform hourly mean wind velocity (\(V_{3600}\)), ASCE7-16 (XXX) recommended to use Durst 1960 (XXX).

\hypertarget{filtering}{%
\subsection{Filtering}\label{filtering}}

\hypertarget{separating}{%
\subsection{Separating}\label{separating}}

\hypertarget{comparison}{%
\subsection{Comparison}\label{comparison}}

\hypertarget{selection-of-input-data}{%
\subsection{Selection of input data}\label{selection-of-input-data}}

\hypertarget{pot---poisson-process}{%
\section{POT - Poisson Process}\label{pot---poisson-process}}

\hypertarget{de-clustering}{%
\subsection{De-clustering}\label{de-clustering}}

\hypertarget{exclude-no-data-periods}{%
\subsection{Exclude no-data periods}\label{exclude-no-data-periods}}

\hypertarget{thresholding}{%
\subsection{Thresholding}\label{thresholding}}

As the POT model requires to work only with the most extreme values in the time series, it is necessary to select a threshold to filter out small values. Selection of threshold value imply two effects in the model. Bias is high when a low threshold is selected (many exceedances) because the asymptotic support is weak. Opposite situation happens for high thresholds where variance is potentially high, so according to Davidson and Smith 1990 (XXX), it is needed to select a threshold value, consistent with model structure.

\hypertarget{fit-intensity-function}{%
\subsection{Fit Intensity Function}\label{fit-intensity-function}}

\hypertarget{intensity-function}{%
\subsubsection{Intensity function}\label{intensity-function}}

\hypertarget{density-function}{%
\subsubsection{Density function}\label{density-function}}

\hypertarget{distribution-function}{%
\subsubsection{Distribution function}\label{distribution-function}}

\hypertarget{maximum-likelihood-estimation}{%
\subsubsection{Maximum likelihood estimation}\label{maximum-likelihood-estimation}}

\hypertarget{hazard-curve}{%
\subsection{Hazard Curve}\label{hazard-curve}}

\hypertarget{return-levels}{%
\subsection{Return Levels}\label{return-levels}}

\hypertarget{spatial-interpolation}{%
\section{Spatial Interpolation}\label{spatial-interpolation}}

\hypertarget{kriging}{%
\subsection{Kriging}\label{kriging}}

\hypertarget{idw}{%
\subsection{IDW}\label{idw}}

\hypertarget{local-polynomials}{%
\subsection{Local Polynomials}\label{local-polynomials}}

\hypertarget{integration-with-non-hurricane-data}{%
\section{Integration with Non-Hurricane data}\label{integration-with-non-hurricane-data}}

\hypertarget{conclusion}{%
\chapter*{Conclusion}\label{conclusion}}
\addcontentsline{toc}{chapter}{Conclusion}

If we don't want Conclusion to have a chapter number next to it, we can add the \texttt{\{-\}} attribute.

\textbf{More info}

And here's some other random info: the first paragraph after a chapter title or section head \emph{shouldn't be} indented, because indents are to tell the reader that you're starting a new paragraph. Since that's obvious after a chapter or section title, proper typesetting doesn't add an indent there.

\appendix

\hypertarget{r-code}{%
\chapter{R Code}\label{r-code}}

This first appendix includes all of the R chunks of code that were hidden throughout the document (using the \texttt{include\ =\ FALSE} chunk tag) to help with readability and/or setup.

\textbf{In the main Rmd file}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This chunk ensures that the thesisdown package is}
\CommentTok{# installed and loaded. This thesisdown package includes}
\CommentTok{# the template files for the thesis.}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(devtools))}
  \KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(thesisdown))}
\NormalTok{  devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"ismayc/thesisdown"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(thesisdown)}
\end{Highlighting}
\end{Shaded}
\textbf{In Chapter \ref{rmd-method}:}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This chunk ensures that the thesisdown package is}
\CommentTok{# installed and loaded. This thesisdown package includes}
\CommentTok{# the template files for the thesis and also two functions}
\CommentTok{# used for labeling and referencing}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(devtools))}
  \KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(dplyr))}
    \KeywordTok{install.packages}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(ggplot2))}
    \KeywordTok{install.packages}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(ggplot2))}
    \KeywordTok{install.packages}\NormalTok{(}\StringTok{"bookdown"}\NormalTok{, }\DataTypeTok{repos =} \StringTok{"http://cran.rstudio.com"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(thesisdown))\{}
  \KeywordTok{library}\NormalTok{(devtools)}
\NormalTok{  devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"ismayc/thesisdown"}\NormalTok{)}
\NormalTok{  \}}
\KeywordTok{library}\NormalTok{(thesisdown)}
\NormalTok{flights <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/flights.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\hypertarget{the-second-appendix}{%
\chapter{The Second Appendix}\label{the-second-appendix}}

\backmatter

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\noindent

\setlength{\parindent}{-0.20in}
\setlength{\leftskip}{0.20in}
\setlength{\parskip}{8pt}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-Coles2001}{}%
Coles, S. (2001). \emph{An introduction to statistical modeling of extreme values}. Springer London. \url{http://doi.org/10.1007/978-1-4471-3675-0}

\leavevmode\hypertarget{ref-Durst1960}{}%
C. S. Durst, B. A., O. B.E. (1960). Wind speeds over short periods of time. \emph{The Meteorological Magazine}, \emph{89}(1056), 181--187. Retrieved from \url{https://www.depts.ttu.edu/nwi/Pubs/ReportsJournals/ReportsJournals/Windspeeds.pdf}

\leavevmode\hypertarget{ref-Asce2017}{}%
Engineers, A. S. O. C. (2017). \emph{Minimum design loads and associated criteria for buildings and other structures (asce7-16)}. American Society of Civil Engineers. Retrieved from \url{https://www.ebook.de/de/product/35017614/american_society_of_civil_engineers_minimum_design_loads_and_associated_criteria_for_buildings_and_other_structures_7_16.html}

\leavevmode\hypertarget{ref-Harris1994}{}%
Harris, J. W., \& Stocker, H. (1998). Maximum likelihood method. In \emph{Handbook of mathematics and computational science} (p. 824). Springer-Verlag.

\leavevmode\hypertarget{ref-Hosking1997}{}%
Hosking, J. R. M., \& Wallis, J. R. (1997). \emph{Regional frequency analysis}. Cambridge University Press. \url{http://doi.org/10.1017/cbo9780511529443}

\leavevmode\hypertarget{ref-Kubler1994}{}%
Kubler, J. (1994). \emph{Computational Statistics \&Amp; Data Analysis}, \emph{18}(4), 473--474. Retrieved from \url{https://EconPapers.repec.org/RePEc:eee:csdana:v:18:y:1994:i:4:p:473-474}

\leavevmode\hypertarget{ref-Pickands1971}{}%
Pickands, J. (1971). The two-dimensional poisson process and extremal processes. \emph{Journal of Applied Probability}, \emph{8}(4), 745--756. \url{http://doi.org/10.2307/3212238}

\leavevmode\hypertarget{ref-Pintar2015}{}%
Pintar, A. L., Simiu, E., Lombardo, F. T., \& Levitan, M. L. (2015). \emph{Simple guide for evaluating and expressing the uncertainty of NIST MeasuremenMaps of non-hurricane non-tornadic wind speeds with specified mean recurrence intervals for the contiguous united states using a two-dimensional poisson process extreme value model and local regressiont results}. National Institute of Standards; Technology.

\leavevmode\hypertarget{ref-Simiu1996}{}%
Simiu, E., \& Scanlan, R. H. (1996). \emph{Wind effects on structures : Fundamentals and applications to design} (3rd ed.). New York : John Wiley. Retrieved from \url{http://lib.ugent.be/catalog/rug01:001267836}

\leavevmode\hypertarget{ref-Smith1989}{}%
Smith, R. L. (1989). Extreme value analysis of environmental time series: An application to trend detection in ground-level ozone. \emph{Statistical Science}, \emph{4}(4), 367--377. \url{http://doi.org/10.1214/ss/1177012400}

\leavevmode\hypertarget{ref-Smith2004}{}%
Smith, R. L. (2004). Extreme values in finance, telecommunications, and the environment (chapman \& hall/crc monographs on statistics and applied probability). In B. F. inkenstädt \& H. Rootzén (Eds.), (pp. 1--78). Chapman; Hall/CRC. Retrieved from \url{https://www.amazon.com/Telecommunications-Environment-Monographs-Statistics-Probability/dp/1584884118?SubscriptionId=AKIAIOBINVZYXZQZ2U3A\&tag=chimbori05-20\&linkCode=xm2\&camp=2025\&creative=165953\&creativeASIN=1584884118}


% Index?

\end{document}
